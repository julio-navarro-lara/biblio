computers & security 28 (2009) 153­173

available at www.sciencedirect.com

journal homepage: www.elsevier.com/locate/cose

An incremental frequent structure mining framework for real-time alert correlation
Reza Sadoddin*, Ali A. Ghorbani
Network Security Laboratory, University of New Brunswick, 550 Windsor St., Fredericton, New Brunswick, Canada E3B 5A3

article info
Article history: Received 19 December 2007 Received in revised form 7 October 2008 Accepted 26 November 2008 Keywords: Online alert correlation Intrusion detection Network security Stream data mining Graph mining Attack scenario extraction False positive analysis FP tree DDoS attack Tilted-time window model

abstract
With the large volume of alerts produced by low-level detectors, management of intrusion alerts is becoming more challenging. Manual analysis of a large number of raw alerts is both time consuming and labor intensive. Alert Correlation addresses this issue by finding similarity and causality relationships between raw alerts to provide a condensed, yet more meaningful view of the network from the intrusion standpoint. While some efforts have been made in the literature by researchers to find the relationships between alerts automatically, not much attention has been given to the issue of real-time correlation of alerts. Previous learning-based approaches either fail to cope with a large number of generated alerts in a large-scale network or do not address the problem of concept drift directly. In this paper, we propose a framework for real-time alert correlation which incorporates novel techniques for aggregating alerts into structured patterns and incremental mining of frequent structured patterns. Our approach to aggregation provides a reduced view of developed patterns of alerts. At the core of the proposed framework is a new algorithm (FSP_Growth) for mining frequent patterns of alerts considering their structures. In the proposed framework, time-sensitive statistical relationships between alerts are maintained in an efficient data structure and are updated incrementally to reflect the latest trends of patterns. The results of experiments conducted with the DARPA 2000 dataset as well as artificial data clearly demonstrate the efficiency of proposed techniques. A promising reduction ratio of 96% is achieved on the DARPA 2000 dataset. The running time of the FSP_Growth algorithm scales linearly with the size of artificial datasets. Moreover, testing the proposed framework with alert logs of a real-world network shows its ability to extract interesting patterns among the alerts. The ability to answer useful time-sensitive queries regarding pattern cooccurrences is another advantage of the proposed method compared to other approaches. Crown Copyright Ş 2008 Published by Elsevier Ltd. All rights reserved.

1.

Introduction

The significant increase of our everyday life dependency on the Internet-based services has intensified the importance of survivability of networks. Intrusion detection is one of the major techniques for protecting information systems. According to the results of the 2006 CSI/FBI Crime and

Computer Security Survey, an intrusion detection system is the fifth most widely used security technology among the respondents (69% of surveyed organizations use IDSs as a security measure). Intrusion detection has been an active research area for over 20 years since it was first introduced in the 1980s. Intrusion detection systems can be roughly classified as

* Corresponding author. E-mail addresses: resa.sadoddin@unb.ca (R. Sadoddin), ghorbani@unb.ca (A.A. Ghorbani). 0167-4048/$ ­ see front matter Crown Copyright Ş 2008 Published by Elsevier Ltd. All rights reserved. doi:10.1016/j.cose.2008.11.010

154

computers & security 28 (2009) 153­173

anomaly-based detection and signature-based detection systems. When an intrusion detection system learns the normal behavior of the system or the network it monitors, it is categorized as an anomaly-based IDS. An anomaly is reported when the monitored behavior deviates significantly from the normal profile. A signature-based (misuse) detection approach, on the other hand, uses information about the known attacks and detects intrusions based on matches with existing signatures. These well-known intrusion detection techniques have their own strengths and weaknesses. For example, signature-based intrusion detection has a lower false positive rate but it is intended for detecting known attacks. Anomaly-based detection has the potential to detect novel attacks, but at the same time it suffers from a high false positive rate. Moreover, it is very hard to define normal behavior for a system. In order to compensate for limitations of individual intrusion detection systems, sensors with various detection mechanisms are deployed in different locations of the protected network. In addition, other security tools such as firewalls, antivirus utilities and file integrity checkers are employed in order to provide a more detailed view of the security status of the network. Managing raw alerts generated by various sensors are becoming more significant to intrusion detection systems as more sensors with different capabilities are distributed spatially in the network. Higher level management is required for analyzing low-level alerts produced by these devices before reporting them to the next layer. This is needed for several reasons. First, it is not easy to locate the source or target of the intrusion or fault in the network by looking into low-level alerts. Secondly, the lowlevel sensors consider raw alerts in isolation and raise alarms for each of them, without considering logical connections between alerts. Also, any automatic response would be inefficient with these raw alerts as input. In addition, in a typical environment there are a lot of false positive alerts reported by traditional IDSs, which are mixed with true positive alerts. Alert Correlation provides the system with automatic analysis of alerts. An alert correlation module not only saves a lot of time on the administrative side, but also helps to deal with potential threats against the network more efficiently. Previous works in this area have addressed different aspects of alert correlation including filtering false positives, aggregating similar alerts into clusters, correlating alerts based on their relationship in an attack scenario, and prioritizing alerts based on their severity. Two main approaches have been used in the literature for correlating alerts in attack scenarios. In the first category of works, the relationships between alerts are hard-coded in the system. These methods are limited to the knowledge base of the system and cannot correlate alerts of unseen attacks. To overcome this problem, machine learning and data mining techniques have been used to extract relationships between alerts after an initial period of training. In this category of works, co-occurrence of alerts within specified time windows is used as an important feature for the statistical analysis of alerts. This involves pair-wise comparison between alerts since every two alerts are candidates to be correlated in a newly emerging pattern. Pair-wise comparison between alerts poses serious challenges on learning-based correlation

techniques in large-scale networks, in which a throughput of 5000 alerts per minute is expectable. In this paper, we address the problem of real-time correlation of alerts in a learning-based approach. The contributions of our work can be summarized as follows: - We propose a framework for real-time correlation of alerts based on their frequency of co-occurrences. The proposed framework provides a means of processing a stream of alerts continuously, maintaining their correlation significance with respect to the latest changes, and answering some interesting queries about patterns. - A method for dynamic creation and generalization of alerts into clusters (patterns) is proposed. Abstract signatures of patterns allow us to detect some similar behavior of alerts which otherwise would have been detected as different patterns. - We propose a novel Frequent Structure Mining technique for extracting patterns considering their structures. The proposed method not only provides more accurate frequency analysis of patterns, but also gives the exact structure of the extracted patterns within the network. The rest of this paper is organized as follows: In Section 2, some of the related works in alert correlation are reviewed. Section 3 provides the details of the proposed framework for incremental mining of frequent alert patterns. In Section 4, we present results of the experiments that were conducted for evaluating the proposed techniques and framework with the DARPA 2000 dataset, a synthetic graph data generator and a real-world dataset. Finally, the conclusions and some suggestions for future work are given in Section 5.

2.

Related work

In the following, we review the related work in the literature, which address aggregating alerts into clusters, correlating alerts into attack scenarios, and filtering false positive alerts. The purpose of aggregation is to group all similar alerts together. During aggregation, alerts are put into a group based on the similarity of their corresponding features. The most common attributes of alerts are Source IP, Destination IP, Source Port, Destination Port, Attack Class and Timestamp. In the technique proposed by Valdes and Skinner, 2001, alerts are grouped with each other based on their overall similarity. This overall similarity of two alerts is defined based on their similarities on the corresponding features. The proposed technique, even though it provides a basic probabilistic model for measuring similarities between alerts, has the drawback of relying on expert knowledge for specifying the similarity degree between attack classes in a two-dimensional matrix. A clustering technique is proposed by Julisch, 2003 for grouping all the alerts which share the same root causes. Central to the clustering technique proposed by Julisch are the hierarchy structures ( generalization hierarchies as they are called), which decompose the attributes of the alerts from the most general values to the most specific ones. The generalization hierarchies are later used for measuring the distance

computers & security 28 (2009) 153­173

155

between alerts in a clustering algorithm. The idea of generalization hierarchies seems promising for the purpose of aggregation, but the proposed method has the drawback of assuming a predetermined size for all the clusters. Another important aspect of correlation is to find causal relationships between alerts. The causal relationships between alerts might represent how they are related to each other in an attack scenario. Although it might not have a significant effect in reducing the number of alerts, the causality analysis component is essential in providing a higher level view of the actual attacks. Previous works on causality analysis can be divided into the following categories: ­ Correlation based on known scenarios: In this category of works, causality relationships between alerts are specified in terms of known attack scenarios. An attack scenario is either specified by an attack language such as STATL (Eckmann et al., 2002), LAMBDA (Cuppens and Ortalo, 2000), or ADeLe (Totel et al., 2004), or extracted automatically using machine learning techniques. ­ Correlation based on prerequisite and consequence relationships: In this group of works (Templeton and Levitt, 2000; Cuppens and Miege, 2002; Ning et al., 2002; Cheung et al., 2003), pair-wise relationships between alerts are specified in rules. In other words, alert `A' is correlated with alert `B' if the first one prepares for the second alert in a prerequisite-consequence relationship. ­ Statistical correlation: Methods in this group correlate two alerts if they are statistically related to each other based on their co-occurrence within a time window. Qin et al. model the correlation between alerts by Bayesian Networks and propose a technique for learning the structure of the network as well as the amount of correlation between alerts (Qin, 2005). In another reported work, Granger Causality Test is used by Qin et al. for statistical analysis of alerts (Qin and Lee, 2003). Each type of alert is modeled by a time series variable representing the alert rate within equal time slots. The Granger Causality Test is used as a statistical test to see whether an alert of type X could cause an alert of type Y or not. Zhu et al. propose two machine learning techniques (Multilayer Perceptron and Support Vector Machine) for estimating correlation probability between alerts. The proposed features by the authors are similar to features proposed by Valdes et al. (Valdes and Skinner, 2001), but the correlation degree between attack classes are learned incrementally by the system (as apposed to having the experts specify it). Generally, the scenario-based and prerequisite-consequence methods are limited to a knowledge base that should be hard-coded in the system, whereas the statistical techniques are capable of correlating alerts that may contribute to unknown attacks. On the other hand, in practice these techniques seem to be less accurate and more time consuming compared to knowledge-based methods. Accordingly, they are complementary to each other in the correlation component. Distinguishing between false positive and true positive alerts is another aspect of correlation. Different sensors have their own strengths and weaknesses in detecting various

attacks, and it is a well-know problem of low-level sensors that they tend to generate alerts with a high rate of false positives. As a result, the role of this component is critical in reducing false alerts. Pietraszek, 2004 proposes an Adaptive Learner for Alert Classification(ALAC) framework for false positive analysis of alerts. Central to the proposed framework is a classification engine that accepts the main attributes of an alert along with some background knowledge as input and estimates the probability of the alert to a true positive one. In another reported work (Manganaris et al., 2000), the idea of frequent episode rules is used by Manganaris et al. for extracting normal alert patterns. In the learning phase, the set of frequent episode rules are extracted from the alert logs after filtering the attack traffic from it (maybe through exploitation of signature-based IDSs). In the operation mode, a sequence of alerts that match a frequent episode rule are considered to be false positives. Zhai et al., 2004 propose a framework for reasoning about alert confidence. In this work, the relationships between alerts and security state of the system are modeled through Bayesian Networks. Based on this model, estimated confidence on the alert (to be true positive) is extracted form Conditional Probability Tables (CPTs) of the Bayesian Network. Svensson and Josang, 2001 propose a framework for fusing confidence of the alerts raised by low-level sensors. At the core of this framework resides the sensor fusion component, which receives the opinions from the sensors and uses well-defined operations of subjective logic (e.g. consensus or multiplication) to provide the confidence of the aggregated and correlated alerts.

3. Proposed framework for incremental frequent structure mining
Online processing of alerts poses some major challenges for correlation approaches. First, the underlying technique should cope with the high rate of alerts produced by the lower-level sensors of the network. Secondly, the alerts that correspond to a pattern of interest usually are not received by the correlation component at the same time. Therefore, the proposed technique for pattern construction should allow incremental development of patterns. Moreover, a statistical approach to alert correlation should deal with ``concept drift''. The correlation degree (based on the proposed statistical correlation measure) between two alerts or a group of alerts within a candidate frequent pattern might not be significant at the moment. However, it might become stronger in the future as a result of following co-occurrences. Therefore, a suitable running model, which is the representative of the correlation degree of the patterns seen so far, and an efficient mechanism for maintaining it is necessary. Fig. 1 shows our proposed framework for incremental alert correlation. Raw alerts are received continuously at the Aggregation component. This component correlates alerts into graph structures based on their connectivity information with respect to origin and target of alerts. Each of these structured patterns might represent attack strategies launched step by

156

computers & security 28 (2009) 153­173

Fig. 1 ­ The incremental framework for alert correlation.

step by an attacker or normal patterns generated due to false positive alerts. Constructed patterns are allowed to change dynamically until they become stable. Signatures of stable structured patterns are passed to the next component as a new batch of transactions for further processing. This component takes care of extracting frequent patterns among the recent transactions and updating a running model with respect to recently seen transactions of alerts. The running model is not only a reduced representative of previous frequent patterns and their statistical significance, but also shows the trend of transactions seen so far in different time periods. The framework provides the system administrator with two interfaces. He/she might see all the patterns of alerts along with their supplementary information by browsing the tree or can query the running model for a specific set of patterns.

3.1.

Aggregation

framework is responsible for analyzing significance of created patterns. Attackers may launch their attacks in different compositions based on the resources available to them and their final goals. For instance, in a distributed denial of service (DDoS ) attack, attackers take advantage of some intermediate victim hosts (such as Zombies) in order to flood their final victim (see Fig. 2). The number of involved intermediate hosts depends on the number of required machines for saturating the final host and the number of hosts the attacker is successful in compromising. However, all of these attacks render a similar pattern: A one-to-many pattern labeled as an XXX_Exploit (the exploit for vulnerable service XXX ) followed by a many-to-one pattern labeled with DoS_Stream. False positive alerts might be related to each other in the same way. In order to capture the common characteristics between different compositions of frequent patterns, the patterns should be generalized. The following definitions provide the required abstractions: Definition 1. Many-to-one Generalization is the abstraction of a set of alerts with the same type, the same destination IP, and multiple source IPs. Assuming that events are of type A, the generalized set of alerts is referred to as Many-to-one Hyper Alert and is represented by A*>. Definition 2. One-to-many Generalization is the abstraction of a set of alerts with the same type, the same source IP, and multiple destination IPs. Assuming that events are of type A, the generalized set of alerts is referred to as One-to-many Hyper Alert and is represented by A*<. Definition 3. Many-to-many Generalization is the abstraction of a set of alerts with the same type, the same source IP, and the same destination IP. Assuming that events are of type A, the generalized set of alerts is referred to as Many-To-Many Hyper Alert and is represented by A*ź.

Attacks might consist of one or multiple steps based on the ultimate goal of the attacker, initial information and accesses of the attacker as well as defence measures that are in effect on the victim side. Low-level detection sensors of the network will issue security alerts for each of these steps (as long as the appropriate detection mechanisms are available). As a result, there is an opportunity to hypothesize about possible attack strategies by correlating individual alerts. In previous works, different features of alerts such as Source IP, Source Port, Destination IP, Destination Port, Attack Class, and Timestamp have been used for correlation. Among these features, we make use of the features Source IP, Destination IP, Attack Class, and Timestamp in correlating individual alerts into candidate frequent patterns. The reason we do not use the feature `port' is that in our approach frequent patterns are represented by graph data structures whose nodes are hosts of the network and edges are alerts issued between two hosts. In addition, the source port is a highly unreliable feature (given the fact that the attacker can easily assign arbitrary values as source ports) and the value of destination port is not important in all types of attacks. In this way, some unrelated alerts might be correlated with each other in a single pattern accidentally. However, these patterns should not be seen frequently if the corresponding alerts are not actually related to each other. Therefore they are not reported as frequent patterns by a frequent mining technique. As mentioned later, the second component of the

Fig. 2 ­ Variants of attack patterns (DDoS).

computers & security 28 (2009) 153­173

157

Even though we model attack strategies by a graph data structure, a one-to-one mapping between hosts of the network and individual alerts to nodes and edges of the graph is not possible due to the possibility of generalization. For instance, in a one-to-many generalization, several target hosts will be mapped to a single virtual node in the generalized model. Candidate frequent patterns are represented by virtual graphs, whose nodes might be representative of several real hosts of the network and edges might be representative of a set of generalized alerts. In the following, we provide formal definitions for virtual node, virtual chain and virtual pattern. Definition 4. A Virtual Node, v, either corresponds to a single host h, or a set of hosts in the network that have been involved in one of the one-to-many, many-to-one, or many-to-many generalizations. Definition 5. A Virtual Chain, e, either corresponds to an individual alert A, or a set of alerts that have been involved in one of the one-to-many, many-to-one, or many-to-many generalizations. Definition 6. A Virtual Pattern (G, V, E) stands for the graph data structure G with a set of Virtual nodes, V, and a set of Virtual chains, E. A real-time correlation system should be able to construct the frequent patterns incrementally. Two issues should be dealt within this regard. First, how long a frequent pattern should be kept active (Keep_Active period ) for possible expansions? Secondly, how a newly received alert should be compared against current active patterns for possible expansion? We considered a fixed user-defined time window as the Keep_Active period of the patterns. A frequent pattern is considered stable if it has not changed (i.e. no new alert is added to the pattern) for a period longer than Keep_Active. Current active patterns in the system are checked periodically and are removed from the active pattern list if they are stable. Stable patterns are appended to a list of transactions and delivered to the next component of the framework for further processing. One efficient way of dealing with the second issue is using a hash table. The hash table provides the mapping between the IP addresses of real hosts and their corresponding virtual nodes in virtual patterns. Fig. 3 represents how a pattern in a real-world network is mapped to a virtual pattern through a hash table. When an alert A is received by the aggregator, it is hashed using its source and destination IP addresses as separate keys to the hash table (i.e. we query the hash table once with the source IP as the key and once with the destination IP). If the corresponding cells for both source and destination IPs in the hash table are empty, it means that none of the source and destination hosts are currently registered with a pattern in the system. In this case, a new pattern is created (which actually consists of just one alert) and is registered in the hash table with its source IP and destination IP as the keys. If a pattern is already registered in the hash table with corresponding cells to either source IP or destination IP, the

alert is absorbed by the registered pattern. The possibility of generalization (one-to-many, many-to-one and many-tomany) should be considered when a new alert is added to a pattern. In case a generalization is possible, a new virtual node is created and the lower-level virtual nodes will point to the new one. In the simplest case when generalization is not possible, just a new chain is added to the graph of the virtual pattern. When a pattern is active (i.e. has not become stable yet), the information of the actual pattern in the real-world network can be restored in full detail. This includes the information regarding the actual hosts that have been generalized into a virtual node and the actual alerts that have been generalized into a virtual chain. However, when a pattern becomes stable, only its signature (virtual graph) along with some supplementary information is stored in the system. The IPs involved in a pattern must be unregistered from the hash table when the pattern becomes stable and is removed from the active pattern list.

3.2.

Mining frequent graph structures

In our proposed approach for constructing candidate frequent patterns, transactions are created based on the connectivity information of the corresponding alerts. In this way, the constructed transactions, whether they are representative of attack scenarios or false positives, might include some additional steps that are not actually parts of the pattern. This might happen as a result of accidental co-occurrence of alerts within a time window. Statistical analysis of the candidate frequent patterns mitigates the mentioned problems by increasing the confidence of patterns based on a specified minimum co-occurrence. In this section, we propose a novel technique for incrementally mining frequent patterns and maintaining them in a reduced data structure (Pattern Tree). The resulting data structure not only represent the trend of the patterns seen in a protected network in multiple time granularities, but also provides a means for answering interesting queries about pattern co-occurrences. Our approach to mining frequent structures is based on the FP_Growth (Han et al., 2000) algorithm. FP_Growth makes use of FP_Tree, which provides a compact data structure for storing candidate frequent patterns. In this method, a scan of the database retrieves the list of frequent 1-itemsets, which are then sorted in descending order. This order is referred to as insertion order. Following that, the transactions that contain at least one frequent 1-itemset are inserted in the FP_Tree data structure based on the order of their items (higher frequency items are inserted first). Inserting the patterns based on the descending order of their frequencies gives frequent patterns better chances to share their prefix and as a result leads to a more compact data structure. Once the initial FP_Tree is constructed from the database, FP_Growth mines the frequent patterns recursively by adding one frequent 1-itemset at a time. Two main issues should be handled in using the FP_Tree data structure in mining frequent structured patterns. First, the structure of the graphs should be encoded linearly in the inserted transactions. Secondly, frequent patterns in each recursion level of the FP_Growth algorithm should be

158

computers & security 28 (2009) 153­173

Fig. 3 ­ Pattern hash table.

expanded by taking into account the connectivity information of a candidate 1-itemset to the current structured pattern. To address these issues, we propose the FSP_Tree (Frequent Structured Pattern Tree) data structure, which is extended from the FP_Tree, along with the FSP_Growth algorithm for mining frequent structured patterns from it.

3.2.1.

FSP_Tree

Each node n of an FSP_Tree corresponds to an edge e of the structured pattern. This mapping is represented by a function E: n / e. Each path from the root to a node n in an FSP_Tree is a linear encoding of a graph/subgraph. The set of nodes from root to node n in an FSP_Tree is represented by RootPath(n). RootPath(n,i) returns the node with depth i from the set RootPath(n). The connectivity information between nodes of a structured pattern is encoded in GraphInfo, for brevity referred to as GI, which is defined as follows: Definition 7. GraphInfo (n) consists of two arrays, corresponding to the source and the destination of node n, which encode the connectivity information of node n with its previous nodes from the root with respect to the corresponding structured pattern. More precisely, corresponding cells to source and destination arrays of GraphInfo(n, i) is set/reset based on the presence/absence of connectivity between the source and the destination of edges E(n) and E(RootPath(n, i)) in the corresponding structured pattern, respectively. Fig. 4 shows how connectivity information of a structured pattern is maintained in the nodes of the FSP_Tree. At every node of the tree with depth equal to or larger than 2, two sets of arrays are maintained that encode connectivity

information of that node with its previous nodes in the path from root. For instance, as shown in Fig. 4, the corresponding cell to source array of GraphInfo(d, 1) has value (1, D). This basically means that the source of node d is connected to the destination (referred to simply as D) of node a (the node with depth 1 in RootPath(d )). Like the FP_Growth algorithm, mining of frequent patterns is started with frequent 1-itemsets. At each recursion step, frequent patterns of length k are expanded using one candidate frequent 1-itemset. However, unlike FP_Growth, FSP_Growth selects the candidate 1-itemsets considering their connectivity pattern to k-itemsets. Definition 8. Basic_Graph(k), for brevity referred to as BG(k), represents the frequent graph structure that has been mined in recursion step k. BG(k, i) returns the node of BG(k) that was added to the graph in the step i of the expansion, i k. At recursion level k of FSP_Growth, the nodes of the FSP_Tree might be in one of the following states based on their relationships with BG(k): - Pending: is the state of a node that is waiting to be included in Basic_Graph - Belong: is the label of a node that belongs to BG(k). - Connected: is the state of a node that is connected to BG(k). These nodes might be selected for expansion in the following recursion steps. - Expanded: is the state of a node that has already been used for expansion, but currently does not belong to BG(k). A node is labeled as Expanded when a recursive call to its expansion ends.

computers & security 28 (2009) 153­173

159

Fig. 4 ­ GraphInfo structure for maintaining connectivity information of structured patterns.

Definition 9. Connectivity_List(n) is a local data structure of a connected node n that represents how it is connected to the current BG. It is basically a list of Connectivity_Info records. Each Connectivity_Info record represents the connectivity information of node n with BG(k, i), if they are connected. In order to keep track of connected nodes to the basic graph at each step of the FSP_Growth algorithm, we maintain a nodelink field in each connected node. Similar to the FP_Tree, the node-link field keeps a pointer to a node, but it points to the next connected node in the list (as opposed to the FP_Tree in which the node-link field points to a node of the same type). The headers of the node-link lists are maintained in a hash table structure, which is called Connected Header Hash Table (CHHT ). The reason for using a hash table instead of a fixedsize table (as it is used in FP_Tree) is that the number of connected nodes varies in different steps of the algorithm and maintaining them in a hash table is more efficient in terms of memory management. Based on the above terminologies and definitions, the following paragraph summarizes the similarities and differences between the FP_Tree and FSP_Tree data structures: ­ Both trees contain one root node whose item-name is null. ­ Each node of both trees contains item-name, frequency, childset, parent and node-link fields. Unlike FP_Tree, the node-link field in FSP_Tree points to the next connected node of the same type. ­ Each node n of the FSP_Tree (except the root and the nodes with depth 1) contains a field named GraphInfo, which encodes its connectivity information with respect to the nodes in the set RootPath(n). ­ Each node of the FSP_Tree stores its relation to BG in the field state. In addition, the Connectivity_List field encodes the connectivity information of connected nodes to BG. ­ Instead of a Header table, which keeps pointers to headers of node-link lists in the FP_Tree, each FSP_Tree maintains

a hash table called CHHT, which keeps pointers to headers of connected node-link lists. The process of constructing an FSP_Tree structure from a set G of structured patterns is as follows: ­ Scan the set G of structured patterns and construct the set F of frequent items together with the frequency of their occurrence in the set G. Sort the set F based on the descending frequency order of its items and remove the infrequent items based on a given minimum frequency, fmin. Remove the infrequent items from the structured patterns as well. ­ Create the root node of the tree and label its item as null. ­ For each structured pattern g in the set G, sort its items based on their descending frequency order and call InsertInFSPTree( g1, g Ŕ g1, root), where gi stands for the item with the rank i among g's items and g Ŕ g1 represents the remaining items of g. ­ The function InsertInFSPTree( gi, g Ŕ gi, ParentNode) is a recursive function which inserts the input structured pattern g (from item gi to the end) in the FSP_Tree starting from ParentNode as follows:  If ParentNode has a children node Ch, which matches with gi in terms of its item-name and its connectivity information with previous nodes in the the set RootPath(Ch), increment the frequency of Ch.  Otherwise, create a new node Ch with its frequency initialized to 1, its parent field pointing to ParentNode, and its GraphInfo field initialized with the connectivity information of gi with respect to its previous nodes. A link to the node Ch should be provided from the corresponding node-link list as well.  If g Ŕ gi is nonempty, call InsertInFSPTree( giţ1, g Ŕ gi Ŕ giţ1, Ch) recursively. Items that do not meet the minimum frequency threshold are removed from the input structured patterns and will not appear in the FSP_Tree. If removal of an infrequent item results in dividing a structured pattern into several components, each of these isolated patterns are inserted in the FSP_Tree separately.

3.2.2.

Mining frequent patterns using the FSP_Tree

We start describing the mining process used in FSP_Growth in the context of an example. Example 1. Fig. 5 (a) shows the initial FSP_Tree constructed from the structured patterns shown in Fig. 5(b). The goal is to mine all the frequent graph structures with a frequency larger than 3. The structured patterns are inserted in the FP_Tree based on their frequency order, which can be computed in a single pass traversal through the database. Item k does not appear in the initial FSP_Tree as it does not meet the minimum frequency. Similar to the FP_Tree, the remaining items are sorted based on their descending frequency orders in the CHHT. Unlike insertion order, mining frequent structured patterns starts with less frequent items. This ascending frequency order of mining is referred to as mining order. Therefore, frequent structures of example 1 are mined in the following order:

160

computers & security 28 (2009) 153­173

Fig. 5 ­ Example 1. (a) Initial structured patterns. (b) Initial FSP Tree.

-

Pn PmŔPn PfŔPnŔPm PdŔPfŔPnŔPm PcŔPdŔPfŔPnŔPm PbŔPcŔPdŔPfŔPnŔPm PaŔPbŔPcŔPdŔPfŔPnŔPm

where Px stands for the set of patterns that contain x and `Ŕ' stands for difference operation of sets (e.g. Pm Ŕ Pn represents the set of frequent patterns which include item m, but do not include item n). For node n, FSP_Growth returns (n:3) as a 1-itemset. For mining higher level itemsets, we notice that item n has three prefix paths in the FSP_Tree: C(a­b­c­d­f­m­n: 1), (a­b­c­f­m­n: 1), (a­c­d­n: 1)D. A new FSP_Tree is constructed based on the prefix patterns of item n, referred to as the conditional pattern base of n. Notice that item n appears in its conditional pattern base. This FSP_Tree is referred to as n's conditional FSP_Tree. The new FSP_Tree consists of one single path, as shown in Fig. 6(a). Since items d, f, and m do not meet the minimum frequency of 3, they are not inserted in n's conditional FSP_Tree. The mining process on this tree can be stopped since frequent structured patterns a and a­c can be easily mined from a single path using a depth-first search algorithm. Item c is not a frequent pattern since it is not directly connected to n. Considering the fact that these patterns are mined based on

a conditional FSP_Tree of n, the final patterns are constructed by merging these patterns with node n, as shown in Fig. 6(b). The mining process continues by selecting the next bottom item m from CHHT. First, the immediate frequent pattern (m:3) is reported as a 1-itemset. Constructing the conditional FSP_Tree of m from its conditional pattern base C(a­b­c­d­f­m: 1, a­b­c­f­m: 1, b­m: 1)D will lead to a single node b with frequency 3. The recursive call to m's conditional FSP_Tree will end with returning (m­b:3) as a frequent pattern. For item f, the conditional FSP_Tree will be constructed from C(a­b­c­d­f: 1, a­b­c­d­f: 1, a­b­c­f: 1)D. The resulting conditional FSP_Tree will be a single path (a­b­c:3). Again, the conditional mining process on the presence of f can be stopped at this step by returning all the frequent patterns {( f­ c:3, f­c­a:3, f­c­b:3, f­c­a­b:3)}. The immediate frequent pattern of item d is (d:3). The conditional FSP_Tree of d is constructed from three paths of the original tree leading to a node of type d, which includes C(a­ c­d: 1, a­c­d: 1, a­c­d: 1)D. The resulting tree is shown in Fig. 7. As a result, no frequent pattern can be mined in this step since the frequency of both paths is less than 3. For item c, a 1-itemset pattern set (c:4) is reported in the first step. The conditional FSP_Tree of c is constructed from its conditional pattern base C(a­b­c: 3, a­c: 1)D. As shown in Fig. 8, the resulting tree is recursively mined by selecting both of the connected items b and a. The order of selecting the connected items is based on their descending frequency ranks that are

Fig. 6 ­ Conditional FSP_Tree of item n (a) and Pn (b).

Fig. 7 ­ Conditional FSP_Tree of item d for Example 1.

computers & security 28 (2009) 153­173

161

Fig. 8 ­ Mining conditional FSP_Tree of item c for Example 1.

extracted from the CHHT. More precisely, two conditional FSP_Trees are constructed by calling ``mine(Ca­c: 4Djc:4)'' and ``mine(Ca­b­c: 3Djc:3)''. These functions refer to the recursive calls of the mining algorithm in the presence of node c given the conditional pattern base of c as an argument. Since the resulting FSP_Trees are single paths, the set of frequent patterns {(a­b­c:3), (b­c:3), (a­c:4)} can be reported without further recursive calls. We can easily verify that the algorithm returns the sets of frequent patterns {(b:4), (a­b:3)} and {(a:4)} when it selects items b and a for expansion, respectively. As mentioned earlier, items are selected for expanding current itemsets based on the connectivity of their respective nodes with the basic graph. If several items become connected to the basic graph in one step, the next item for expansion is selected based on its frequency order in the CHHT. The immediate result of this condition is that, unlike FPGrowth, nodes of the frequent itemsets are not necessarily separate components in the bottom of the tree. As shown in an example in Fig. 9, there is a gap between the nodes of the basic graph when the algorithm selects the next connected item for expansion. Assume that parts of structured patterns P1, P2 and P3 correspond to the left, middle and right branches of the FSP_Tree shown in Fig. 9 (this is not a complete example; only parts of the input structured patterns and FSP_Tree are shown

for the purpose of describing the gap between nodes in the FSP_Tree). Assuming that item d is part of the basic graph, item a is selected by the algorithm for expanding the basic graph even though it is not connected to node d in the FSP_Tree. Items b and c cannot be selected at this step since none of their respective nodes are connected to a node of type d in the respective input structure patterns (they become connected to the basic graph when more intermediate nodes are included). When a node becomes connected to the basic graph based on its relation with a lower-level node, its connectivity pattern might be different in different paths. For instance, a might be connected to the basic graph in the left a­b­d path and a­c­d path and disconnected from it in the right a­b­d path. As a result, the right a­b­d path does not contribute to the conditional pattern base for creating the higher level FSP_Tree when node a is used for expansion. This fact should be taken into account in creating the conditional pattern base. This example reflects another major difference between the FP_Growth and FSP_Growth mining algorithms. In FP_Tree, when item a is selected for expansion, the terminated node of all patterns in the conditional pattern base is always a node of type a. This is due to the absence of gaps. However, as shown in the FSP_Tree of Fig. 9, when node a becomes connected to the basic graph through node d, the conditional pattern base which is used in the next step would be as follows (given that the connectivity of node a to the basic graph is the same in the left a­b­d path and the a­c­d path): Cđa­b­dŢ; đa­c­dŢD: We make two adjustments based on this observation. First, the Connectivity_List of the original node a is passed to proxy node d. Furthermore, the connected node-link list for node a in CHHT will keep the pointers to proxy node d instead of node a. The following definition captures the abovementioned points. Definition 10.. When the node n becomes connected to the basic graph through the intermediate node i with a larger depth, the connectivity information of node n is delegated to node i. This information includes the terminated node for the corresponding transaction in the conditional pattern base, Connectivity_List field of node n and the node-link list which is kept in the CHHT for node n. We refer to node n as the original node and node i as the proxy node. The following example presents the execution of the FSP_Growth algorithm in the presence of original and proxy nodes. Example 2. Assume that we are looking for frequent patterns with minimum frequency 2 among the input structured patterns shown in Fig. 10. After constructing the initial FSP_Tree, the mining process continues by selecting item d (i.e. the item with the lowest frequency) and generates (d:4) as a 1-itemset pattern set. The conditional FSP_Tree of d, as shown in Fig. 11, is constructed from the conditional pattern base C(a­c­d: 1), (a­b­c­d: 2), (a­b­d: 1)D. At this step, both nodes a and b (original nodes) become connected to the basic graph (which consists of the single proxy node d ). Node b is selected for expansion based on its rank in the initial CHHT. Since the connectivity pattern of node b to the basic graph is different in the two paths leading to d, they are considered for possible

Fig. 9 ­ Possible gap between connected nodes in FSP_Growth algorithm.

162

computers & security 28 (2009) 153­173

Fig. 10 ­ Input structured patterns and Initial FSP ­Tree of example 2.

expansion separately. From these two paths, only the conditional pattern base C(a­b­c: 2)D leads to a new FSP_Tree (the conditional pattern base C(a­b­d: 1)D does not meet the minimum frequency 2). The resulting tree, as shown in the top right of Fig. 11, is a single path, and the frequent patterns {(d­ b:2), (d­b­a:2), (d­b­c:2), (d­b­a­c:2)} can be extracted from it without further recursion calls. When node a is selected for expansion as the next connected node in the conditional FSP_Tree of d, only conditional pattern base C(a­c­d: 1), (a­b­c­d: 2)D leads to an FSP_Tree as shown in the bottom right of Fig. 11 (conditional pattern base {(a­b­d:1)} does not meet the minimum

frequency condition). Again, the frequent patterns {(d­a:3), (d­a­c:3)} can be reported from a single path in the resulting FSP_Tree. The reason node b does not appear in the resulting tree is that it was used for expansion in the previous step and would be labeled as expanded afterwards. In this way, we avoid generating redundant patterns. Other frequent patterns are generated by the algorithm when items c, b, and a are selected for expansion. It is worth mentioning that nodes cannot be necessarily pruned from the bottom of the tree after they become part of the basic graph. The reason is that these nodes might be proxies for higher nodes, which still are not part of the basic graph. As a result, a proxy node can only be pruned from the tree when the status of the node itself and all of the original nodes referring to it change to belong. Algorithm 1 represents the high-level pseudocode of FSP_Growth. It is assumed that the algorithm is called with an initial FSP_Tree constructed from input structured patterns. The initial FSP_Tree is initialized with an empty BG and a CHHT that contains headers to the linked-list of all items (every node is assumed to be connected to an empty basic graph). At each recursion level, the algorithm selects the connected items to the basic graph based on their frequency order, which are computed in the initial traverse of the database. For each selected item, the current Tree is expanded using the selected item by calling function ExpandFSPTree. If the expanded tree consists of a single path, the mining process is handled through a simple Depth-first search on the corresponding graph. Otherwise, the mining process continues recursively on the expanded FSP_Tree. The final step of each recursion level is to label the recently added nodes to the basic graph as Expanded. The purpose is to avoid generating redundant patterns when the algorithm returns from a recursive call. Function ExpandFSPTree constructs a new FSP_Tree with an expanded basic graph and inserts the transactions of the conditional pattern base into it. The current FSP_Tree, the expanding item-name and the list of terminated nodes of the conditional pattern base are passed to this function as arguments. During expansion of the current FSP_Tree with a node, the connectivity information of nodes should be updated considering the new node, which subsequently becomes a member of the basic graph. The CHHT data structure should be updated accordingly. Each node in the list of terminated nodes (TNList) might either be an original node or a proxy node. If the latter is the case, the original node should be extracted from the proxy node and used for updating connectivity information of potentially connected nodes and the CHHT data structure. It is worth mentioning that the original node of a proxy node can be reached by following the parent nodes in the set RootPath of that proxy node. Moreover, the frequency of a frequent pattern (basic graph) at each recursion step is equal to the sum of the frequencies of terminated nodes (passed on to the function ExpandFSPTree through parameter TNList). Algorithm 1. (FSP_GROWTH(Tree, frequency)) Tree: FSP_Tree frequency: integer Initialize an iterator Itr for CHHT of Tree while Itr has more items

Fig. 11 ­ Mining conditional FSP_Tree of d in Example 2.

computers & security 28 (2009) 153­173

163

8 nextItem)Next candidate item for expansion returned > > > > > by Itr > > > > > TNList)List of terminate nodes returned by Itr > > > > > > < ExpFSPTree)ExpandFSPTreeđTree; nextItem; TNListŢ do if đExpFSPTree <> nullŢ > 8 > > > > > < if ExpFSPTree just consists of a single path > > > > then then GenPatternsByDFSđExpFSPTreeŢ > > > > : > > else FSP GrowthđExpFSPTree; frequencyŢ > > : Label the nodes of type nextItem as Expanded

Algorithm 2. (EXPANDFSPTree(Src_Tree, nextItem, TNList)) Src_Tree: FSP_Tree nextItem: Item TNList: TreeNode_List Create ExpTree as a new FSP_Tree and initialize its CHHT Expand Basic_Graph of ExpTree(i.e. ExpTree.BG ź SrcTree.BG ) nextltem) for each terminated node TN in TNList

The idea of mining time-sensitive data streams is proposed by Giannella et al. (Giannella et al., 2002). In this work, the frequency of patterns is updated incrementally within tiltedtime windows. Each tilted-time window basically contains time frames of multiple granularities. The design is based on the observation that people are often interested in recent changes at a fine granularity, but long term changes at a coarse granularity. An example of a tilted-time window is shown in Fig. 12. In this model, the frequencies of recent patterns, which occurred in the past quarter of an hour, are maintained at fine granularity while older patterns are kept at coarser granularities (i.e. hour and day). A Pattern tree combines the representation of frequent patterns with their time-sensitive information using tiltedtime windows. Each node in the pattern tree represents a pattern/sub_pattern (from root to this node). As shown in Fig. 13, a tilted-time window table is associated with each node of the pattern tree that maintains the frequency of the corresponding pattern along with other supplementary information. In the current design, we just included IP rankings in the supplementary information. However, other information of interest can be included with minor changes. The IP ranking

8 if TN is a proxy node > > > > then ON)original node of TN > > > > < else ON)TN do Insert PđSrc Tree; root Ŕ TN; ONŢ as a transaction in ExpTree > > > đPđSrc Tree; root Ŕ TN; ONŢstands for a path in Src Tree from root to TN considering ON as original nodeŢ > > > > Insert the nodes from SubTreeđSrc Tree; TNŢwhich are proxy for some nodes in the path PđSrc Tree; root Ŕ TNŢof ExpTree > : đSubTreeđSrc Tree; TNŢstands for the sub tree in Src Tree rooted at node TNŢ

Report the basic graph of ExpTree along with its frequency retrun (ExpTree)

3.3. Maintaining alert streams at multiple time granularities
Dealing with a stream of data poses several challenges on the analysis and management of interesting patterns within the data. The notion of frequency as the sign of a pattern's significance can be defined based on a time period in a fixed database of transactions. However, in applications with potentially infinite data streams, transactions are added continuously and the period in question can continue for a long time. Therefore, the concept of pattern significance should be defined in a way to capture the dynamic nature of data. In this section, we describe how the output of the proposed frequent structure mining technique (FSP_Growth) can be maintained incrementally in an efficient way. We adopt the framework proposed by Giannella et al. in (Giannella et al., 2002) to show: - how all the frequent patterns can be represented in a compact pattern tree data structure - how the frequency of patterns can be maintained in time windows with multiple time granularities to capture the trend of patterns - how the size of the pattern tree can be kept reasonably small

information is maintained in an IP Ranking table. This table maintains the most frequent pairs of (Source IP, Destination IP) that have contributed to creation of that pattern based on their descending frequency order. The number of rows of the table is bounded by a constant value of k. The structure of the pattern tree is similar to that of the FPS_Tree. The only difference is in the way they are used in two consecutive steps of the incremental frequent pattern mining framework (discussed in more detail later). In addition, the frequencies of patterns/sub_patterns in the pattern tree are the aggregated values computed by the FSP_Growth algorithm. In (Giannella et al., 2002), the frequency of an itemset I over a time period T is defined to be the number of transactions in T in which I occurs. The support of I is the frequency divided by the total number of transactions observed in T. Patterns are divided into three categories based on their frequency over a time period T, the minimum support s and the maximum support error 3. A pattern is: a) frequent if its support is not less than s; b) sub-frequent if its support is less than s, but not less than 3; and, c) infrequent, otherwise (s ! 3). The maximum

Fig. 12 ­ Sample tilted-time window (Giannella et al., 2002).

164

computers & security 28 (2009) 153­173

Fig. 13 ­ Pattern tree structure.

support error 3 represents the maximum tolerable error in the estimated frequency of items. Let t0, ., tn represent the tilted-time windows that have been seen so far in the data stream, where tn is the oldest one, and wi denote the window size of ti in terms of the number of transactions seen in (ti). The query to answer is to return all frequent itemsets whose support are larger than s over period T ź tk Wtkţ1 W.Wtk0 đ0 k k0 nŢ. This query can be answered precisely if all the tilted-time windows are maintained in all periods. However, this will require too much memory space. A pruning technique is proposed in Giannella et al., 2002 which provides an approximate frequency with a guaranteed upper bound error based on sub-frequent minimum support 3. More precisely, the following relationship can be guaranteed between the approximated frequency b f I đTŢ and the actual frequency fI(T ): fI đTŢ Ŕ 3W b f I đTŢ fI đTŢ; (1)

tail of the table and the tilted-time windows fI(t0), ., fI(tmŔ1) are maintained. ci; m i n; fI đti Ţ < swi and
i i X X Ŕ Á fI tj < 3 wj jź0 jź0

(2)

Figure 14 illustrates the incremental process of alert streams and maintaining them in the pattern tree. Stable transactions (candidate frequent patterns) are periodically passed to the Frequent Structure Mining component. This period depends on the rate of the events in the network in question and the smallest windows in which frequent patterns should be reported. Every batch of recent transactions is processed by the Frequent Structure Mining component and the running model ( pattern tree) is updated accordingly. First, a new FSP_Tree is constructed from the batch B of recent transactions. Following that, the FSP_Growth algorithm is executed with minor changes as follows: ­ For each mined itemset I (returned by the FSP_Growth algorithm), check if I is in the pattern tree. If I is in the pattern tree,  Add fI(B) in the tilted-time window table of I.  Prune the tail tilted-time windows for which condition 2 holds. If the tilted-time window table of I becomes empty after pruning, stop mining supersets of I (this is of type II pruning as explained in Giannella et al., 2002).

where W is the window size of the query (W ź wk ţ wkţ1 ţ . ţ wk0 ). The basic idea behind pruning is that when an itemset is not frequent in the recent tilted-time windows (it is either infrequent or sub-frequent), the corresponding windows are dropped from the tilted-time window table if the maximum error rate 3 is met. More precisely, the smallest m (0 m n) that meets the condition 2 is selected and tilted-time windows fI(tm), ., fI(tn) are dropped from the

Fig. 14 ­ Incremental mining architecture.

computers & security 28 (2009) 153­173

165

­ If I is not in the pattern tree and fI đBŢ ! 3jBj insert I in the tilted-time window table of I. Otherwise, stop mining supersets of I in FSP_Growth (this is of type I pruning as explained in Giannella et al., 2002). ­ Search the pattern tree (using the depth-first search algorithm). For each itemset I, check to see whether its corresponding node was updated in the last execution of FSP_Growth. If not, then insert 0 into the tilted-time window table for I and perform tail pruning. Consider the leaf nodes for dropping from the pattern tree when their tilted-time window table becomes empty. Note that non-leaf nodes might be candidates for pruning from the tree when all of their children are dropped. Including IP Ranking tables along with pattern frequencies involves the following changes:

transactions. Assuming that the size of the initial FSP_tree is k and the size of the largest discovered frequent pattern is s, the amount of the required memory for mining is bounded by k Â s. The reason for this analysis is that the deepest recursive call of the FSP_Growth algorithm is bounded by k and the size of each intermediate FSP_Tree is bounded by s. Therefore, the required space for mining an input alert dataset of size a is upper bounded by a Â s, which is linear in the size of the input dataset. Considering the fact that the FSP_Growth algorithm is called periodically to extract the latest statistics of the patterns, the size of input dataset (a) cannot become too large. This makes the space requirement of the mining algorithm manageable.

4.
­ An IP Ranking table should be maintained for each node of the FSP_Tree and each tilted-time window of the pattern tree. ­ AddNewPatternIPSetToTable(NewPatternIP, freq) function should be defined for inserting the IP set of a newly received transaction (NewPatternIP) with frequency value freq into the IP Ranking table of a node in the FSP_Tree as follows:  If the newly received IP set matches with the IP sets in the row i of the table, increase the frequency of this IP set by freq and call the function BubbleUP on the row i. This function changes the rank of a row in the table with respect to last update of its frequency to ensure that the rows of the table are sorted based on their descending frequency order.  Otherwise if the table is not full, insert the new IP set in the first empty row of the table with the initialized frequency value of freq and call the BubbleUP function on this row.  Otherwise if the table is full, decrease the frequencies of all rows of the table by an amount of freq. The goal is to give the chance to the new potential frequent IP sets to replace the existing ones. If the new frequency of the last row of the table becomes negative, replace the IP set of the last row with the new IP set, initialize its frequency to 0, and call the BubbleUP function on this row. ­ The function AggregateTwoTables(Table1, Table2) should be defined for merging two IP Ranking tables. This function can be easily implemented by inserting every row of one table along with its frequency in the other table using the function AddNewPatternIPSetToTable. Even though the proposed method for updating IP frequencies might not provide an exact frequency values for IP sets, it is fairly efficient for ranking IP sets. Moreover, it has the advantage of O(1) update time (given that the size of table is constant). The FSP_Growth algorithm constructs the FSP_tree from the input transactions and continues mining the frequent patterns using the resulting tree. The memory space required by the FSP_tree is smaller than the space required by the total number of transactions as a result of sharing the prefix (or whole) part of a sub-pattern/pattern between lots of input

Test and evaluation

In this chapter, we report the results of experiments performed for evaluating the proposed framework. We evaluated the proposed framework in three steps. Two sets of experiments were conducted for evaluating the main components of the framework separately. We used the DARPA 2000 dataset in order to test how complex attack scenarios are reconstructed by the aggregation component. The performance of the FSP_Growth algorithm was evaluated using an artificial random graph data generator. In addition, we replayed the alerts collected by Snort in Fred-eZone (The WiFi network provided by the City of Fredericton, NB, Canada) into our system in order to evaluate the proposed framework against alert logs of a real-world network.

4.1.

Experiment with the DARPA 2000 dataset

DARPA 2000 (MIT Lincoln Laboratory, 2000) is a well-known IDS evaluation dataset created by the MIT Lincoln Laboratory. It consists of two multistage attack scenarios, namely LLDDOS1.0 and LLDOS2.0. Both attack scenarios include a Distributed Denial of Service (DDoS) attack, with different stealth levels. The purpose of this experiment is to evaluate the ability of our method to reconstruct attack scenarios. To that end, we evaluate the Aggregation component of the proposed framework with the LLDOS1.0 attack scenario. The LLODS1.0 scenario can be divided into five phases as follows. - Phase 1: The attacker scans the network to determine which hosts are ``up''. - Phase 2: The attacker then uses the ``ping'' option of the sadmind exploit program to determine which of the hosts selected in Phase 1 are running the Sadmind service. - Phase 3: The attacker attempts the sadmind Remoteto-Root exploit several times in order to compromise the vulnerable machines. - Phase 4: The attacker uses telnet and rpc to install a DDoS program in the compromised machines. - Phase 5: The attacker telnets to the DDoS master machine and launches the mstream DDOS against the final victim of the attack.

166

computers & security 28 (2009) 153­173

We use the alert log file (Ning, 2007) generated by RealSecure IDS. This includes 922 alerts of 22 different types for the traffic corresponding to inside segment of the DARPA simulation network. Our proposed technique for Aggregation creates the patterns incrementally from the raw alerts and generalizes them based on the defined generalization types. As a result, the constructed patterns are virtual graphs whose nodes might represent several hosts within the network and edges might correspond to aggregated Hyper Alerts. Fig. 15 shows the virtual graph constructed by Aggregator when the raw alerts were fed into it sequentially. The mapping between host IPs and the nodes of the graphs is shown in Table 1. The attacker IP is mapped to node N18 in pattern A and Zombie machines are mapped to N20 in the same pattern. Most of the edges on the graphs correspond to hyper alerts. The steps launched by the attack can be followed from the created graphs: - Sadmind & Sadmind_Ping: Two one-to-many hyper alerts from node N18 to node N20 in pattern A. These hyper alerts correspond to the ping step from the attacker against several inside machines for detecting hosts running Sadmind (RealSecure issues two alerts for the probing step). - Email_Amslverify_Overflow: A one-to-many hyper alert which corresponds to exploit step of the attack. It is launched against three inside machines detected in the previous step. - Rsh: A many-to-one hyper alert from node N20 to node N18 in pattern A. It corresponds to communications between victim hosts (Zombie machines) and the attacker for

transferring Mstream_Zombie program to the compromised machines. ­ Rsh: A one-to-many hyper alert from node N18 to node N20 in pattern A. It corresponds to communications between the attacker and victim hosts (Zombie machines) for transferring MStream_Zombie program to the compromised machines. ­ TelnetTerminalType & TelnetXdisplay & TelnetEnvAll: Three single alerts from node N18 to node N20 in pattern A. These alerts are probably issued when the attacker tries to connect to the Zombie master through Telnet for launching DDoS attack. ­ MStream_Zombie: many-to-many hyper alert from node N20 to itself. This hyper alert corresponds to communications between Zombie machines before the actual DoS attack starts. The reason we see this hyper alert as a loop is that corresponding nodes have been generalized to one single node in the virtual graph. ­ Stream_DoS: single alert from node N0 to node N1 in pattern C. It corresponds to the last step of the attack in which the attacker uses compromised Zombie machines with spoofed IP addresses in order to flood his/her final target. There are some other alerts that are issued by RealSecure and are parts of the virtual graphs created by our method. This might be due to the background traffic of the network (which was labeled by the RealSecure network IDS as suspicious) and/ or unsuccessful steps taken on behalf of the attacker. As is shown in Fig. 15, the last step of the DDoS attack is isolated from the principal attack pattern (Pattern A) and

Fig. 15 ­ Created patterns for LLDDOS1.0.

computers & security 28 (2009) 153­173

167

Table 1 ­ Mappings between real IPs and virtual nodes. IP
135.008.060.182 172.016.112.010 172.016.112.050 172.016.112.100 172.016.112.149 172.016.112.207 172.016.113.050 172.016.113.084 172.016.113.105 172.016.113.148 172.016.113.204 172.016.115.020 194.007.248.153 195.115.218.108 196.227.033.189 197.218.177.069 255.255.255.255 202.077.162.213 205.254.240.185 209.075.005.250 208.216.182.015 135.013.216.191 194.027.251.021 195.073.151.050 196.037.075.158 197.182.091.233 172.016.112.194 172.016.113.207 078.111.082.041 131.084.001.031 100.202.139.115 172.016.112.020 172.016.112.255

(Pattern, Node)
(PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 20) (PatternA, 18) (PatternA, 17) (PatternA, 17) (PatternA, 21) (PatternB, 0) (PatternB, 0) (PatternB, 0) (PatternB, 0) (PatternB, 0) (PatternB, 1) (PatternB, 1) (PatternC, 0) (PatternC, 1) (PatternC, 2) (PatternD, 0) (PatternD, 1)

Description
Client Zombie Client Zombie

Master Zombie

source node, and destination node in the virtual graphs, respectively. The results of experiments show that the proposed technique is successful at providing an abstract signature from a complex attack scenario and at reducing the number of alerts significantly. The number of raw alerts issued initially by RealSecure is reduced from 922 to 29 single or hyper alerts in the generalized patterns (the number of edge labels reported in Fig. 15). This corresponds to a reduction ratio of đ922 Ŕ 29Ţ=922x96%. Even though we loose some details as a result of generalization (e.g. client and server Zombie machines are mapped to one virtual node), the basic semantics of the attack scenario are preserved.

4.2.

Experiments with synthetic datasets

Attacker

The purpose of this experiment is to evaluate the performance of the FSP_Growth algorithm in terms of its time complexity. A sample evaluation model was proposed in (Agrawal and Srikant, 1994) for basket data mining and was adopted for evaluating graph mining algorithms in (Kuramochi and Karypis, 2001). We use a similar model for generating synthetic graphs with minor changes. The synthetic graph generator is controlled by the following 5 parameters: (i) jDj: The total number of graphs. (ii) jTj: The average size of graphs (in terms of the number of edges). (iii) jIj: The average size of potentially frequent subgraphs (in terms of the number of edges). (iv) jLj: The number of potentially frequent subgraphs. (v) jNj: The number of labels (for edges). The synthetic graph generator works as follows. First, a set of jLj potentially frequent directed subgraphs is generated. We create a label set N, which serves as the label pool for edges of the graphs. The size of each frequent subgraph is determined by a Poisson distribution with mean I. The topology and edge labels of each frequent graph are selected randomly (i.e. to expand a frequent subgraph, a random label

Spoofed IP for flooding Final Target

creates a separate pattern (Pattern C ). The reason for this is that a spoofed IP address is used for the flooding step. This is a well-known problem in the area of alert correlation and has been reported by some previous works (Zhu and Ghorbani, 2006). One way to handle this problem is to analyze statistical relationships between structured patterns based on their time differences. The idea is to relate the structured patterns with each other based on a weak correlation relationship. The value of a weak correlation can be defined based on a function of the time difference between creation of structured patterns. The value of a weak correlation is updated based on the future occurrences of the structured patterns and is considered to be a strong correlation if two structured patterns were seen together several times within a short time interval. It is worthy of mention that detailed information regarding raw alerts contributing to a hyper alert can be extracted when the corresponding structured pattern is active. This information includes the source IP, destination IP, source port, destination port, timestamp and other information provided by the low-level sensors. When a structured pattern becomes stable, detailed information are dropped and only the signature of the pattern along with its supplementary information is maintained. Table 2 shows detailed information of the Sadmind_Amslverify_Overflow*< hyper alert. The triples (-,-,-) in the caption of this table stands for the type of the hyper alerts,

Table 2 ­ (Sadmind_Amslverify_Overflow*<, N18, N20). Source IP
202.077.162.213 ź ź ź ź ź ź ź ź ź ź ź ź ź

Dest IP
172.016.115.020 172.016.115.020 172.016.115.020 172.016.115.020 172.016.115.020 172.016.115.020 172.016.112.010 172.016.112.010 172.016.112.010 172.016.112.010 172.016.112.050 172.016.112.050 172.016.112.050 172.016.112.050

Source Port
60,251 60,255 60,269 60,276 60,289 60,300 60,519 60,524 60,542 60,549 60,569 60,578 60,605 60,619

Dest Port
32,773 32,773 32,773 32,773 32,773 32,773 32,774 32,774 32,774 32,774 32,773 32,773 32,773 32,773

168

computers & security 28 (2009) 153­173

Table 3 ­ Different settings used for generating synthetic structured patterns. Parameter
jDj jTj jIj jLj

Value
10,000; 20,000; 30,000; 40,000; 50,000; 60,000 5, 10, 15 3, 5 200

is selected from the pool of labels and its source and destination are determined randomly considering the connectivity limitation that the newly added edge should be connected to the pattern from at least one of its sides). Moreover, a weight is assigned to each potentially frequent subgraph, which represents the probability of its inclusion in a transaction. The weights are determined by an Exponential distribution with mean one. At the end, the generated weights for all frequent graphs are normalized to 1. This set of jLj potentially frequent graphs is called the seed pool, which would serve as a pool for selecting a frequent pattern and adding it to a transaction. In the next step, a set of jDj transactions is created as follows. First, a Poisson distribution of mean T is queried to determine the size ST of the next transaction. Following that,

we start constructing a transaction of size ST by selecting potentially frequent subgraphs from the seed pool and adding them to the transaction. The probability of selecting a frequent subgraph is determined based on the assigned weights. A newly selected frequent subgraph is added to the current transaction (which has been constructed so far) so that the last node of the current transaction merges with the first node of the frequent subgraph. If including the selected seed will lead to a transaction larger than ST, we add it to the transaction for half of the cases, and discard it (and move onto the next transaction) for the other half. We conducted a set of experiments in order to evaluate the effect of the size of the database on the running time of the algorithm. The experiments are conducted with different parameter settings as shown in Table 3. The labels are selected from a label pool of size 100. For each parameter setting, 10 different instances of datasets are created and the performance of the algorithm is reported based on the average of 10 trials. Since the performance of the algorithm depends on the number of reported frequent structures, we exclude the trials that returned significantly more frequent patterns compared to the average number of frequent patterns. The reason for excluding these trials is to make a fair comparison between the average running times of trials. The support

Fig. 16 ­ Runtime and number of reported patterns vs. database size.

computers & security 28 (2009) 153­173

169

Fig. 17 ­ Runtime and number of reported patterns vs. database size.

value was set to 0.5% for all experiments (i.e. structures are considered as frequent if they appear in at least 0.5% of the structured patterns). All the experiments were performed on a 1.86 GHz Intel Xeon machine with 2 GB main memory running the Ubuntu operating system.

Fig. 16(a) shows the results of experiments for the parameter setting (jLj,jTj,jIj) ź (200,10,3) (for brevity referred to as EX_200_10_3). In this figure, axes X and Y represent the size of the database and the time in seconds, respectively, and solid and dash­dot­dot lines represent the mining time

Fig. 18 ­ Extracted patterns in the first day (length( pattern)  2).

170

computers & security 28 (2009) 153­173

and the insertions time, respectively (insertion time includes the time required for creating the initial FSP_Tree). The average number of reported patterns for experiments with different database sizes is shown in the right curve of Fig. 16(a). It is seen from the figures that both the mining time and the insertion time roughly scale linearly with the size of the database. The behavior of the algorithm should be analyzed by taking the average number of reported patterns into account. This effect can be verified in Fig. 16(a). The running time of the algorithm increases with a lower rate at points 30,000 and 60,000, which correspond to the dropping points in the number of reported patterns in the right curve of Fig. 16(a). The results of experiments with other parameter settings are shown in Figs. 21 and 17. Each row in these figures corresponds to results of a different parameter setting.

Figures 18­20 show the extracted patterns from the alert logs after the first day, first week and first month, respectively. To avoid redundancy, only the emerging patterns of each pattern tree are shown in the figures (i.e. patterns that were not in the pattern tree of the previous snapshot). In addition, we exclude the patterns of length one that were not correlated with other alerts. In these figures, nodes correspond to a host (or a set of hosts in case of generalization) and edges correspond to single or hyper alerts issued between hosts. The text labels belong to edges and represent the high-level attack classes. Moreover, notations *>, *< and *ź stand for generalized hyper alerts as discussed earlier. Among the extracted patterns, some well-known attack patterns such as (i) Buffer Overflow*< / Worm Active*< (ii) Host Query*< / ICMP Reconnaissance*< / Buffer Overflow*< are mixed with other unknown patterns such as IP Fragmentation*< / Privilege Escalation Failed*< / Suspicious U sername*< whose descriptions require further investigation. Figure 21 (a) and (b) represent the size of pattern tree in terms of the number of nodes and number of tilted-time windows in different days, respectively. As it is seen in the figures, the size of tree increases within the first two weeks of the month and becomes more stable after that. These results are expectable as the number of emerging patterns is more than disappearing patterns at first, but they will compensate for each other after a while. The only exception is a sharp decrease in the number of tilted-time windows in day 24. Further investigation of alert logs showed us that no alerts were received for a period of around one day from the beginning of the day 23. This resulted in the decrease in the number of hourly tiltedtime windows for most of the persisting patterns in the next day (day 24) that the stream of alerts was resumed. In our experiments, although the frequent and subfrequent thresholds are set to very small values (0.15 and 0.05, respectively), the size of the pattern tree becomes stable while containing nearly 1000 tilted-time windows, which makes it easily manageable in the main memory. It takes our system around 8 min to process a stream of alerts for one month, which contains 3,208,788 raw alerts. This will amount to a throughput of 401,098 number of alerts in one minute, which is much more than the alert throughput in large-scale networks.2 Considering the fact that the Frequent Structure Mining component is the bottleneck of the framework and given the linearly scalable running time of the FSP_Growth algorithm with the size of the database, the proposed framework can cope with the alert throughput of large-scale networks as well. Note that each node in the pattern tree encodes the connectivity information of that node to its previous nodes in the path from the root in addition to the tilted-time window table. We use this information to reconstruct the patterns stored in the tree. The size of the pattern tree is controlled
2 Having discussed it with network security experts, we believe that the alert throughput in large-scale networks is less than 10,000 per minute.

4.3.

Experiments with a real-world dataset

The purpose of this experiment is to test the proposed framework with a real-world stream of alerts. It allows us to see how the proposed technique can extract interesting patterns from a long history of alerts and summarize them in a reduced data structure. To that end, we used alert logs collected by a Snort box in the Fred-eZone. The logs include 3,208,788 raw alerts within a period of one month.

4.3.1.

Experiment setup

We normalized the raw alerts received from the City of Fredericton using QRadarŞ (a Security Information Management product provided by Q1Labs Inc.1). During normalization, attack classes that are reported by Snort are mapped to highlevel categories of events. We used this high-level Category Description along with Source IP, Destination IP, and Device Date/ Time attributes of the normalized alerts. We replayed the alert logs into our system using a simple Alert Log Scanner. The alerts are received by the correlation framework one by one and the current time of the system is changed accordingly. The alerts are processed using the following parameters: - Keep_Active is set to 60 s, which basically means that patterns are assumed to be stable if they are not changed for a period longer than 60 s. - The value of Mining Interval is set to 15 min (i.e. stable patterns are mined every 15 min and the pattern tree structure is updated accordingly). - The values of s (minimum support) and 3 (maximum support error) are set to 0.15 and 0.05, respectively.

4.3.2.

Experimental results

Since the pattern tree data structure and its tilted-time windows are the main output of our system, we analyze the snapshots taken from the pattern tree at different time spots within a one-month interval. These time spots include the end of the first day, the end of the first week and the end of the month.
1

http://www.q1labs.com/.

computers & security 28 (2009) 153­173

171

Fig. 19 ­ Extracted patterns in the first week (length( pattern)  2).

through a pruning mechanism as described in Chapter 3. The pruning mechanism drops the tilted-time windows (and nodes of the tree accordingly) which become infrequent considering the latest transactions. The pruning facility along with automatic summarization of tilted-time windows of old

transactions makes the pattern tree an efficient data structure for maintaining frequent patterns. Maintaining the alert stream in the pattern tree not only reflects the latest trends of patterns, but also provides a means for answering some time-sensitive interesting queries

Fig. 20 ­ Extracted patterns in first month (length( pattern)  2).

172

computers & security 28 (2009) 153­173

Fig. 21 ­ Size of the pattern tree in different days. (a) Number of nodes of the pattern tree in different days. (b) Number of tilted-time windows of pattern tree in different days.

regarding alert co-occurrences. For instance, the following queries can be answered efficiently using the pattern tree: - Which alerts co-occurred with one-to-many hyper alert Network Sweep*< in day d. - Which alerts co-occurred in hour h with an arbitrary pattern p (e.g. Network Sweep*< / Web Exploit*<). - Return the tilted-time windows in which pattern p occurred with support s1, where s1 >ź s (s1 is the specified support in the query and s is the support of the incremental mining framework).

5.

Conclusions and future work

In this paper, we proposed a framework for real-time analysis of intrusion alerts. The framework consists of three components. A stream of alerts is received continuously by the Aggregator and structured patterns are created from alerts based on their source and/or destination host connectivity. Several generalization rules were proposed for refining the constructed patterns and generating an abstract signature from them. The proposed generalization rules not only reduce the size of the constructed patterns, but also allow us to detect similarities between different compositions of patterns. The concept of stability of patterns was introduced and used for creating dynamic transactions of alerts from the stream data. The signature of stable patterns are mined periodically by a frequent structured pattern mining technique (FSP_Growth) and the running model of the framework ( pattern tree) is updated accordingly. Reporting the constructed patterns along with their structures and other supplementary information makes analysis of patterns easier for the security administrator. Maintaining the frequent patterns of alerts in the pattern tree not only reflects the latest trends of patterns, but also provides a means for answering interesting time-sensitive queries. This would be beneficial to the security administrator in two ways. First, automatically extracted patterns provide the security administrator with a reduced view of the most significant patterns of alerts in the network. This view is helpful in detecting new attack scenarios launched against the network and reducing the number of alerts by filtering the false positive ones. Secondly, the security administrator can issue queries on the pattern tree for further analysis of patterns. Moreover, the pattern tree is an efficient data

structure in terms of memory management with summarizing older patterns in coarser tilted-time windows and pruning infrequent patterns (i.e. patterns that were frequent in the past, but no longer are frequent) with a guaranteed upper bound error in frequencies. The proposed framework and algorithms were implemented and evaluated in several aspects. We used the DARPA 2000 dataset to evaluate our proposed technique for constructing and generalizing attack scenarios. The results of experiments on DDOS1.0 show that the reconstructed attack scenario represents the main logic of the attack (though the last step of the attack is isolated from the whole scenario) with a promising reduction ratio of 96%. An artificial graph data generator was developed in order to evaluate the performance of the FSP_Growth algorithm in terms of its running time. The results of experiments with artificial datasets show that the proposed algorithm roughly scales linearly with the size of the database. We also evaluated the proposed framework with alert logs collected by Snort in a real-world network. The experiments show that the proposed framework cannot only cope with the throughput of a large-scale network, but also is efficient in terms of memory requirements for maintaining the pattern tree. Analyzing the patterns of the tree shows the presence of some well-known attack patterns along with some other unknown suspicious patterns in the alert logs. A few extensions to the proposed work are summarized in the following: Alerts that contribute to a pattern with correlation with other alerts are less likely to be false positives. Even though the proposed framework provides a means for analyzing false positive alerts (roughly speaking the attack probability of patterns will increase with their lengths), the stored pattern tree might include some false positive alerts (the leaf nodes with depth 1, in particular). Therefore, a useful improvement to the proposed framework is to add a component responsible for filtering the false positive alerts. This would increase the purity of the pattern tree significantly. Reconstructing slowly developing attacks is a difficult task for correlation systems since almost all of them incorporate the time difference between alerts in correlating them. Choosing a large value as the time threshold allows us to find relationships between alerts of these slowly developing attacks, but increases the false positive correlations in turn. Developing techniques for correlating alerts with adaptive time windows (which works well for different types of attacks) is an interesting line of research.

computers & security 28 (2009) 153­173

173

As discussed earlier, complete attack scenarios might be divided into two or more isolated patterns if intermediate attack steps are missed by low-level sensors and/or some steps of attacks are launched using spoofed IP addresses. Developing techniques to find relationships between isolated patterns and merge them into one scenario would facilitate interpretation of the results for the administrator.

references

Agrawal Rakesh, Srikant Ramakrishnan. Fast algorithms for mining association rules in large databases, VLDB '94. In: Proceedings of the 20th international conference on very large data bases. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.; 1994. p. 487­99. Cheung S, Lindqvist U, Fong MW. Modeling multistep cyber attacks for scenario recognition. In: DARPA Information Survivability Conference and Exposition, vol. 1. IEEE; April 2003. p. 284­92. Cuppens F, Miege A. Alert correlation in a cooperative intrusion detection framework, security and privacy, 2002. In: Proceedings. 2002 IEEE symposium. IEEE; 2002. p. 202­15. Cuppens F, Ortalo Rodolphe. Lambda: a language to model a database for detection of attacks. In: Debar H, LM, Wu SF, editors. Proceedings of recent advances in intrusion detection, 3rd international symposium, (RAID 2000). Lecture Notes in Computer Science, vol. 1907. Toulouse, France: SpringerVerlag Heidelberg; October 2000. p. 197­216. Eckmann S, Vigna G, Kemmerer R. Statl: an attack language for state-based intrusion detection; 2002. p. 71­103. Giannella C, Han J, Pei J, Yan X, Yu P. Mining frequent patterns in data streams at multiple time granularities. In: Proceedings of the NSF Workshop on Next Generation Data Mining; 2002. Han Jiawei, Pei Jian, Yin Yiwen. Mining frequent patterns without candidate generation, SIGMOD '00. In: Proceedings of the 2000 ACM SIGMOD international conference on management of data. New York, NY, USA: ACM Press; 2000. p. 1­12. Julisch Klaus. Clustering intrusion detection alarms to support root cause analysis. ACM Transactions on Information and System Security 2003;6(4):443­71. Kuramochi Michihiro, Karypis George. Frequent subgraph discovery, ICDM '01. In: Proceedings of the 2001 IEEE international conference on data mining. Washington, DC, USA: IEEE Computer Society; 2001. p. 313­20. Manganaris Stefanos, Christensen Marvin, Zerkle Dan, Hermiz Keith. A data mining analysis of rtid alarms. Comput Networks 2000;34(4):571­7. MIT Lincoln Laboratory. 2000 darpa intrusion detection scenario specific data sets. Available from: http://www.ll.mit.edu/IST/ ideval/data/2000/2000_data_index.html; 2000 [accessed 09.07.07]. Ning Peng, Cui Yun, Reeves Douglas S. Constructing attack scenarios through correlation of intrusion alerts. In: Proceedings of the 9th ACM conference on computer and communication security. Washington DC, USA: ACM Press; November 2002. p. 245­54. Ning P. TIAA: a toolkit for intrusion alert analysis. Available from: http://discovery.csc.ncsu.edu/software/correlator/; 2007 [accessed 28.05.07]. Pietraszek Tadeusz. Using adaptive alert classification to reduce false positives in intrusion detection. In: 21st century military communications conference proceedings, vol. 1. IEEE; Oct 2004. p. 440­3. Qin Xinzhou, Lee Wenke. Statistical causality analysis of infosec alert data. In: Vigna G, Jonsson E, Kruegel C, editors.

Proceedings of recent advances in intrusion detection, 6th international symposium, (RAID 2003). Lecture Notes in Computer Science, vol. 2820. Pittsburgh, PA, USA: SpringerVerlag Heidelberg; September 2003. p. 73­93. Qin Xinzhou. A probabilistic-based framework for infosec alert correlation, Ph.D. thesis, Georgia Institute of Technology; 2005. Svensson H, Josang A. Correlation of intrusion alarms with subjective logic. In: Proceedings of the sixth Nordic workshop on secure IT systems (NordSec2001). Denmark: Copenhagen; November 2001. Templeton Steven J, Levitt Karl. A requires/provides model for computer attacks, NSPW '00. In: Proceedings of the 2000 workshop on new security paradigms. New York, NY, USA: ACM Press; 2000. p. 31­8. ´ Ludovic. A language driven ids for Totel Eric, Vivinis Bernard, Me event and alert correlation. SEC; 2004. p. 209­24. Valdes Alfonso, Skinner Keith. Probabilistic alert correlation. In: Lee WLM, Wespi A, editors. Proceedings of recent advances in intrusion detection, 4th international symposium, (RAID 2001). Lecture Notes in Computer Science, vol. 3089. Davis, CA, USA: Springer-Verlag Heidelberg; October 2001. p. 54­68. Zhai Yan, Ning Peng, Iyer Purush, Reeves Douglas S. Reasoning about complementary intrusion evidence, ACSAC '04. In: Proceedings of the 20th annual computer security applications conference (ACSAC'04). Washington, DC, USA: IEEE Computer Society; 2004. p. 39­48. Zhu Bin, Ghorbani Ali A. Alert correlation for extracting attack strategies. International Journal of Network Security 2006;3(2): 244­58.

Reza Sadoddin received his MSc in Computer Science from the University of New Brunswick, Fredericton-Canada in 2007. He received his B.Eng (2003) in Computer Software Engineering from Sharif University of Technology, Tehran-Iran in 2003. He has the experience of software application development in Nebras Informatics Inc. (2000­2003) and Kavoshcom Asia company (2003­2005), Tehran-Iran. In the meantime, he did research in the area of Network Vulnerability Analysis and Network Intrusion Detection in Sharif Network Security Center, Tehran-Iran (2004­2005). He is currently a PhD student in the department of Computing Science in University of Alberta, Edmonton-Canada (From 2007). His research interests include Data Mining and Machine Learning, Data warehousing and Database Systems, Network Intrusion Detection, and Graph Theory. Dr. Ali A. Ghorbani is currently a Professor and Dean at the University of New Brunswick (UNB), Canada. His current research focus is on web intelligence, network security, complex adaptive systems, critical infrastructure protection, and Trust & Security assurance. He is the Director of Information Security Center of Excellence and the coordinator of the Privacy, Security, and Trust (PST) network annual conferences. Dr. Ghorbani has supervised numerous postdoctoral fellows and graduate students to advance the state of threat detection algorithms, attack simulation, correlation techniques, network application discovery, and critical infrastructure protection. He holds UNB Research Scholar position and is coEditor-in-Chief of the Computational Intelligence, an International Journal, Associate Editor of International Journal of Information Technology and Web Engineering. Dr. Ghorbani is a member of ACM, IEEE, IEEE Computer Society, and CSCSI.

