Enhanced Correlation in an Intrusion Detection Process
Salem Benferhat1 , Fabien Autrel2 , and Fr´ ed´ eric Cuppens3
CRIL CNRS Universit´ e d'Artois Rue Jean Souvraz SP 18 F 62307, Lens Cedex, France 2 ONERA-CERT, 2 Av. E. Belin, 31055 Toulouse Cedex, France 3 IRIT, 118 route de Narbonne, 31062 Toulouse Cedex, France benferhat@cril.univ-artois.fr, autrel@cert.fr, cuppens@irit.fr
1

Abstract. Generally, the intruder must perform several actions, organized in an intrusion scenario, to achieve his or her malicious objective. Actions are represented by their pre and post conditions, which are a set of logical predicates or negations of predicates. Pre conditions of an action correspond to conditions the system's state must satisfy to perform the action. Post conditions correspond to the effects of executing the action on the system's state. When an intruder begins his intrusion, we can deduce, from the alerts generated by IDSs, several possible scenarios, by correlating attacks, that leads to multiple intrusion objectives. However, with no further analysis, we are not able to decide which are the most plausible ones among those possible scenarios. We propose in this paper to define an order over the possible scenarios by weighting the correlation relations between successive attacks composing the scenarios. These weights reflect to what level executing some actions are necessary to execute some action B . We will see that to be satisfactory, the comparison operator between two scenarios must satisfy some properties.

1

Introduction

The main objective of computer security is to design and develop computer systems that conform to the specification of a security policy. A security policy is a set of rules that specify the authorizations, prohibitions and obligations of agents (including both users and applications) that can access to the computer system. An intruder (also called hacker or cracker) might be viewed as a malicious agent that tries to violate the security policy. Thus, an intrusion is informally defined as a deliberate attempt to violate the security policy. Sometimes the intruder might perform his intrusion by using a single action. For instance, performing a deny of service using the ping of death attack simply requires sending a too long IP packet. However, more complex intrusions generally require several steps to be performed [9,6,7]. For instance, let us consider the Mitnick attack. There are two steps in this attack. In the first step, the intruder floods a given host H . Then the intruder sends spoofed SYN messages
V. Gorodetsky et al. (Eds.): MMM-ACNS 2003, LNCS 2776, pp. 157­170, 2003. c Springer-Verlag Berlin Heidelberg 2003 

158

S. Benferhat, F. Autrel, and F. Cuppens

corresponding to H address to establish a TCP connection with a given server S . When S sends a SYN-ACK message, H would normally send a RESET message to close the connection. But this is not possible since H is flooded. This enables the intruder to send an ACK message to illegally open a connection with S . Notice also that opening a TCP connection with S is probably not the intruder's final objective. It is likely that the intruder will then attempt to get an access on S for instance by performing a rlogin. This means that the Mitnick attack will actually represent preliminary steps of a more global intrusion. In the following, we shall call intrusion scenario the complete sequence of actions that enables the intruder to achieve his intrusion objective. In [1,2] a notion of attack correlation, which allows to recognize various steps of an intrusion scenario, has been defined. Then an approach, based on attack correlation, which recognizes if a sequence of correlated actions can lead to an intrusion objective (malicious intention recognition) has been developped. This approach allows to build a set of possible scenario instances compatible with observations generated by IDSs. The proposed approach in [1,2] is not satisfactory. Indeed, the number of possible scenarios can be high, and no additional information is provided to the system administrator to distinguish between the most plausible scenarios and the less plausible ones. This paper proposes a new approach to alert correlation which allows to rank order different possible scenarios. We first enrich the representation of action by also considering the detection time of each action. We distinguish two kinds of influence relations between two actions: ­ positive influence relation where the realisation of an action A may lead to the realisation of an action B . ­ negative influence relation where the realisation of action A blocks the realisation of B Then, we associate with each action A a weight which represents the plausibility of realisation of action A, given the fact that some actions (which may directly influence A) have been achieved. These weights will allow us to compare and rank-order different scenarios. The rest of this paper is organized as follows. Section 2 introduces the representation of actions and scenarios. These representations are simple extensions of those used in [1] taking into account the notion of detection time. Section 3 presents an example and illustrates the need for defining methods to limit the number of possible scenarios. Section 4 presents the weighted correlation approach.

2

Modelling the Intrusion

In order to model the intrusion process, we extend the material defined in [1]. We consider that the intruder can use a set of actions to achieve his intrusion objective, more precisely he must find a subset of actions that allows him to

Enhanced Correlation in an Intrusion Detection Process

159

reach a system state where the security policy is violated, i.e where the intrusion objective is reached. We assume that we have a set of actions that an intruder can execute, and a set of intrusion objectives to be protected. Intrusion detection systems (IDSs) produce alerts which correspond to instanciated attacks. Our aim is to see if there are sequences of instanciated attacks, called scenarios, which allows to reach an intrusion objective. The following subsections first gives the representation of actions and intrusion objectives, then defines the notions of action correlation and intrusion scenarios. 2.1 Representing Actions

In [1], actions are represented by their pre and post conditions. Pre conditions of an action represent the state the system must satisfy in order to be able to execute the action. Post condition expresses the effects of the action over the system state. Discovering correlation links among a set of actions often involve the time where these actions are detected. Indeed, in practice we deal with time-stamped alerts, associated with attacks, that are totally ordered. The order over a set of alerts is imposed by the intruder who is doing the intrusion. We propose to augment the action model by adding the time-stamp which represents the time where the action has been detected. Definition 1: Action Modelisation. An action A is modelled using four fields: ­ N ame(P aram1 , P aram2 , ..., P aramn ): a functionnal expression representing the name of the action and its parameters ­ DetectTime: the timestamp at which the action has been detected ­ Pre condition: conjunction of predicates the system's state must satisfy in order to be able to execute the action. ­ Post condition: conjunction of predicates expressing the effects of the action over the system's state. From now DetectT ime(Actioni ) designates the timestamp of an action's instance. P re(Actioni ) and P ost(Actioni ) designate respectively the action's pre conditions and post conditions. Fig. 1 shows examples of action modelisations, which will be used later to define scenarios. 2.2 Representing Intrusion Objectives

Intrusion objectives are modelled by a condition over the system's state. Definition 2: Intrusion Objective Modelisation. An intrusion objective O is modelled using two fields:

160

S. Benferhat, F. Autrel, and F. Cuppens Action touch(Agent, F ile) Detectime: timestamp Pre: OperatingSystem(OS ) Post: f ile(F ile), authorized(Agent, read, F ile), authorized(Agent, write, F ile) Action block(Agent, P rinter) Detectime: timestamp Pre: printer(P rinter), physical access(Agent, P rinter), not(blocked(P rinter)) Post: blocked(P rinter) Action lpr -s(Agent, P rinter, F ile) Detectime: timestamp Pre: printer(P rinter), f ile(F ile), authorized(Agent, read, F ile), OperatingSystem(OS ) Post: queued(F ile, P rinter) Action remove(Agent, F ile) Detectime: timestamp Pre: authorized(Agent, write, F ile), f ile(F ile) Post: not (f ile(F ile)) Action ln -s(Agent, Link, F ile) Detectime: timestamp Pre: not (f ile(Link)) OperatingSystem(OS ) Post: linked(Link, F ile) f ile(F ile) Action unblock(Agent, P rinter) Detectime: timestamp Pre: printer(P rinter), blocked(P rinter), physical access(Agent, P rinter) Post: not (blocked(P rinter)) Action print-process(P rinter, Link) Detectime: timestamp Pre: queued(Link, P rinter), linked(Link, F ile), not (blocked(P rinter)) Post: printed(P rinter, F ile), not (queued(Link, P rinter)) Action get-f ile(Agent, F ile, P rinter) Detectime: timestamp Pre: printed(P rinter, F ile), physical access(Agent, P rinter) Post: read access(Agent, F ile) Fig. 1. Definition of actions used in the illegal file access scenario

Enhanced Correlation in an Intrusion Detection Process

161

­ N ame(P aram1 , P aram2 , ..., P aramn ): a functionnal expression representing the name of the objective and its parameters ­ StateCondition: conjunction of predicates the system's state verify when the objective is reached. For example the intrusion objective DOS on DN S (Host) is reached when the two following predicates are satisfied: dns server(Host) and dos(Host). They signify respectively that Host is a DNS server and that Host is not available. Fig. 2 shows another example of intrusion objective modeling. The intrusion objective illegal file access is achieved when an agent obtains a read access to a file while he is not allowed to do so.
Intrusion Objective illegal f ile access(F ile) State Condition: read access(Agent, F ile), not (authorized(Agent, read, F ile)) Fig. 2. Illegal file access intrusion objective

2.3

Representing Domain Knowledge or System's State

Domain knowledge or system's state, denoted by K , contains available information about the system. It is represented by a set of predicates. For instance, domain knowledge K can be equal to {f ile(secret f ile), printer(ppt), physical access(bad guy, ppt)}, which means that secret f ile is a file, ppt is a printer and that the agent bad guy has access to the printer ppt. 2.4 Action Correlations

For the intruder, once the intrusion scenario and the intrusion objective have been defined, the set of actions necessary to achieve its goal is defined and fixed. On the intrusion detection point of view, we must find among a big amount of intrusion alerts a set of alerts that lead to an intrusion objective. For this purpose we define action correlation. Action correlation allows us to say that if an action A is correlated with an action B , then A may have an influence over the realisation of B . Let E and F be two logical expressions having the following form1 : ­ E = exprE1 , exprE2 , ..., exprEm ­ F = exprF1 , exprF2 , ..., exprFn where each exprEi (resp exprFi ) is either a predicate or a negation of predicate, namely exprEi (resp exprFi ) must have one of the following forms:
1

Notice that we assume that these two expressions do not include disjunctions. This is a restriction which is used to simplify definitions of correlation. Generalising correlation definitions to take into account disjunctions represents further work that remains to be done.

162

S. Benferhat, F. Autrel, and F. Cuppens

­ exprEi = pred ­ exprEi = not (pred) where pred is a predicate. We also assume that E and F are not equivalent to true. Definition 3: Correlation. We say that logical expressions E and F are correlated if there exist i in {1, .., m} and j in {1, .., n} such that exprEi and exprFj are unifiable through a most general unifier (mgu) . Definition 4: Action Correlation or Positive Influence. An action A has a positive influence on an action B if the post condition of A and the pre condition of B are correlated using definition 1. Fig. 3 illustrates an example of attack correlation where the action mount may have a positive influence on the action .rhostmodif ication.
action mount(User,Address,Partition) Pre: remote_access(User,Address), mounted_partition(Address,Partition) Post: can_access(User,Partition) action .rhost modification(User,Address,Partition) Pre: remote_access(User,Address), can_access(User,Partition), owner(Partition,U), userid(U,Userid) Post: user_access(User,Address)

Fig. 3. Example of positive influence between two attacks

Definition 5: Malicious Action. An action A is a malicious action with respect to an intrusion objective O, if the post condition of A and the state condition of O are correlated. For example the action get-f ile(Agent, F ile, P rinter) is a malicious action because its post condition is correlated with intrusion objective illegal f ile access(F ile). Definition 6: Initial Action. An action A is said to be an initial action if either its pre condition is equal to true, or all its pre condition predicates are satisfied by the system's state. For example the action touch(Agent, F ile) is an initial action, since its pre condition is equal to true. 2.5 Intrusion Scenario

An intrusion scenario is a sequence of action which aims at modifying the system's state in order to reach a particuliar state where the intrusion objective is achieved.

Enhanced Correlation in an Intrusion Detection Process

163

Definition 7: Intrusion Scenario. An intrusion scenario is a sequence S (A1 , A2 , ..., An , O) where Ai 's are attacks instances, A1 is an initial action and O is an intrusion objective instance such that: ­ i, j  {1, .., n}, if i > j then Detectime(Ai )  Detectime(Aj ) ­ i  {1, .., n}, j < i such that Ai has an influence over Aj . ­ An is a malicious attack with respect to O Note that other actions (than An ) in scenario S can also have an influence over O.

3

Example and Limitations

The definition of correlation used in this paper is quite weak. Actually two actions are correlated as soon as they have one predicate in common in their post condition and pre condition. As a side effect, given a set of actions we can build a high number of scenarios leading to an intrusion objective. We illustrate this with a scenario example leading to an illegal access to a protected file. Let us consider an intruder, bad guy , and a confidential file secret f ile. Let us say that bad guy wants to reach the intrusion objective illegal f ile access(secret f ile). The intruder and the system start in the following system's state K : ­ ­ ­ ­ ­ f ile(secret f ile) not(read access(bad guy, read, secret f ile)) printer(ppt) physical access(bad guy, ppt) not(blocked(ppt)

This means that secret f ile is a file, bad guy does not have the rights to read it and ppt is a printer that bad guy can reach physically. bad guy wants to reach a system state where the following conditions are achieved: ­ read access(bad guy, read, secret f ile)) ­ not(authorized((bad guy, read, secret f ile)) That is, bad guy can read the sensible file secret f ile while he is not allowed to do so. Let us assume that the following actions are detected: ­ ­ ­ ­ ­ ­ ­ ­ A = touch(bad guy, guy f ile) with Detectime(A) = t1 B = block (bad guy, ppt) with Detectime(B ) = t2 C = lpr-s(bad guy, ppt, guy f ile) with Detectime(C ) = t3 D = remove(bad guy, guy f ile) with Detectime(D) = t4 E = ln-s(bad guy, guy f ile, secret f ile) with Detectime(E ) = t5 F = unblock (bad guy, ppt) with Detectime(F ) = t6 G = print - process(ppt, guy f ile) with Detectime(G) = t7 H = get - f ile(bad guy, secret f ile) with Detectime(H ) = t8

The timestamps are such that t1 < t2 < t3 < t4 < t5 < t6 < t7 < t8 .

164

S. Benferhat, F. Autrel, and F. Cuppens

3.1

Possible Scenarios

From the set of instanciated actions presented above and according to the definition of action correlation, we can build several plausible scenarios which are all correlated to the illegal file access intrusion objective. Fig. 4 shows the correlation links existing in our example according to the actions timestamps and hence exhibits the following possible scenarios: ­ ­ ­ ­ ­ ­ ­ scenario scenario scenario scenario scenario scenario scenario 1: 2: 3: 4: 5: 6: 7: S1 S2 S3 S4 S5 S6 S7 = (A, B, C, D, E, F, G, H, O) = (A, C, G, H, O) = (A, D, E, G, H, O) = (B, F, G, H, O) = (A, C, D, E, G, H, O) = (A, B, D, E, F, G, H, O) = (A, B, C, F, G, H, O)

Note that only scenario 1 involves all instanciated actions (A - H ). A and B are initial states since P re(A) is true and all predicates of P re(B ) are satisfied by the initial system's state. Any system administrator would easily conclude that the most dangerous scenario among those seven possible scenarios is the first one which uses all the actions. However we would like to be able to choose automatically the most plausible scenario among those seven. More generally, given a set of action instances, we would like to be able to build a set of possible scenarios and choose the most plausible one among them. In order to achieve this, we introduce in the next section two improvements which are the notion of anti-correlation and the notion of weighted correlation.

4

Weighted Correlation

The first improvement consists in introducing the notion of anti-correlation, or negative influence, between two actions. Intuitively, A anti-correlates B if when A is achieved, B cannot be imediately observed. More precisely, A anti-correlates B is there exists an expression expr1 in P ost(A), and an expression expr2 in P re(B ) such that expr1 and not(expr2 ) are unifiable. Definition 8: Anti-correlation. We say that logical expressions E and F are anti correlated if one of the following conditions is satisfied: ­ there exists i in [1, m] and j in [1, n] such that exprEi and not (exprFj ) are unifiable through a mgu . ­ there exists i in [1, m] and j in [1, n] such that not (exprEi ) and exprFj are unifiable through a mgu .

action Touch(Agent,File) Pre: OperatingSystem(UNIX) Post: file(File), authorized(Agent,read,File)

action lpr -s(Agent,Printer,File) Pre: printer(Printer), file(File), authorized(Agent,read,File), OperatingSystem(UNIX) Post: queued(File,Printer)

action Get-file(Agent,Printer,File) Pre: printed(Printer,File), physical_access(Agent,Printer) Post: read_access(Agent,File)

Fig. 4. Graph of the illegal file access scenario
action ln -s(Agent,Link,File) Pre: not(file(Link)), OperatingSystem(UNIX) Post: linked(Link,File), file(File) action Print-process(Printer,Link) Pre: queued(Link,Printer), linked(Link,File), not(blocked(Printer)) Post: printed(Printer,File), not(queued(Link,Printer)) action Unblock(Agent,Printer) Pre: printer(Printer), blocked(Printer), physical_access(Agent,Printer) Post: not(blocked(Printer))

action Remove(Agent,File) Pre: authorized(Agent,read,File), file(File) Post: not(file(File))

objective illegal_access(Agent,File) state_condition: not(authorized(Agent,read,File)), read_access(Agent,File)

Enhanced Correlation in an Intrusion Detection Process

action Block(Agent,Printer) Pre: printer(Printer), physical_access(Agent,Printer), not(blocked(Printer) Post: blocked(Printer)

165

166

S. Benferhat, F. Autrel, and F. Cuppens

Definition 9: Negative Influence. We say that an action A has a negative influence on an action B if P re(A) and P ost(B ) are anti-correlated using definition 8. For instance, the post condition of touch(Agent1, F ile1) is anti correlated with the pre condition of ln-s(Agent2, Link 2, F ile2) through the unifier F ile1 = Link 2 (see fig. 5). Anti-correlation allows us to ignore scenarios containing at least one action which has a negative influence on another action.

action Touch(Agent1,File1) Pre: OperatingSystem(UNIX) Post: file(File1), authorized(Agent1,read,File1) action ln -s(Agent2,Link2,File2) Pre: not(file(Link2)), OperatingSystem(UNIX) Post: linked(Link,2File2), file(File2)

Anti correlated throught unifier File1=Link2

Fig. 5. Example of anti correlation between two attacks

The second improvement that we propose is to associate to each action instance B , in a given scenario, a correlation weight. This weight depends on the set of all attacks which have a positive or negative influence on B . Let us denote by SB the set of actions belonging to scenario S , which have an influence on B . Then the correlation weight associated to B is defined from the number of predicates of P re(B ) that can be unified with post conditions of actions in SB . More formally, let: ­ P os(SB ) =
ASB

P ost(A)

­ U (SB , B ): the number of predicates in P re(B ) which are unified at least with one element of P os(SB ) Then: Definition 10: Correlation Weight. A correlation weight associated with an action B in a scenario S , denoted by S (B ), is defined as:  0 if there exists at least one element in SB    which has a negative influence on B S (B ) = 1 if SB =  (namely, B is an initial state)    U (SB ,B ) |P re(B )| otherwise

Enhanced Correlation in an Intrusion Detection Process

167

Where |P re(B )| is the number of predicates in the pre condition of B . In other terms S (B ) gives the rate of preconditions in B that can be achieved using a scenario S . Similarly, S (O) gives the ratio of state conditions in intrusion objective O that can be satisfied in a scenario S , namely:  if there exists at least one element in SO 0 which has a negative influence on O S (O) =  U (SO ,O ) |StateCondition(O )| otherwise

5

Weighting Scenarios

This section aims at showing how correlation weights can be used to rank-order a set of possible scenarios leading to the same intrusion objective. In the following, to each scenario S = (A1 , A2 , ..., An , O) we associate its vector of correlation weights (S (A1 ), S (A2 ), ..., S (An ), S (O)). The question is how to aggregate these weights in order to evaluate the plausibility of a given scenario and how to compare two weighted scenarios. By g we designate the aggregation operator. A first natural aggregation mode is to consider the mean operator, namely: Mean-based agregation mode:
S (Ai )+S (O )

g (A1 , ..., An , O) =

i=1

n+1

However this aggregation mode is not desirable since scenarios containing actions with a null weight are not excluded. Conjunctive-based agregation mode: A natural condition that g should satisfy is: If i  {1, .., n} S (Ai ) = 0 or S (O) = 0 then g (A1 , ..., An , O) = 0. Aggregation functions satisfying this condition are called conjunctive operators. A weaker form of such operators can be if S (Ai ) = 0 or S (O) = 0 then scenario S should be among the least plausible ones. The weakest form of a conjunctive operator would be to say that a scenario S should not be among the most plausible ones if S (Ai ) = 0 or S (O) = 0. An example of aggregation operator which is conjunctive is the minimum operator, namely: Definition 11: A scenario S = (A1 , A2 , ..., An , O) is said to be more plausible than S  = (B1 , B2 , ..., Bn , O) if min((S (A1 ), S (A2 ), ..., S (An ), S (O))) > min((S  (B1 ), S  (B2 ), ..., S  (Bn ), S  (O)))

168

S. Benferhat, F. Autrel, and F. Cuppens

This definition considers that a scenario is plausible as soon as the lowest correlation weight of an action is somewhat plausible. The higher is the correlation weight, the more plausible is the scenario. This definition is however too restrictive. Assume that we have two scenarios S = (A1 , A2 , ..., An , O) and S  = (B1 , B2 , ..., Bn , O). Concerning the scenario S assume that i  1, n, S (Ai ) =  and S (O) = . Assume also that for the scenario S  there exists j such that S  (Bj ) =  and that i  1, n , i = j, S  (Bi ) > , S  (O) > . In such a case, one would clearly prefer scenario S  to S since S  contains stronger correlated actions. But they are considered equally plausible when compared with the minimum operator since we only consider the worst correlated action. A possible refinement of the minimum operator is to use a so-called "leximin operator", well-known in social-choice theory [5]. The leximin ordering makes sense only when comparing two equally sized vectors. Hence when comparing two scenarios having a different number of actions, we have to duplicate the lowest weight in the shortest scenario to obtain two equally sized vectors of weights. The following describes the leximin ordering:  -    Definition 12: Let - v = (v1 , ..., vn ) and v  = (v1 , ..., vn ) be two vectors of weights    . Then - v is said to ranked increasingly, namely v1 > ... > vn and v1 > ... > vn  -    be leximin prefered to v if i such that vi > vi and j < i, vj = vj . In order to apply this definition to rank-order scenarios, we view the corre- - -  -  lation weights associated to each scenario S as a vector of weights v S . By v (S )  we denote the vector obtained from - v by ranking the weights increasingly. S Then, the selection of plausible scenarios is given by the following definition: -  Definition 13: A scenario S is prefered to S  , denoted by S > S  , if - v-  (S ) >leximin - - -  v(S  ) . A scenario S is among the most plausible scenarios if there is no scenario S  such that S  > S . Let us go back to our illegal file access example. As we said in the section possible scenarios, according to definition 3 we can build the following seven scenarios: ­ ­ ­ ­ ­ ­ ­ scenario scenario scenario scenario scenario scenario scenario 1: 2: 3: 4: 5: 6: 7: S1 S2 S3 S4 S5 S6 S7 = (A, B, C, D, E, F, G, H, O) = (A, C, G, H, O) = (A, D, E, G, H, O) = (B, F, G, H, O) = (A, C, D, E, G, H, O) = (A, B, D, E, F, G, H, O) = (A, B, C, F, G, H, O)

According to definition 10, their corresponding vectors of weights are: ­ scenario 1: ­ scenario 2:
1 1 1 1 1 1 - - - -  v S1 = (1, 1, 1, 1, 1, 2 , 1, 2 , 2 ) and v (S1 ) = ( 2 , 2 , 2 , 1, 1, 1, 1, 1, 1) 1 1 1 1 1 1 - - -  -  = ( , , , 1, 1) vS = (1, 1, , , ) and v
2

3 2 2

 (S2 )

3 2 2

Enhanced Correlation in an Intrusion Detection Process

169

­ ­ ­ ­ ­

scenario scenario scenario scenario scenario

3: 4: 5: 6: 7:

1 1 1 1 1 1 - - - -  v S3 = (1, 1, 1, 3 , 2 , 2 ) and v (S3 ) = ( 3 , 2 , 2 , 1, 1, 1) 1 1 1 1 1 1 1 1 - - -  -  vS4 = (1, 2 , 3 , 2 , 2 ) and v(S4 ) = ( 3 , 2 , 2 , 2 , 1) 1 1 1 1 1 1 - - - -  v S5 = (1, 1, 1, 1, 3 , 2 , 2 ) and v (S5 ) = ( 3 , 2 , 2 , 1, 1, 1, 1) 1 1 1 1 1 1 1 - - -  -  vS6 = (1, 1, 1, 1, 2 , 3 , 2 , 2 ) and v(S6 ) = ( 1 3 , 2 , 2 , 2 , 1, 1, 1, 1) 1 1 1 1 1 1 1 1 -  - - -  vS = (1, 1, 1, , , , ) and v = ( , , , , 1, 1, 1)
7

2 3 2 2

 (S7 )

3 2 2 2

Applying definition 12, the height scenarios are ranked as follow: S1 > S6 > S5 > S7 > S3 > S2 > S4 Hence, S1 (which involves all instanciated attacks) is the most plausible scenario, as expected.

6

Conclusion

Based on the observation that an intrusion scenario might be represented as a planning activity, we suggest a model to recognize intrusion scenarios and malicious intentions. This model does not follow previous proposals [3,4] that require to explicitly specify a library of intrusion scenarios. Instead, our approach is based on specification of elementary attacks and intrusion objectives. We then show how to derive correlation relations, or positive influence, between two attack instances or between an attack instance and an intrusion objective. Detection of complex intrusion scenario is obtained by combining these binary correlation relations. We then define the notion of anti correlation, or negative influence, that is useful to recognize a sequence of correlated attacks that does no longer enable the intruder to achieve an intrusion objective. This may be used to eliminate a category of false positives that correspond to false attacks, that is actions that are not further correlated to an intrusion objective. Lastly we proposed correlation weights which can be very useful to select plausible scenarios. When the intruder did not achieved his intrusion objective yet but there are several possible intrusion objectives consistent with a given sequence of correlated attacks, our current strategy is to select the objective that contain stronger correlated attacks. A future work is to see how to integrate expert knowledge in the correlation process. Indeed, to decide if a given intrusion scenario instance is achieved or not, it is often necessary to combine information provided by "classical" IDS with other information about the system monitored by the IDS: its topology, configuration and other data about the type and version of the operating systems and applications installed in this system [8]. This kind of data is not provided by classical IDS but other tools exist that may be used to collect it. Since current IDS also provide alerts that do not allow us to distinguish between successful or failing attacks, these additional data would be also useful for that purpose. This problem is currently investigated in the ongoing project DICO.

Acknowledgements
This work was funded by the French Ministry of Research as part of the DICO project. The authors would like to thank all the members of these projects,

170

S. Benferhat, F. Autrel, and F. Cuppens

especially the members of the sub-project "Correlation": Herve Debar, Ludovic Me and Benjamin Morin.

References
1. Cuppens, F. and Mi` ege, A.: Alert Correlation in a Cooperative Intrusion Detection Framework. In IEEE Symposium on Security and Privacy, Oakland, USA (2002) 2. Cuppens, F., Autrel, F., Mi` ege, A., Benferhat, S.: Recognizing malicious intention in an intrusion detection process. In Second International Conference on Hybrid Intelligent Systems (HIS'2002), Santiago, Chile (October 2002) 3. Geib, C. and Goldman, R.: Plan Recognition in Intrusion Detection Systems. In DARPA Information Survivability Conference and Exposition (DISCEX) (June 2001) 4. Geib, C. and Goldman, R.: Probabilistic Plan Recognition for Hostile Agents. In Florida AI Research Symposium (FLAIR) , Key-West, USA (2001) 5. Moulin, H.: Axioms of Cooperative Decision Making. Cambridge University Press, Cambridge (1988) 6. Debar, H. and Wespi, A.: The Intrusion Detection Console Correlation Mechanism. Workshop on the Recent Advances in Intrusion Detection (RAID'2001), Davis, USA (October 2001) 7. M` e, L., Marrakchi, Z., Michel, C., Debar, H. and Cuppens, F.: La detection d'intrusion: les outils doivent coop´ erer. REE journal 8. Huang, M.-Y.: A Large-scale Distributed Intrusion Detection Framework Based on Attack Strategy Analysis. Proceedings of the First Internationnal Workshop on the Recent Advances in Intrusion Detection (RAID'98), Louvain-La-Neuve, Belgium (1998) 9. Valdes, A. and Skinner, K.: Probabilistic Alert Correlation. In Fourth International Workshop on the Recent Advances in Intrusion Detection (RAID'2001), Davis, USA, October 2001. 171 (septembre 2002) 20

