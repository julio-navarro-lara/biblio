Toward Automated Intrusion Alert Analysis
Peng Ning and Dingbang Xu

Contents
1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2 Correlating Intrusion Alerts Based on Prerequisites and Consequences of Attacks. . . . . . . . .
2.1 Prerequisite and Consequence of Attacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Hyper-Alert Type and Hyper-Alert . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3 Analyzing Intensive Alerts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1 Alert Aggregation and Disaggregation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Focused Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3 Clustering Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4 Frequency Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.5 Link Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.6 Association Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.7 Discussion. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4 Learning Attack Strategies from Correlated Alerts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.1 Attack Strategy Graph . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2 Learning Attack Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Dealing with Variations of Attacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

175
177
178
178
184
185
188
189
190
190
192
193
193
194
196
197
200
203
203

1 Introduction
Traditional intrusion detection systems (IDSs) focus on low-level attacks or anomalies and raise alerts independently, though there may be logical connections between
them. In situations where there are intensive attacks, not only will actual alerts be
mixed with false alerts, but the amount of alerts will also become unmanageable.

P. Ning (!)
Computer Science Department, North Carolina State University, Raleigh, NC 27695, USA
e-mail: pning@ncsu.edu
S.C.-H. Huang et al. (eds.), Network Security, DOI 10.1007/978-0-387-73821-5 8,
c Springer Science+Business Media, LLC 2010
!

175

176

P. Ning and D. Xu

As a result, it is difficult for human users or intrusion response systems to understand the alerts and take appropriate actions. Therefore, it is necessary to develop
techniques to construct attack scenarios (i.e., steps that attackers use in their attacks)
from alerts to facilitate intrusion analysis.
In this article, we summarize a series of research efforts aimed at addressing the
above problem [26–29]. These efforts start with an approach to constructing attack
scenarios based on prerequisites and consequences of attacks. Intuitively, the prerequisite of an attack is the necessary condition for the attack to be successful, while
the consequence of an attack is the possible outcome of the attack. For example, the
existence of a vulnerable service is the prerequisite of a remote buffer overflow attack against the service, and as the consequence of the attack, the attacker may gain
access to the host. Accordingly, we correlate the alerts together when the attackers
launch some early attacks to prepare for the prerequisites of some later ones. For
example, if they use a UDP port scan to discover the vulnerable services, followed
by an attack against one of the services, we can correlate the corresponding alerts together. It is well-known that current IDSs often miss unknown attacks or variations
of known attacks. To tolerate missing detections, our method allows partial satisfaction of prerequisites of an attack. In addition, our method allows flexible alert
aggregation and provides intuitive representations of correlated alerts.
We apply this alert correlation method to analyze real-world, intrusion intensive data sets. In particular, we would like to see how well the alert correlation
method can help human users organize and understand intrusion alerts, especially
when IDSs report a large amount of alerts. We argue that this is a practical problem
that the intrusion detection community is facing. As indicated in [22], “encountering 10–20,000 alarms per sensor per day is common.” To facilitate the analysis of
large sets of correlated alerts, we develop several utilities (called alert aggregation
and disaggregation, focused analysis, clustering analysis, frequency analysis, link
analysis, and association analysis). These utilities are intended for human users to
analyze and understand the correlated alerts as well as the strategies behind them.
It is often desirable, and sometimes necessary, to understand attack strategies
in security applications such as computer forensics and intrusion responses. For
example, it is easier to predict an attacker’s next move, and decrease the damage
caused by intrusions, if the attack strategy is known during intrusion response. To
facilitate the extraction of attack strategies from intrusion alerts and complement
static vulnerability analysis techniques (e.g., [2, 17, 33, 35]), we develop techniques
to automatically learn attack strategies from intrusion alerts reported by IDSs. By
examining correlated intrusion alerts, our method extracts the constraints intrinsic
to the attack strategy automatically. Specifically, an attack strategy is represented as
a directed acyclic graph (DAG), which we call an attack strategy graph, with nodes
representing attacks, edges representing the (partial) temporal order of attacks, and
constraints on the nodes and edges. These constraints represent the conditions that
any attack instance must satisfy in order to use the strategy. To cope with variations
in attacks, we use generalization techniques to hide the differences not intrinsic to
the attack strategy. By controlling the degree of generalization, users may inspect
attack strategies at different levels of details.

Toward Automated Intrusion Alert Analysis

177

The remainder of this article is organized as follows. Section 2 presents our
formal framework for correlating alerts using prerequisites and consequences of attacks. Section 3 describes several utilities for analyzing attack scenarios constructed
from large collections of alerts. Section 4 presents techniques to extract attack strategies from correlated intrusion alerts. Section 5 discusses related work. Section 6
concludes this article and points out some future research directions.

2 Correlating Intrusion Alerts Based on Prerequisites
and Consequences of Attacks
Our method for alert correlation is based on the observation that in a series of attacks the attacks are usually not isolated, but related as different stages of the attack
sequence, with the early ones preparing for the later ones. To take advantage of this
observation, we propose to correlate the alerts generated by IDSs using prerequisites and consequences of the corresponding attacks. Intuitively, the prerequisite of
an attack is the necessary condition for the attack to be successful. For example,
the existence of a vulnerable service is a prerequisite for a remote buffer overflow
attack against the service. Moreover, the attacker may make progress in gaining access to the victim system (e.g., discover the vulnerable services, install a Trojan
horse program) as a result of an attack. Informally, we call the possible outcome of
an attack the (possible) consequence of the attack. In a series of attacks where the
attackers launch earlier attacks to prepare for later ones, there are usually strong connections between the consequences of the earlier attacks and the prerequisites of the
later ones. Indeed, if an earlier attack is to prepare for a later attack, the consequence
of the earlier attack should at least partly satisfy the prerequisite of the later attack.
Accordingly, we identify the prerequisites (e.g., existence of vulnerable services)
and the consequences (e.g., discovery of vulnerable services) of each type of attack. These are then used to correlate alerts, which are attacks detected by IDSs, by
matching the consequences of (the attacks corresponding to) some previous alerts
and the prerequisites of (the attacks corresponding to) some later ones. For example,
if we find a Sadmind Ping followed by a buffer overflow attack against the corresponding Sadmind service, we can correlate them to be parts of the same series of
attacks. In other words, we model the knowledge (or state) of attackers in terms of
individual attacks, and correlate alerts if they indicate the progress of attacks.
Note that an attacker does not have to perform early attacks to prepare for a
later attack, even though the later attack has certain prerequisites. For example, an
attacker may launch an individual buffer overflow attack against a service blindly,
without knowing if the service exists. In other words, the prerequisite of an attack
should not be mistaken for the necessary existence of an earlier attack. However,
if the attacker does launch attacks with earlier ones preparing for later ones, our
method can correlate them, provided that the attacks are detected by IDSs.
In the following subsections, we adopt a formal approach to develop our alert
correlation method.

178

P. Ning and D. Xu

2.1 Prerequisite and Consequence of Attacks
We propose to use predicates as basic constructs to represent the prerequisites
and (possible) consequences of attacks. For example, a scanning attack may discover UDP services vulnerable to a certain buffer overflow attack. We can use the
predicate UDPVulnerableToBOF (VictimIP, VictimPort) to represent the attacker’s
discovery (i.e., the consequence of the attack) that the host having the IP address
VictimIP runs a service (e.g., sadmind) at UDP port VictimPort and that the service
is vulnerable to the buffer overflow attack. Similarly, if an attack requires a UDP
service vulnerable to the buffer overflow attack, we can use the same predicate to
represent the prerequisite.
Some attacks may require several conditions be satisfied at the same time in
order to be successful. To represent such complex conditions, we use a logical
combination of predicates to describe the prerequisite of an attack. For example,
a certain network launched buffer overflow attack may require that the target host
has a vulnerable UDP service accessible to the attacker through the firewall. This
prerequisite can be represented by UDPVulnerableToBOF (VictimIP, VictimPort) ^
UDPAccessibleViaFirewall (VictimIP, VictimPort). To simplify the following discussion, we restrict the logical operators in predicates to ^ (conjunction) and _
(disjunction).
We also use a set of predicates to represent the (possible) consequence of an
attack. For example, an attack may result in compromise of the root privilege as
well as modification of the .rhost file. Thus, we may use the following to represent the corresponding consequence: fGainRootAccess (VictimIP), rhostModified
(VictimIP)g. Note that the set of predicates used to represent the consequence is
essentially the logical combination of these predicates and can be represented by a
single logical formula. However, representing the consequence as a set of predicates
rather than a long formula is more convenient and will be used here.

2.2 Hyper-Alert Type and Hyper-Alert
Using predicates as the basic construct, we introduce the notion of a hyper-alert type
to represent the prerequisite and the consequence of each type of alert.
Definition 1. A hyper-alert type T is a triple (fact, prerequisite, consequence),
where (1) fact is a set of attribute names, each with an associated domain of values, (2) prerequisite is a logical combination of predicates whose free variables are
all in fact, and (3) consequence is a set of predicates such that all the free variables
in consequence are in fact.
Each hyper-alert type encodes the knowledge about a type of attack. The component fact of a hyper-alert type tells what kind of information is reported along
with the alert (i.e., detected attack), prerequisite specifies what must be true in order
for the attack to be successful, and consequence describes what could be true if the

Toward Automated Intrusion Alert Analysis

179

attack indeed succeeds. For the sake of brevity, we omit the domains associated with
the attribute names when they are clear from the context.
Example 1. Consider the buffer overflow attack against the sadmind remote administration tool. We may have a hyper-alert type SadmindBufferOverflow D
(fVictimIP, VictimPortg, ExistHost (VictimIP) ^ VulnerableSadmind (VictimIP),
fGainRootAccess(VictimIP)g) for such attacks. Intuitively, this hyper-alert type says
that such an attack is against the host at IP address VictimIP. (We expect the actual
values of VictimIP are reported by an IDS.) For the attack to be successful, there
must exist a host at IP address VictimIP, and the corresponding sadmind service
must be vulnerable to buffer overflow attacks. The attacker may gain root privilege
as a result of the attack.
Given a hyper-alert type, a hyper-alert instance can be generated if the corresponding attack is detected and reported by an IDS. For example, we can generate
a hyper-alert instance of type SadmindBufferOverflow from a corresponding alert.
The notion of hyper-alert instance is formally defined as follows:
Definition 2. Given a hyper-alert type T D (fact, prerequisite, consequence), a
hyper-alert (instance) h of type T is a finite set of tuples on fact, where each tuple
is associated with an interval-based timestamp [begin time, end time]. The hyperalert h implies that prerequisite must evaluate to True and all the predicates in
consequence might evaluate to True for each of the tuples. (Notation-wise, for each
tuple t in h, we use t:begin time and t:end time to refer to the timestamp associated
with t.)
The fact component of a hyper-alert type is essentially a relation schema (as in
relational databases), and a hyper-alert is a relation instance of this schema. One
may point out that an alternative way is to represent a hyper-alert as a record, which
is equivalent to a single tuple on fact. However, such an alternative cannot accommodate certain alerts possibly reported by an IDS. For example, an IDS may report
an IPSweep attack along with multiple swept IP addresses, which cannot be represented as a single record. In addition, our current formalism allows aggregation
of alerts of the same type and is flexible in reasoning about alerts. Therefore, we
believe the current notion of a hyper-alert is an appropriate choice.
A hyper-alert instantiates its prerequisite and consequence by replacing the free
variables in prerequisite and consequence with its specific values. Since all free
variables in prerequisite and consequence must appear in fact in a hyper-alert type,
the instantiated prerequisite and consequence will have no free variables. Note that
prerequisite and consequence can be instantiated multiple times if fact consists of
multiple tuples. For example, if an IPSweep attack involves several IP addresses,
the prerequisite and consequence of the corresponding hyper-alert type will be instantiated for each of these addresses.
In the following, we treat timestamps implicitly and omit them if they are not
necessary for our discussion.

180

P. Ning and D. Xu

Example 2. Consider the hyper-alert type SadmindBufferOverflow discussed in
Example 1. There may be a hyper-alert hSad mi ndBOF as follows: f(VictimIP D
152.1.19.5, VictimPort D 1235), (VictimIP D 152.1.19.7, VictimPort D 1235)g. This
implies that if the attack is successful, the following two logical formulas must be
True as the prerequisites of the attack: ExistHost (152.1.19.5) ^ VulnerableSadmind
(152.1.19.5), ExistHost (152.1.19.7) ^ VulnerableSadmind (152.1.19.7). Moreover,
as possible consequences of the attack, the following might be True: GainRootAccess (152.1.19.5), GainRootAccess (152.1.19.7). This hyper-alert says that there are
buffer overflow attacks against sadmind at IP addresses 152.1.19.5 and 152.1.19.7,
and the attacker may gain root access as a result of the attacks.
A hyper-alert may correspond to one or several related alerts. If an IDS reports
one alert for a certain attack and the alert has all the information needed to instantiate
a hyper-alert, a hyper-alert can be generated from the alert. However, some IDSs
may report a series of alerts for a single attack. For example, EMERALD [31] may
report several alerts (within the same thread) related to an attack that spreads over a
period of time. In this case, a hyper-alert may correspond to the aggregation of all the
related alerts. Moreover, several alerts may be reported for the same type of attack
in a short period of time. Our definition of hyper-alert allows them to be treated as
one hyper-alert and thus provides flexibility in the reasoning about alerts. Certain
constraints are necessary to make sure the hyper-alerts are reasonable. However,
since our hyper-alert correlation method does not depend on them directly, we will
discuss them after introducing our method.
Ideally, we may correlate a set of hyper-alerts with a later hyper-alert if the consequences of the former ones imply the prerequisite of the latter one. However, such
an approach may not work in reality due to several reasons. First, the attacker may
not always prepare for certain attacks by launching some other attacks. For example, the attacker may learn a vulnerable sadmind service by talking to people who
work in the organization where the system is running. Second, the current IDSs may
miss some attacks, and thus affect the alert correlation if the above approach is used.
Third, due to the combinatorial nature of the aforementioned approach, it is computationally expensive to examine sets of alerts to find out whether their consequences
imply the prerequisite of an alert.
Having considered these issues, we adopt an alternative approach. Instead of
examining if several hyper-alerts imply the prerequisite of a later one, we check
if an earlier hyper-alert contributes to the prerequisite of a later one. Specifically,
we decompose the prerequisite of a hyper-alert into individual predicates and test
whether the consequence of an earlier hyper-alert makes some of the prerequisites
True (i.e., make the prerequisite easier to satisfy). If the result is yes, then we correlate the hyper-alerts together. This idea is specified formally through the following
definitions.
Definition 3. Consider a hyper-alert type T D (fact, prerequisite, consequence). The
prerequisite set (or consequence set, resp.) of T , denoted P .T / (or C.T /, resp.), is
the set of all predicates that appear in prerequisite (or consequence, resp.). Given a
hyper-alert instance h of type T , the prerequisite set (or consequence set, resp.) of h,

Toward Automated Intrusion Alert Analysis

181

denoted P .h/ (or C.h/, resp.), is the set of predicates in P .T / (or C.T /, resp.)
whose arguments are replaced with the corresponding attribute values of each tuple in h. Each element in P .h/ (or C.h/, resp.) is associated with the timestamp
of the corresponding tuple in h. (Notation-wise, for each p 2 P .h/ (or C.h/,
resp.), we use p:begin time and p:end time to refer to the timestamp associated
with p.
Example 3. Consider the Sadmind Ping attack through which an attacker discovers possibly vulnerable sadmind services. The corresponding alerts can be represented by a hyper-alert type SadmindPing D (fVictimIP, VictimPortg, fExistHost
(VictimIP)g, fVulnerableSadmind (VictimIP)g).
Suppose a hyper-alert instance hSadmindPing of type SadmindPing has the following tuples: f(VictimIP D 152.1.19.5, VictimPort D 1235), (VictimIP D 152.1.19.7,
VictimPort D 1235), (VictimIP D 152.1.19.9, VictimPort D 1235)g. Then, we
have the prerequisite set P .hSadmindPing / D fExistHost (152.1.19.5), ExistHost
(152.1.19.7), ExistHost (152.1.19.9)g, and the consequence set C.hSadmindPing / D
fVulnerableSadmind (152.1.19.5), VulnerableSadmind (152.1.19.7), VulnerableSadmind (152.1.19.9)g.
Example 4. Consider the hyper-alert hSadmindBOF in Example 2. The prerequisite set of hSadmindBOF is P .hSad mi ndBOF / D fExistHost (152.1.19.5), ExistHost
(152.1.19.7), VulnerableSadmind (152.1.19.5), VulnerableSadmind (152.1.19.7)g,
and the consequence set is C.hSadmindBOF / D fGainRootAccess (152.1.19.5), GainRootAccess (152.1.19.7)g.
Definition 4. Hyper-alert h1 prepares for hyper-alert h2 , if there exist p 2 P .h2 /
and C ! C.h1 / such that for all c 2 C , c:end time < p:begin time and the conjunction of all the predicates in C implies p.
The prepare-for relation is developed to capture the causal relationships between
hyper-alerts. Intuitively, h1 prepares for h2 if some attacks represented by h1 make
the attacks represented by h2 easier to succeed.
Example 5. Let us continue Examples 3 and 4. Assume that all tuples in hSadmindPing
have timestamps earlier than every tuple in hSadmindBOF . By comparing the contents
of C.hSadmindPing / and P .hSadmindBOF /, it is clear the instantiated predicate VulnerableSadmind (152.1.19.5) (among others) in P .hSadmindBOF / is also in C.hSadmindPing /.
Thus, hSadmindPing prepares for, and should be correlated with hSadmindBOF .
Given a sequence S of hyper-alerts, a hyper-alert h in S is a correlated hyperalert, if there exists another hyper-alert h0 in S such that either h prepares for h0 or
h0 prepares for h. If no such h0 exists, h is called an isolated hyper-alert. The goal
of the correlation process is to discover all pairs of hyper-alerts h1 and h2 in S such
that h1 prepares for h2 .
The prepare-for relation between hyper-alerts provides a natural way to represent the causal relationship between correlated hyper-alerts. In the following, we
introduce the notion of a hyper-alert correlation graph to represent attack scenarios

182

P. Ning and D. Xu

on the basis of the prepare-for relation. As we will see, the hyper-alert correlation
graph reflects the high-level strategies or logical steps behind a sequence of attacks.
Definition 5. A hyper-alert correlation graph HG D (N , E) is a connected DAG,
where the set N of nodes is a set of hyper-alerts, and for each pair of nodes n1 ;
n2 2 N , there is an edge from n1 to n2 in E if and only if n1 prepares for n2 .
The hyper-alert correlation graph is not only an intuitive way to represent attack scenarios constructed through alert correlation but also reveals opportunities to
improve intrusion detection. First, the hyper-alert correlation graph can potentially
reveal the intrusion strategies behind the attacks and thus lead to better understanding of the attacker’s intention. Second, assuming some attackers exhibit patterns in
their attack strategies, we can use the hyper-alert correlation graph to profile previous attacks and thus identify on-going attacks by matching to the profiles. A partial
match to a profile may indicate attacks possibly missed by the IDSs, and thus lead
to human investigation and improvement of the IDSs. Nevertheless, additional research is necessary to demonstrate the usefulness of hyper-alert correlation graphs
for this purpose.
Figure 1 shows a hyper-alert correlation graph discovered in our experiments
[27]. Each node in Fig. 1 represents a hyper-alert. The text inside the node is the
name of the hyper-alert type followed by the hyper-alert ID. (We will follow this
convention for all the hyper-alert correlation graphs.)
The hyper-alerts can be divided into five stages horizontally. The first stage consists of three Sadmind Ping alerts, which the attacker used to find out the vulnerable
Sadmind services. The three alerts are from source IP address 202.077.162.213, and
to destination IP addresses172.016.112.010, 172.016.115.020, and172.016.112.050,

Rsh67535
Sadmind_Amslverify_Overflow67438
Sadmind_
Ping67341

Sadmind_Amslverify_Overflow67442
Sadmind_Amslverify_Overflow67428
Sadmind_Amslverify_Overflow67430

Rsh67536
Rsh67538

Mstream_Zombie67563

Rsh67539
Rsh67562
Rsh67542

Sadmind_
Ping67286

FTP_Syst
67243

Sadmind_
Ping67343

Sadmind_Amslverify_Overflow67416

Rsh67546

Sadmind_Amslverify_Overflow67417

Rsh67547

Sadmind_Amslverify_Overflow67420

Rsh67549

Mstream_Zombie67767

Sadmind_Amslverify_Overflow67422

Rsh67550

Mstream_Zombie67537

Sadmind_Amslverify_Overflow67424

Rsh67540

Mstream_Zombie67776

Sadmind_Amslverify_Overflow67426

Rsh67543

Email_Almail_Overflow67304

Rsh67545

Sadmind_Amslverify_Overflow67432

Rsh67553

Sadmind_Amslverify_Overflow67434

Rsh67558

Sadmind_Amslverify_Overflow67436

Rsh67559

Sadmind_Amslverify_Overflow67440

Rsh67560

Mstream_Zombie67777

Mstream_Zombie67554

Email_Almail_Overflow67529

Fig. 1 A hyper-alert correlation graph discovered in our experiments

Stream_DoS67773

Toward Automated Intrusion Alert Analysis

183

respectively. The second stage consists of fourteen Sadmind Amslverify Overflow
alerts. According to the description of the attack scenario, the attacker tried three
different stack pointers and two commands in Sadmind Amslverify Overflow attacks
for each victim host until one attempt succeeded. All the above three hosts were
successfully broken into. The third stage consists of some Rsh alerts, with which
the attacker installed and started the mstream daemon and master programs. The
fourth stage consists of alerts corresponding to the communications between the
DDOS master and daemon programs. Finally, the last stage consists of the DDOS
attack. We can see clearly that the hyper-alert correlation graph reveals the structure
as well as the high-level strategy of the sequence of attacks.
To better understand the effectiveness of our method, we examine the completeness and the soundness of alert correlation. The completeness of alert correlation
assesses how well we can correlate related alerts together, while the soundness evaluates how correctly the alerts are correlated. Figure 2 shows the completeness and
the soundness measures computed in our experiments [27]. We also examine the effect of alert correlation in differentiating true and false alerts. Figures 3 and 4 show

Fig. 2 Completeness and soundness

Fig. 3 False alert rate

184

P. Ning and D. Xu

Fig. 4 Detection rate

the false alert rate and the detection rate before and after alert correlation. We can
see a significant reduction in false alert rate but a slight reduction in detection rate
after correlation.

3 Analyzing Intensive Alerts
Our initial experiments demonstrate that the alert correlation method is effective
in analyzing small sets of alerts. However, our experience with intrusion intensive
datasets (e.g., the DEFCON 8 CTF dataset [10]) has revealed several problems.
First, let us consider the following scenario. Suppose an IDS detected an SadmindPing attack, which discovered the vulnerable Sadmind service on host V, and
later an SadmindBufferOverlfow attack against the Sadmind service. Assuming that
they were launched from different hosts, should we correlate them? On the one hand,
it is possible that one or two attackers coordinated these two attacks from two different hosts, trying to avoid being correlated. On the other hand, it is also possible that
these attacks belonged to two separate attempts. Such a scenario clearly introduces a
dilemma, especially when there are a large number of alerts. One may suggest to use
time to solve this problem. For example, we may correlate the aforementioned attacks if they happened within t seconds. However, knowing this method, an attacker
may introduce delays between attacks to bypass correlation.
The second problem is the overwhelming information encoded by hyper-alert
correlation graphs when intensive attacks trigger a large amount of alerts. Our initial attempt to correlate the alerts generated for the DEFCON 8 CTF dataset [10]
resulted in 450 hyper-alert correlation graphs, among which the largest hyper-alert
correlation graph consists of 2,940 nodes and 25,321 edges even if the transitive
edges are removed. Such a graph is clearly too big for a human user to comprehend
in a short period of time. Although the DEFCON 8 dataset involves intensive attacks

Toward Automated Intrusion Alert Analysis

185

not usually seen in normal network traffic, the actual experience of intrusion detection practitioners indicates that “encountering 10–20,000 alarms per sensor per day
is common [22].” Thus, it is necessary to develop techniques or tools to deal with
the overwhelming information.
In this section, we develop a set of utilities to at least partially address these problems. These utilities are provided for human analysts to examine different aspects
of (correlated) alerts efficiently. Though they cannot fully solve the first problem,
these utilities can help analysts get as much information as possible and make the
best judgment. To address the second problem, some of the utilities are designed to
narrow down the scope of alerts being analyzed or reduce the complexity of hyperalert correlation graphs. These utilities are then integrated into one system (which
we will present in the next section), which provides human analysts a platform to
examine correlated intrusion alerts interactively and progressively.
Each utility takes a set of hyper-alerts as input. Depending on the output, these
utilities can be divided into two classes: hyper-alert generating utilities and feature extraction utilities. A hyper-alert generating utility outputs one or multiple
sets of hyper-alerts, while a feature extraction utility only outputs the properties
of the input hyper-alerts. We have developed six utilities, including alert aggregation/disaggregation, focused analysis, clustering analysis, frequency analysis, link
analysis, and association analysis. The first three utilities are hyper-alert generating
utilities, while the last three are feature extraction utilities.

3.1 Alert Aggregation and Disaggregation
The goal of alert aggregation is to reduce the complexity of hyper-alert correlation
graphs without sacrificing the structures of the attack scenarios; it allows analysts
to get concise views of correlated alerts. For this reason, we also refer to alert aggregation as graph reduction. Alert disaggregation allows analysts to selectively
disaggregate certain aggregated alerts, thus providing the ability to examine the details of select aggregated alerts.
3.1.1 Alert Aggregation
As discussed earlier, the difficulty of understanding a large hyper-alert correlation
graph is mainly due to the large numbers of nodes and edges in the graph. Thus, a
natural way to reduce the complexity of a large hyper-alert correlation graph is to
reduce the number of nodes and edges. However, to make the reduced graph useful,
any reasonable reduction should maintain the structure of the corresponding attacks.
We propose to aggregate hyper-alerts of the same type to reduce the number of nodes in a hyper-alert correlation graph. Due to the flexible definition of
hyper-alerts, the result of hyper-alert aggregation will remain valid hyper-alerts. For
example, in Fig. 5, hyper-alerts 67432, 67434, 67436, and 67440 are all instances of

186

P. Ning and D. Xu
Attacking Host: 202.77.162.213
Victim Host: 172.16.112.50

67432
67559

67434

67554

67558

67343
Sadmind_Ping

67436

67553

67773

67560

67776

Stream_DoS

Mstream_Zombie

67440
Sadmind_Amslverify_Overflow

Rsh

Fig. 5 A hyper-alert correlation graph discovered in the 2000 DARPA intrusion detection evaluation datasets
Attacking Host: 202.77.162.213
Victim Host: 172.16.112.50
67343

A 001

A 002

Sadmind_Ping
Rsh
Sadmind_Amslverify_Overflow

A003

67773

Mstream_Zombie Stream_Dos

Fig. 6 A hyper-alert correlation graph reduced from Fig. 5

hyper-alert type Sadmind Amslverify Overflow. Thus, we may aggregate them into
one hyper-alert. As another example, hyper-alerts 67558, 67559, 67560, and 67553
are all instances of Rsh, and can be aggregated into a single hyper-alert.
Edges are reduced along with the aggregation of hyper-alerts. In Fig. 5, the
edges between the Rsh hyper-alerts are subsumed into the aggregated hyperalert, while the edges between the Sadmind Ping hyper-alert and the four
Sadmind Amslverify Overflow hyper-alerts are merged into a single edge. As a
result, we have a reduced hyper-alert correlation graph as shown in Fig. 6.
Reduction of a hyper-alert correlation graph may lose information contained in
the original graph. Indeed, hyper-alerts that are of the same type but belong to different sequences of attacks may be aggregated and thus provide overly simplified
results. Nevertheless, our goal is to lose as little information about the structure of
attacks as possible.
Depending on the actual alerts, the reduction of a hyper-alert correlation graph
may be less simplified so that there is too much detail in the resulting graph, or
overly simplified so that some structures are hidden. We would like to give a human
user more control over the graph reduction process.
We allow hyper-alert aggregation only when the resulting hyper-alerts satisfy an
interval constraint of a given threshold I . Intuitively, we allow hyper-alerts to be
aggregated only when they are close to each other in time. The larger a threshold I
is, the more a hyper-alert correlation graph can be reduced. By adjusting the interval
threshold, a user can control the degree to which a hyper-alert correlation graph is
reduced.
Though simply aggregating the same type of hyper-alerts can simplify complex
hyper-alert correlation graphs and thus improve their readability, one problem still

Toward Automated Intrusion Alert Analysis

187

Fig. 7 An example abstraction hierarchy of hyper-alert types

remains. That is, there may be many types of alerts in a hyper-alert correlation graph.
One incentive to have many types of alerts is to allow fine-grained names for different types of alerts and thus to keep more semantics along with the alerts. However,
a reduced hyper-alert correlation graph may still have too many nodes and remain
difficult to understand.
To allow further reduction of hyper-alert correlation graphs, we extend the
above aggregation by combining abstraction with interval constraints. Specifically,
we generalize each hyper-alert type to a more abstract one. For example, RealSecure Network Sensor 7.0 may raise two types of alerts for mstream zombie
activities: Mstream Zombie Request and Mstream Zombie Response alerts, which
represent the request sent from an mstream master program to an mstream zombie program and the response, respectively. We may abstract both of them into
one type of Mstream Zombie alerts. Abstraction may be performed hierarchically
so that there are different levels of abstractions. For example, we may generalize
Mstream Zombie and Trinoo Daemon into a type of DDoS Daemon alert. We assign an abstraction level to each (abstract) hyper-alert type to reflect the degree of
abstraction. Figure 7 shows the abstraction hierarchy for this example.
3.1.2 Alert Disaggregation
Alert aggregation controlled by interval constraints and abstraction hierarchies of
hyper-alert types can reduce the size of hyper-alert graphs and present concise views
of correlated alerts. However, some details of the correlated alerts and the preparefor relations are hidden in the aggregated alerts. Alert disaggregation provides a
way to examine additional details of certain aggregated hyper-alerts in the context
of reduced hyper-alert correlation graphs.
Similar to alert aggregation, alert disaggregation is also performed in terms
of interval constraints and abstraction hierarchies. Specifically, given an aggregated hyper-alert, we may specify an interval threshold smaller than the one
used for aggregation and/or an abstraction level lower than the one used for the
aggregated hyper-alert, so that this aggregated hyper-alert is divided into multiple finer-grained hyper-alerts. For example, we may choose to disaggregate an
Mstream Zombie hyper-alert to level 3 abstraction according to the abstraction

188

P. Ning and D. Xu

hierarchy in Fig. 7. As a result, all the raw alerts that constitute the original
Mstream Zombie will be regrouped and re-aggregated based on their finer types
(Mstream Zombie Request or Mstream Zombie Response), resulting in two hyperalerts. In some sense, alert disaggregation is a re-application of a smaller interval
constraint threshold and a lower-level abstraction level to the raw alerts that constitute the select aggregated alert.
One way to effectively use alert aggregation/disaggregation is to use large enough
interval constraint threshold and the highest abstraction level for all hyper-alerts
when performing alert aggregation for the first time. This will result in concise
hyper-alert correlation graphs. After getting the high-level idea of the alerts in the
hyper-alert correlation graphs, we may select hyper-alerts in the graph and disaggregate them by reducing their abstraction levels and/or the interval constraint
threshold. This will regenerate the hyper-alert correlation graphs in a finer granularity for selected hyper-alerts. As a result, different levels of abstractions can be
used for different hyper-alerts in the same hyper-alert correlation graph. Moreover,
this also implies that the abstraction levels assigned to hyper-alert types have little
impact on the analysis results.

3.2 Focused Analysis
Focused analysis is to help an analyst focus on the hyper-alerts in which he or she
is interested. In particular, this may generate hyper-alert correlation graphs much
smaller and more comprehensible than the original ones.
Focused analysis is implemented on the basis of focusing constraints. A focusing
constraint is a logical combination of comparisons between attribute names and
constants. (In our work, we restrict logical operations to AND (^), OR (_), and NOT
(:).) For example, we may have a focusing constraint SrcIP D 129:174:142:2 _
DestIP D 129:174:142:2. We say a focusing constraint Cf is enforceable w.r.t. a
hyper-alert type T , if when we represent Cf in a disjunctive normal form, at least
for one disjunct Cf i , all the attribute names in Cf i appear in T . For example, the
above focusing constraint is enforceable w.r.t. T D .fSrcIP; SrcPortg; NULL; ;/, but
not w.r.t. T 0 D .fVictimIP; VictimPortg; NULL; ;/. Intuitively, a focusing constraint
is enforceable w.r.t. T if it can be evaluated using a hyper-alert instance of type T .
We may evaluate a focusing constraint Cf with a hyper-alert h if Cf is enforceable w.r.t. the type of h. A focusing constraint Cf evaluates to True for
h if there exists a tuple t 2 h such that Cf is True with the attribute names
replaced with the values of the corresponding attributes of t; otherwise, Cf evaluates to False. For example, consider the aforementioned focusing constraint Cf ,
which is SrcIP D 129:174:142:2 _ DestIP D 129:174:142:2, and a hyper-alert
h D f.SrcIP D 129:174:142:2; SrcPort D 80/g, we can easily have that Cf D True
for h.
The idea of focused analysis is quite simple: we only analyze the hyper-alerts
with which a focusing constraint evaluates to True. In other words, we would

Toward Automated Intrusion Alert Analysis

189

like to filter out irrelevant hyper-alerts and concentrate on analyzing the remaining hyper-alerts. We are particularly interested in applying focusing constraints to
atomic hyper-alerts, i.e., hyper-alerts with only one tuple. In our framework, atomic
hyper-alerts correspond to the alerts reported by an IDS directly.
Focused analysis is particularly useful when we have certain knowledge of the
alerts, the systems being protected, or the attacking computers. For example, if we
are interested in the attacks against a critical server with IP address Server IP, we
may perform a focused analysis using DestIP D Server IP. However, focused analysis cannot take advantage of the intrinsic relationship among the hyper-alerts (e.g.,
hyper-alerts having the same IP address). In the following, we introduce the third
utility, clustering analysis, to fill in this gap.

3.3 Clustering Analysis
Intuitively, clustering analysis is to partition a set of hyper-alerts into different
groups so that the hyper-alerts in each group share certain common features. As
a special case, we refer to the clustering analysis applied to a hyper-alert correlation graph as graph decomposition, since this operation will decompose the original
correlation graphs into subgraphs on the basis of the clusters.
We use a clustering constraint to specify the “common features” for clustering
hyper-alerts. Given two sets of attribute names A1 and A2 , a clustering constraint
Cc .A1 ; A2 / is a logical combination of comparisons between constants and attribute names in A1 and A2 . (In our work, we restrict logical operations to AND
(^), OR (_), and NOT (:).) A clustering constraint is a constraint for two hyperalerts; the attribute sets A1 and A2 identify the attributes from the two hyper-alerts.
For example, we may have two sets of attribute names A1 D fSrcIP; DestIPg and
A2 D fSrcIP; DestIPg, and Cc .A1 ; A2 / D .A1 :SrcIP D A2 :SrcIP/ ^ .A1 :DestIP D
A2 :DestIP/. Intuitively, this is to say two hyper-alerts should remain in the same
cluster if they have the same source and destination IP addresses.
A clustering constraint Cc .A1 ; A2 / is enforceable w.r.t. hyper-alert types T1 and
T2 if when we represent Cc .A1 ; A2 / in a disjunctive normal form, at least for one
disjunct Cci , all the attribute names in A1 appear in T1 and all the attribute names in
A2 appear in T2 . For example, the above clustering constraint is enforceable w.r.t.
T1 and T2 if both of them have SrcIP and DestIP in the fact component. Intuitively,
a clustering constraint is enforceable w.r.t. T1 and T2 if it can be evaluated using
two hyper-alerts of types T1 and T2 , respectively.
If a clustering constraint Cc .A1 ; A2 / is enforceable w.r.t. T1 and T2 , we can
evaluate it with two hyper-alerts h1 and h2 that are of type T1 and T2 , respectively. A clustering constraint Cc .A1 ; A2 / evaluates to True for h1 and h2 if there
exists a tuple t1 2 h1 and t2 2 h2 such that Cc .A1 ; A2 / is True with the attribute
names in A1 and A2 replaced with the values of the corresponding attributes of t1
and t2 , respectively; otherwise, Cc .A1 ; A2 / evaluates to False. For example, consider the clustering constraint Cc .A1 ; A2 /: .A1 :SrcIP D A2 :SrcIP/ ^ .A1 :DestIP D

190

P. Ning and D. Xu

A2 :DestIP/, and hyper-alerts h1 D f.SrcIP D 129:174:142:2; SrcPort D 1234;
DestIP D 152:1:14:5; DestPort D 80/g, h2 D f.SrcIP D 129:174:142:2;
SrcPort D 65333; DestIP D 152:1:14:5; DestPort D 23/g, we can easily have
that Cc .A1 ; A2 / D True for h1 and h2 . For brevity, we write Cc .h1 ; h2 / D True if
Cc .A1 ; A2 / D True for h1 and h2 .
Our clustering method is very simple, with a user-specified clustering constraint
Cc .A1 ; A2 /. Two hyper-alerts h1 and h2 are in the same cluster if Cc .A1 ; A2 /
evaluates to True for h1 and h2 (or h2 and h1 ). Note that Cc .h1 ; h2 / implies that
h1 and h2 are in the same cluster, but the reverse is not true. This is because
Cc .h1 ; h2 / ^ Cc .h2 ; h3 / (i.e., h1 , h2 , and h3 are in the same cluster) implies neither
Cc .h1 ; h3 / nor Cc .h3 ; h1 /.

3.4 Frequency Analysis
Frequency analysis is developed to help an analyst identify patterns in a collection
of alerts by counting the number of raw alerts that share some common features.
Similar to clustering analysis, frequency analysis partitions the input collection of
hyper-alerts. For example, an analyst may count the number of raw alerts that share
the same destination IP address to find the most frequently hit target. For convenience, we reuse the notion of clustering constraints to specify the clusters.
Frequency analysis can be applied in both count mode and weighted analysis
mode. In count mode, frequency analysis simply counts the number of raw intrusion
alerts that fall into the same cluster, while in weighted analysis mode, it adds all the
values of a given numerical attribute (called the weight attribute) of all the alerts in
the same cluster. As an example of frequency analysis in weighted analysis mode,
an analyst may use the priority of an alert type as the weight attribute, and learn the
weighted frequency of alerts for all destination IP addresses.
For convenience reasons, frequency analysis automatically ranks the clusters ascendantly or descendantly in terms of the results. A filter which specifies a range
of frequency values may be applied optionally so that only results that fall into this
range are returned to the analyst.
The frequency analysis utility is conceptually equivalent to applying clustering
analysis followed by a simple counting or summing for each of the clusters. However, since frequency analysis is developed for interactive analysis, it is much more
convenient for an analyst if there is a utility combining these operations together,
especially when not all the clusters need to be reported to the analyst.

3.5 Link Analysis
Link analysis is intended to analyze the connection between entities represented
by categorical attribute values. Examples include how two IP addresses are related

Toward Automated Intrusion Alert Analysis

191

to each other in a collection of alerts, and how IP addresses are connected to the
alert types. Though link analysis takes a collection of hyper-alerts as input, it indeed
analyzes the raw intrusion alerts corresponding to these hyper-alerts. Link analysis
can identify candidate attribute values, evaluate their importance according to a userdefined metric and rank them accordingly.
Link analysis takes at least two categorical attributes, A1 and A2 (e.g., source
IP and destination IP), as parameters. Similar to frequency analysis, link analysis
may be used in count mode or weighted analysis mode. In the latter case, link analysis needs an additional weight attribute with a numerical domain. For each pair of
attribute values .A1 D a1 ; A2 D a2 /, link analysis with categorical attributes A1
and A2 counts the number of all the alerts that have A1 D a1 and A2 D a2 in
count mode, or summarize the weight attribute values of these alerts in weighted
analysis mode.
Given a link analysis with categorical attributes A1 and A2 over a collection
of hyper-alerts, or equivalently, the corresponding set of raw intrusion alerts, we
call each pair of attribute values a link involving attributes A1 and A2 , denoted
.A1 D a1 ; A2 D a2 /. We then define the weight of a link .A1 D a1 ; A2 D a2 / as
the number of alerts that have A1 D a1 and A2 D a2 in count mode, or the sum
of the corresponding weight attribute values in weighted analysis mode. The weight
of an attribute value is then the sum of the weights of the links involving the value.
Specifically, the weight of A1 D a1 is the sum of the weights of all links that have
a1 as the value of A1 , while the weight of A2 D a2 is the sum of the weights of all
links that have a2 as the value of A2 .
Link analysis has two variations, dual-domain link analysis and uni-domain
link analysis, depending on the treatment of the values of the two categorical attributes. In dual-domain link analysis, values of the two categorical alert attributes
are considered different entities, even though they may have the same value. For
example, we may perform a dual-domain link analysis involving source IP address
and destination IP address. An IP address representing source IP is considered as a
different entity from the same IP address representing a destination IP address. In
contrast, uni-domain link analysis requires that the two attributes involved in link
analysis must have the same domain, and the same value is considered to represent
the same entity, no matter which attribute it corresponds to. In the earlier example,
the same IP address represents the same host, no matter it is a source or a destination
IP address.
The result of a link analysis can be visualized in a graphical format. Attribute
values are represented as nodes in the (undirected) graph, with different sizes representing the weight of the corresponding attribute values. When uni-domain link
analysis is used, all the nodes have the same shape (e.g., circle); when dual-domain
link analysis is used, two different shapes (e.g., circle and square) correspond to the
two different attributes, respectively. The link between two attribute values is represented by the edge connecting the corresponding nodes. The weight of each link is
indicated by the color of the edge. Figure 8 shows an example of a uni-domain link
analysis. Note that additional information (e.g., attribute values) about each node or
link can be obtained through a user interface.

192

P. Ning and D. Xu

Fig. 8 Visual representation of a uni-domain link analysis (Note that edges are in different colors)

Link analysis can be considered a special case of association analysis, which is
discussed next. However, due to its simplicity and the visual representation of its
results, we use link analysis as a separate utility.

3.6 Association Analysis
Association analysis is used to find out frequent co-occurrences of values belonging to different attributes that represent various entities. For example, we may
find through association analysis that many attacks are from source IP address
152.14.51.14 to destination IP address 129.14.1.31 at destination port 80. Such patterns cannot be easily found by frequency analysis because of the large number of
attribute combinations that would need to be analyzed using frequency analysis.
Association analysis is inspired by the notion of association rule, which was first
introduced in [1]. Given a set I of items, an association rule is a rule of the form
X ! Y , where X and Y are subsets (called item sets) of I and X \ Y D ;.
Association rules are usually discovered from a set T of transactions, where each
transaction is a subset of I . The rule X ! Y has a support s in the transaction set
T if s% of the transactions in T contain X [ Y , and it has a confidence c if c% of
the transactions in T that contain X also contain Y .
We do not use association rules directly; instead, we use the item sets that have
large enough support (called large item sets) to represent the patterns embedded
in alert attributes. We consider each raw alert a transaction. The large item sets
discovered from the intrusion alerts then represent frequent attribute patterns in the
alert set.

Toward Automated Intrusion Alert Analysis

193

Syntactically, association analysis takes a set S of categorical alert attributes and
a threshold t as parameters. Similar to frequency analysis and link analysis, association analysis can be applied in both count mode and weighted analysis mode. In the
latter mode, association analysis requires a numerical attribute (also called a weight
attribute) as an additional parameter. To facilitate the weighted analysis mode, we
extend the notion of support to weighted support. Given a set X of attribute values
and a weight attribute w, the weighted support of X w.r.t. w in the alert (transaction)
set T is
weighted supportw .X / D

sum of w of all alerts in T that contain X
:
sum of w of all alerts in T

Thus, association analysis of a collection of alerts in count mode finds all sets of
attribute values that have support more than t, while association analysis of a collection of alerts in weighted analysis mode returns all sets of attribute values that
have weighted support more than t.

3.7 Discussion
It is desirable to develop techniques that can comprehend a hyper-alert correlation
graph and generate feedback to direct intrusion detection and response processes.
We consider such a technique a part of our future research plan. However, given
the current status of intrusion detection and response techniques, it is also necessary
to allow human users to understand the attacks and take appropriate actions. The
utilities developed in this section are intended to help human users analyze attacks
behind large amounts of alerts. They can make attack strategies behind intensive
alerts easier to understand, but cannot improve the performance of alert correlation.

4 Learning Attack Strategies from Correlated Alerts
The correlation model can be used to construct attack scenarios (represented as
hyper-alert correlation graphs) from intrusion alerts. Although such attack scenarios
reflect attack strategies, they do not capture the essence of the strategies. Indeed,
even with the same attack strategy, if an attacker changes certain details during attacks, the correlation model will generate different hyper-alert correlation graphs.
For example, an attacker may repeat (unnecessarily) one step in a sequence of attacks many times, and the correlation model will generate a much more complex
attack scenario. As another example, if an attacker uses equivalent, but different attacks, the correlation model will generate different hyper-alert correlation graphs as
well. It is then up to the user to figure out manually the common strategy used in
two sequences of attacks. This certainly increases the overhead in intrusion alert
analysis.

194

P. Ning and D. Xu

In the following, we present a model to represent and automatically extract attack
strategies from correlated alerts. The goal of this model is to capture the invariants
in attack strategies that do not change across multiple instances of attacks.

4.1 Attack Strategy Graph
The strategy behind a sequence of attacks is indeed about how to arrange earlier attacks to prepare for the later ones so that the attacker can reach his or her final goal.
Thus, the prepare-for relations between the intrusion alerts (i.e., detected attacks)
is intrinsic to attack strategies. However, in the correlation model, the prepare-for
relations are between specific intrusion alerts; they do not directly capture the conditions that have to be met by related attacks. To facilitate the representation of the
invariant attack strategy, we transform the prepare-for relation into some common
conditions that have to be satisfied by all possible instances of the same strategy.
We represent such a condition as an equality constraint.
To clarify the notion of equality constraint, we need to explain the concept of
expanded consequence set. Given a hyper-alert type T , the expanded consequence
set of T , denoted EC.T /, is the set of all predicates that are implied by T ’s consequence set C.T /. Thus, C.T / ! EC.T /. EC.T / can be computed using the
implication relationships between predicates [27]. Given a type T hyper-alert h,
the expanded consequence set of h, denoted EC.h/), is the predicates in EC.T /
whose arguments are replaced with the corresponding attribute values of each tuple
in h. Each element in EC.h/ is associated with the timestamp of the corresponding
tuple in h.
In the following, we give the formal definition of equality constraint.
Definition 6. Given hyper-alert types T1 and T2 , an equality constraint for .T1 ; T2 /
is a conjunction of equalities in the form of u1 D v1 ^" " "^un D vn , where u1 ; " " " ; un
are attribute names in T1 and v1 ; " " " ; vn are attribute names in T2 , such that there
exist p.u1 ; " " " ; un / and p.v1 ; " " " ; vn /, which are the same predicate with possibly
different arguments, in EC.T1 / and P .T2 /, respectively. Given a type T1 hyperalert h1 and a type T2 hyper-alert h2 , h1 and h2 satisfy the equality constraint if
there exist t1 2 h1 and t2 2 h2 such that t1 :u1 D t2 :v1 ^ " " " ^ t1 :un D t2 :vn evaluates
to True.
There may be several equality constraints for a pair of hyper-alert types. However, if a type T1 hyper-alert h1 prepares for a type T2 hyper-alert h2 , then h1 and
h2 must satisfy at least one of the equality constraints. Indeed, h1 preparing for
h2 is equivalent to the conjunction of h1 and h2 satisfying at least one equivalent
constraint and h1 occurring before h2 . Assume that h1 occurs before h2 . If h1 and
h2 satisfy an equality constraint for .T1 ; T2 /, then by Definition 6, there must be a
predicate p.u1 ; " " " ; un / in EC.T1 / such that the same predicate with possibly different arguments, p.v1 ; " " " ; vn /, is in P .T2 /. Since h1 and h2 satisfy the equality

Toward Automated Intrusion Alert Analysis

195

constraint, p.u1 ; " " " ; un / and p.v1 ; " " " ; vn / will be instantiated to the same predicate in EC.h1 / and P .h2 /. This implies that h1 prepares for h2 . Similarly, if h1
prepares for h2 , there must be an instantiated predicate that appears in EC.h1 / and
P .h2 /. This implies that there must be a predicate with possibly different arguments in EC.T1 / and P .T2 / and that this predicate leads to an equality constraint
for .T1 ; T2 / satisfied by h1 and h2 .
Example 6. Consider the hyper-alert types: SadmindPing D (fVictimIP, VictimPortg, ExistsHost(VictimIP), fVulnerableSadmind (VictimIP)g), and SadmindBufferOverflow D (fVictimIP, VictimPortg, ExistHost (VictimIP) ^ VulnerableSadmind
(VictimIP), fGainRootAccess (VictimIP)g). The first hyper-alert type indicates that
SadmindPing is a type of attack that requires the existence of a host at the VictimIP, and as a result, the attacker may find out that this host has a vulnerable
Sadmind service. The second hyper-alert type indicates that this type of attacks
requires a vulnerable Sadmind service at the VictimIP, and as a result, the attack
may gain root access. It is easy to see that the predicate VulnerableSadmind is in
both P .SadmindBufferOverflow/ and EC .SadmindPing/. So, we have an equality
constraint VictimIP D VictimIP for (SadmindPing, SadmindBufferOverflow), where
the first VictimIP comes from SadmindPing, and the second VictimIP comes from
SadmindBufferOverflow.
We observe many times that one step in a sequence of attacks may trigger multiple intrusion alerts, and the number of alerts may vary in different situations.
This is partially due to the existing vulnerabilities and the hacking tools. For example, unicode shell [30], which is a hacking tool against Microsoft IIS web
server, checks about 20 vulnerabilities at the scanning stage and usually triggers
the same number of alerts. As another example, in the attack scenario reported in
[27], the attacker tried three different stack pointers and two commands in Sadmind Amslverify Overflow attacks for each victim host until one attempt succeeded.
Even if not necessary, an attacker may still deliberately repeat the same step multiple
times to confuse IDSs and/or system administrators. However, such variations do not
change the corresponding attack strategy. Indeed, these variations make the attack
scenarios unnecessarily complex, and may hinder manual or automatic analysis of
the attack strategy. Thus, we decide to disallow such situations in our representation
of attack strategies.
In the following, an attack strategy is formally represented as an attack strategy
graph.
Definition 7. Given a set S of hyper-alert types, an attack strategy graph over
S is a quadruple .N; E; T; C /, where (1) .N; E/ is a connected DAG; (2) T is a
mapping that maps each n 2 N to a hyper-alert type in S; (3) C is a mapping that
maps each edge .n1 ; n2 / 2 E to a set of equality constraints for .T .n1 /; T .n2 //;
(4) For any n1 ; n2 2 N , T .n1 / D T .n2 / implies that there exists n3 2 N such that
T .n3 / ¤ T .n1 /, and n3 is in a path between n1 and n2 .
In an attack strategy graph, each node represents a step in a sequence of related
attacks. Each edge .n1 ; n2 / represents that a type T .n1 / attack is needed to prepare

196

P. Ning and D. Xu

Sadmind_Ping
n1

Sadmind_Amslverify_Overflow

{n1.DestIP=n2.DestIP}

n2

{n2.DestIP=n3.SrcIP}

Rsh
n3

Mstream_Zombie
{n3.SrcIP=n4.SrcIP}

n4

Stream_Dos
{}

n5

Fig. 9 An example of attack strategy graph

for a successful type T .n2 / attack. Each edge may also be associated with a set
of equality constraints satisfied by the intrusion alerts. These equality constraints
indicate how one attack prepares for another. Finally, as represented by condition 4
in Definition 7, same type of attacks should be considered as one step, unless they
depend on each other through other types of attacks.
Now, let us see an example of an attack strategy graph.
Example 7. Figure 9 is the attack strategy graph extracted from the hyper-alert correlation graph in Fig. 5. The hyper-alert types are marked above the corresponding
nodes, and the equality constraints are labeled near the corresponding edges. This
attack strategy graph clearly shows the component attacks and the constraints that
the component attacks must satisfy.

4.2 Learning Attack Strategies
As discussed earlier, our goal is to learn attack strategies automatically from correlated intrusion alerts. This requires us to extract the constraints intrinsic to attack
strategy from alerts so that the constraints apply to all instances of the same strategy.
Our strategy to achieve this goal is to process the correlated intrusion alerts in two
steps. First, we aggregate intrusion alerts that belong to the same step of a sequence
of attacks into one hyper-alert. For example, in Fig. 5, alerts 67432, 67434, 67436,
and 67440 are indeed attempts of the same attack with different parameters, and thus
they should be aggregated as one step in the attack sequence. Second, we extract the
constraints between the attack steps and represent them as an attack strategy graph.
For example, after we aggregate the hyper-alerts in the first step, we may extract the
attack strategy graph shown in Fig. 9.
The challenge lies in the first step. Because of the variations of attacks as well as
the signatures that IDSs use to recognize attacks, there is no clear way to identify
intrusion alerts that belong to the same step in a sequence of attacks. In the following, we first attempt to use the attack type information to do so. The notion of
aggregatable hyper-alerts is introduced formally to clarify when the same type of
hyper-alerts can be aggregated.
Definition 8. Given a hyper-alert correlation graph C G D .N; E/, a subset
N 0 ! N is aggregatable, if (1) all nodes in N 0 are the same type of hyper-alerts,
and (2) 8n1 ; n2 2 N 0 , if there is a path from n1 to n2 , then all nodes in this path
must be in N 0 .

Toward Automated Intrusion Alert Analysis

197

Intuitively, in a hyper-alert correlation graph, where intrusion alerts have been
correlated together, the same type of hyper-alerts can be aggregated as long as they
are not used in different stages in the attack sequence. Condition 1 in Definition 8 is
quite straightforward, but condition 2 deserves more explanation. Consider the same
type of hyper-alerts h1 and h2 . If h1 prepares for a different type of hyper-alert h0
(directly or indirectly), and h0 further prepares for h2 (directly or indirectly), h1 and
h2 obviously belong to different steps in the same sequence of attacks. Thus, we
should not allow them to be aggregated together. Although we have never observed
such situations, we cannot rule out such possibilities.
Based on the notion of aggregatable hyper-alerts, the first step in learning attack
strategy from a hyper-alert correlation graph is quite straightforward. We only need
to identify and merge all aggregatable hyper-alerts. To proceed to the second step in
strategy learning, we need a hyper-alert correlation graph in which each hyper-alert
represents a separate step in the attack sequence. Formally, we call such a hyperalert correlation graph an irreducible hyper-alert correlation graph.
Definition 9. A hyper-alert correlation graph C G D .N; E/ is irreducible if for all
N 0 ! N , where jN 0 j > 1, N 0 is not aggregatable.
Figure 10 shows the algorithm to extract attack strategy graphs from hyperalert correlation graphs. The subroutine GraphReduction is used to generate an
irreducible hyper-alert correlation graph, and the rest of the algorithm extracts the
components of the output attack strategy graph. The steps in this algorithm are selfexplanatory; we do not repeat them in the text.

4.3 Dealing with Variations of Attacks
Algorithm 1 in Fig. 10 has ignored equivalent but different attacks in sequences of
attacks. For example, an attacker may use either pmap dump or Sadmind Ping to
find a vulnerable Sadmind service. As another example, an attacker may use either
SadmindBufferOverflow or TooltalkBufferOverflow attack to gain remote access to
a host. Obviously, at the same stage of two sequences of attacks, if an attacker uses
equivalent but different attacks, Algorithm 1 will return two different attack strategy
graphs, though the strategies behind them are the same.
We propose to generalize hyper-alert types so that the syntactic difference between equivalent hyper-alert types is hidden. For example, we may generalize
both SadmindBufferOverflow and TooltalkBufferOverflow attacks into RPCBufferOverflow.
A generalized hyper-alert type is created to hide the unnecessary difference
between specific hyper-alert types. Thus, an occurrence of any of the specific
hyper-alerts should imply an occurrence of the generalized one. This is to say that
satisfaction of the prerequisite of a specific hyper-alert implies the satisfaction of the
prerequisite of the generalized hyper-alert. Moreover, to cover all possible impact

198

P. Ning and D. Xu
Algorithm 1. ExtractStrategy
Input: A hyper-alert correlation graph C G.
Output: An attack strategy graph ASG.
Method:
1. Let C G 0 D GraphReduction (C G).
2. Let ASG D .N; E; T; C / be an empty attack strategy graph.
3. for each hyper-alert h in C G 0
4.
Add a new node, denoted nh , into N and set
T .nh / be the type of h.
5. for each edge .h; h0 / in C G 0
6.
Add .nh ; nh0 / into E.
7.
for each pc 2 EC.h/ and pp 2 P .h0 /
8.
if pc D pp then
9.
Add into C.nh ; nh0 / the equality constraint
.u1 D v1 / ^ " " " ^ .un D vn /, where ui and vi are
the i t h variable of pc and pp before instantiation, resp.
10. return ASG.N; E; T; C /.
Subroutine GraphReduction
Input: A hyper-alert correlation graph C G D .N; E/.
Output: An irreducible hyper-alert correlation graph C G 0 D .N 0 ; E 0 /.
Method:
1. Partition the hyper-alerts in N into groups such that the same
type of hyper-alerts are all in the same group.
2. for each group G
3.
if there is a path g; n1 ; " " " ; nk ; g 0 in C G such that only g
and g 0 in this path are in G then
4.
Divide G into G1 , G2 , and G3 such that all hyper-alerts
in G1 occur before n1 , all hyper-alerts in G3 occur after
nk , and all the other hyper-alerts are in G2 .
5. Repeat steps 2 to 4 until no group can be divided.
6. Aggregate the hyper-alerts in each group into one hyper-alert.
7. Let N 0 be the set of aggregated hyper-alerts.
8. for all n1 ; n2 2 N 0
9.
if there exists .h1 ; h2 / 2 E and h1 and h2 are aggregated
into n1 and n2 , resp.
10.
add .n1 ; n2 / into E 0 .
11. return C G 0 D .N 0 ; E 0 /.

Fig. 10 Algorithm for extracting attack strategy graphs

of all the specific hyper-alerts, the consequences of all the specific hyper-alert types
should be included in the consequence of the generalized hyper-alert type. It is easy
to see that this generalization may cause loss of information. Thus, generalization
of hyper-alert types must be carefully handled so that information essential to attack
strategy is not lost.
In the following, we formally clarify the relationship between specific and generalized hyper-alert types.
Definition 10. Given two hyper-alert types Tg and Ts , where Tg D .factg ; prereqg ;
conseqg / and Ts D .facts ; prereqs ; conseqs /, we say Tg is more general than Ts

Toward Automated Intrusion Alert Analysis

199

(or, equivalently, Ts is more specific than Tg ) if there exists an injective mapping f
from f actg to f acts such that the following conditions are satisfied:
# If we replace all variables x in prereqg with f .x/, prereqs implies prereqg ,

and

# If we replace all variables x in conseqg with f .x/, then all formulas in conseqs

are implied by conseqg .

The mapping f is called the generalization mapping from Ts to Tg .
Example 8. Consider hyper-alert types SadmindBufferOverflow and TooltalkBufferOverflow: SadmindBufferOverflow D (fVictimIP, VictimPortg, ExistHost
(VictimIP) ^ VulnerableSadmind (VictimIP), fGainRootAccess (VictimIP)g),
and TooltalkBufferOverflow D (fVictimIP, VictimPortg, ExistHost (VictimIP) ^
VulnerableTooltalk (VictimIP), fGainRootAccess (Victim-IP)g). Assume that VulnerableSadmind (VictimIP) imply VulnerableRPC (VictimIP). Intuitively, this
represents that if there is a vulnerable Sadmind service at VictimIP, then there
must be a vulnerable RPC service (i.e., the Sadmind service) at VictimIP. Similarly,
we assume VulnerableTooltalk (VictimIP) also implies VulnerableRPC (VictimIP).
We can generalize both SadmindBufferOverflow and TooltalkBufferOverflow into
RPCBufferOverflow D (fVictimIPg, ExistHost (VictimIP) ^ VulnerableRPC (VictimIP), fGainRootAccess (VictimIP)g), where the generalization mapping only
includes f .V i cti mIP / D V i cti mIP .
By identifying a generalization mapping, we can specify how a specific hyperalert can be generalized into a more general hyper-alert. Following the generalization mapping, we can find out what attribute values of a specific hyper-alert should
be assigned to the attributes of the generalized hyper-alert. The attack strategy learning algorithm can be easily modified: We first generalize the hyper-alerts in the input
hyper-alert correlation graph into generalized hyper-alerts following the generalization mapping, and then apply Algorithm 1 to extract the attack strategy graph.
Although a hyper-alert can be generalized in different granularities, it is not
an arbitrary process. In particular, if one hyper-alert prepares for another hyperalert before generalization, the generalized hyper-alerts should maintain the same
relationship. Otherwise, the dependency between different attack stages, which is
intrinsic in an attack strategy, will be lost.
The remaining challenge is how to get the “right” generalized hyper-alert types
and generalization mappings. The simplest way is to manually specify them. For
example, Apache2, Back, and Crashiis are all Denial of Service attacks. We may
simply generalize all of them into one WebServiceDOS. However, there are often
different ways to generalize. To continue the above example, Apache2 and Back attacks are against the apache web servers, while Crashiis is against the Microsoft IIS
web server. To keep more information about the attacks, we may want to generalize
Apache and Back into ApacheDOS, while generalize Crashiis and possibly other
DOS attacks against the IIS web server into IISDOS. Nevertheless, this does not
affect the attack strategy graphs extracted from correlated intrusion alerts as long as
the constraints on the related alerts are satisfied.

200

P. Ning and D. Xu

4.3.1 Automatic Generalization of Hyper-Alert Types
It is time-consuming and error-prone to manually generalize hyper-alert types. One
way to partially automate this process is to use clustering techniques to identify
the hyper-alert types that should be generalized into a common one. In our experiments, we use the bottom-up hierarchical clustering [16] to group hyper-alert types
hierarchically on the basis of the similarity between them, which is derived from
the similarity between the prerequisites and consequences of hyper-alert types. The
method used to compute the similarity is described below.
To facilitate the computation of similarity between prerequisites of hyper-alert
types, we convert each prerequisite into an expanded prerequisite set, which includes all the predicates that appear or are implied by the prerequisite. Similarly,
we can get the expanded consequence set. Consider two sets of predicates, denoted
S1 and S2 , respectively. We adopt the Jaccard similarity coefficient [15] to compute
the similarity between S1 and S2 , denoted S i m.S1 ; S2 /. That is, S i m.S1 ; S2 / D
a
, where a is the number of predicates in both S1 and S2 , b is the number of
aCbCc
predicates only in S1 , and c is the number of predicates only in S2 .
Given two hyper-alert types T1 and T2 , the similarity between T1 and T2 , denoted S i m.T1 ; T2 /, is then computed as S i m.T1 ; T2 / D S i m.XP1 ; XP2 / # wp C
S i m.XC1 ; XC2 / # wc ; where XP1 and XP2 are the expanded prerequisite sets of
T1 and T2 , XC1 and XC2 are the expanded consequence sets of T1 and T2 , and wp
and wc D 1 $ wp are the weights for prerequisite and consequence, respectively.
(In our experiments, we use wp D wc D 0:5 to give equal weight to both prerequisite and consequence of hyper-alert types.) We may then set a threshold t so that two
hyper-alert types are grouped into the same cluster only if their similarity measure
is greater than or equal to t.
We have performed a series of experiments to study the proposed techniques
[29]. Figure 11 shows one of the attack strategy graphs extracted from the 2000
DARPA intrusion detection scenario specific data set in our experiments. Based on
the description of the data set [23], we know that Fig. 11 has captured most of the
attack strategy. The missing parts are due to the attacks missed by the IDSs. For
more information, please refer to [29].

5 Related Work
Intrusion detection has been studied for more than twenty years, since Anderson’s
report [3]. A survey of the early work on intrusion detection is given in [25], and an
excellent overview of current intrusion detection techniques and related issues can
be found in a recent book [4].
Research on intrusion alert correlation has been rather active recently. The first
class of approaches (e.g., Spice [36], probabilistic alert correlation [38], and the
alert clustering methods in [5] and [18]) correlates alerts based on the similarities

Toward Automated Intrusion Alert Analysis

201

n1: FTP_Syst
{n1.DestIP=n2.DestIP}
{n1.DestIP=n3.DestIP}

n2: Sadmind_Ping
{n2.DestIP=n3.DestIP}

n3: Sadmind_Amslverify_Overflow

n4: Email_Almail_Overflow

{n3.DestIP=n5.SrcIP}

{n4.DestIP=n5.SrcIP}

{n3.DestIP=n6.SrcIP} n5: Rsh

{n4.DestIP=n6.SrcIP}

{n5.SrcIP=n6.SrcIP}

n6: Mstream_Zombie
{}
n7: Stream_DoS

Fig. 11 An attack strategy graph extracted in our experiments

between alert attributes. Though they are effective for clustering similar alerts (e.g.,
alerts with the same source and destination IP addresses), they cannot fully discover
the causal relationships between related alerts.
Another class of methods (e.g., correlation based on STATL [11] or
LAMBDA [7], and the data mining approach [8]) performs alert correlation based
on attack scenarios specified by human users or learned from training datasets. A
limitation of these methods is that they are restricted to known attack scenarios, or
those that can be generalized from known scenarios. A variation in this class uses a
consequence mechanism to specify what types of attacks may follow a given attack,
partially addressing this problem [9].
A third class of methods, including JIGSAW [37], the MIRADOR correlation
method [6], and our approach, targets recognition of multistage attacks; it correlates
alerts if the prerequisites of some later alerts are satisfied by the consequences of
some earlier alerts. Such methods can potentially uncover the causal relationship
between alerts, and are not restricted to known attack scenarios.
Our method can be considered as a variation of JIGSAW [37]. Both methods try
to uncover attack scenarios based on specifications of individual attacks. However,
our method also differs from JIGSAW. First, our method allows partial satisfaction of prerequisites (i.e., required capabilities in JIGSAW [37]), recognizing the
possibility of undetected attacks and that of attackers gaining information through
non-intrusive ways (e.g., talking to a friend working in the victim organization),
while JIGSAW requires all required capabilities be satisfied. Second, our method
allows aggregation of alerts, and thus can reduce the complexity involved in alert

202

P. Ning and D. Xu

analysis, while JIGSAW currently does not have any similar mechanisms. Third,
we develop a set of utilities for alert correlation and interactive analysis of correlated alerts, which is not provided by JIGSAW.
The work closest to ours is the MIRADOR correlation method proposed in [6],
which was developed independently and in parallel to ours. These two methods
share substantial similarity. The MIRADOR approach also correlates alerts using
partial match of prerequisites (pre-conditions) and consequences (post-conditions)
of attacks. However, the MIRADOR approach uses a different formalism than ours.
In particular, the MIRADOR approach treats alert aggregation as an individual stage
before alert correlation, while our method allows alert aggregation during and after
correlation. As we have seen in Sect. 3, our treatment of alert aggregation leads to
the three utilities for interactive alert analysis.
A formal model named M2D2 was proposed in [24] to correlate alerts using
multiple information sources, including the characteristics of the monitored systems, the vulnerability information, the information about the monitoring tools, and
information of the observed events. Due to the multiple information sources used in
alert correlation, this method can potentially lead to better results than those simply
looking at intrusion alerts. A mission-impact-based approach was proposed in [32]
to correlate alerts raised by INFOSEC devices such as IDSs and firewalls. A distinguishing feature of this approach is that it correlates the alerts with the importance of
system assets so that attention can be focused on critical resources. These methods
are complementary to ours.
Several languages have been proposed to represent attacks, including STAT
[11,14,39], Colored-Petri Automata (CPA) [19,20], LAMBDA [7], and MuSig [21].
In particular, LAMBDA uses a logic-based method to specify the pre-condition
and post-condition of attack scenarios, which is similar to our method. However,
all these languages specify entire attack scenarios, which are limited to known
scenarios. In contrast, our method (as well as JIGSAW and the MIRADOR correlation method) describes prerequisites and consequences of individual attacks, and
correlates detected attacks (i.e., alerts) based on the relationship between these prerequisites and consequences. Thus, our method can potentially correlate alerts in
unknown attack scenarios.
Alert correlation has been studied in the context of network management (e.g.,
[13], [34], and [12]). In theory, alert correlation methods for network management
are applicable to intrusion alert correlation. However, intrusion alert correlation
faces more challenges than its counter part in network management: While alert
correlation for network management deals with alerts about natural faults, which
usually exhibit regular patterns, intrusion alert correlation has to cope with less predictable, malicious intruders.
Our approach to learning attack strategies from correlated alerts is also closely
related to techniques for static vulnerability analysis (e.g., [2, 17, 33, 35]). In particular, the methods in [2, 35] also use a model of exploits (possible attacks) in
terms of their pre-conditions (prerequisites) and post-conditions (consequences).
Our approach complements static vulnerability analysis methods by providing the

Toward Automated Intrusion Alert Analysis

203

capability of examining the actual execution of attack strategies in different details
(e.g., an attacker tries different variations of the same attack) and thus gives human
users more information to respond to attacks.

6 Conclusion
This article summarized a series of research efforts toward automating the analysis of intrusion alerts. These efforts start with a practical method for constructing
attack scenarios through alert correlation, using prerequisites and consequences of
attacks. We proposed a formal framework to represent alerts along with their prerequisites and consequences, and developed a method to correlate related hyper-alerts
together, including an intuitive representation of correlated alerts that reveals the attack scenario of the corresponding attacks. To facilitate the analysis of large sets of
correlated alerts, we also developed several interactive utilities. Finally, to automate
the analysis of intrusion alerts, we developed a method to extract attack strategies
from correlated intrusion alerts.
The research described in this article is only a part of the effort toward automated
intrusion alert analysis. More research is desirable to make automated intrusion
analysis practical. In particular, it would be useful to integrate intrusion related information from multiple sources, such as IDSs, vulnerability scanning tools, and OS
or application logs.

References
1. R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in
large databases. In Proceedings of the 1993 International Conference on Management of Data,
pages 207–216, 1993.
2. P. Ammann, D. Wijesekera, and S. Kaushik. Scalable, graph-based network vulnerability analysis. In Proceedings of the 9th ACM Conference on Computer and Communications Security,
pages 217–224, November 2002.
3. J. P. Anderson. Computer security threat monitoring and surveillance. Technical report, James
P. Anderson Co., Fort Washington, PA, 1980.
4. R. G. Bace. Intrusion Detection. Macmillan Technology Publishing, Indianapolis, 2000.
5. F. Cuppens. Managing alerts in a multi-intrusion detection environment. In Proceedings of the
17th Annual Computer Security Applications Conference, December 2001.
6. F. Cuppens and A. Miege. Alert correlation in a cooperative intrusion detection framework. In
Proceedings of the 2002 IEEE Symposium on Security and Privacy, May 2002.
7. F. Cuppens and R. Ortalo. LAMBDA: A language to model a database for detection of attacks. In Proceedings of Recent Advances in Intrusion Detection (RAID 2000), pages 197–216,
September 2000.
8. O. Dain and R. K. Cunningham. Fusing a heterogeneous alert stream into scenarios. In Proceedings of the 2001 ACM Workshop on Data Mining for Security Applications, pages 1–13,
November 2001.
9. H. Debar and A. Wespi. Aggregation and correlation of intrusion-detection alerts. In Recent
Advances in Intrusion Detection, LNCS 2212, pages 85–103, 2001.

204

P. Ning and D. Xu

10. DEFCON. Def con capture the flag (CTF) contest. http://www.defcon.org/html/defcon-8post.html, July 2000. Archive accessible at http://wi2600.org/mediawhore/mirrors/shmoo/.
11. S. T. Eckmann, G. Vigna, and R. A. Kemmerer. STATL: An Attack Language for State-based
Intrusion Detection. Journal of Computer Security, 10(1/2):71–104, 2002.
12. R. Gardner and D. Harle. Pattern discovery and specification translation for alarm correlation. In Proceedings of Network Operations and Management Symposium (NOMS’98), pages
713–722, February 1998.
13. B. Gruschke. Integrated event management: Event correlation using dependency graphs. In
Proceedings of the 9th IFIP/IEEE International Workshop on Distributed Systems: Operations
& Management, October 1998.
14. K. Ilgun, R. A. Kemmerer, and P. A. Porras. State transition analysis: A rule-based intrusion
detection approach. IEEE Transaction on Software Engineering, 21(3):181–199, 1995.
15. D. A. Jackson, K. M. Somers, and H. H. Harvey. Similarity coefficients: Measures of cooccurence and association or simply measures of occurrence? The American Naturalist,
133(3):436–453, March 1989.
16. A. K. Jain and R. C. Dubes. Algorithms for Clustering Data. Prentice Hall, Englewood Cliffs,
1988.
17. S. Jha, O. Sheyner, and J. M. Wing. Two formal analyses of attack graphs. In Proceedings of
the 15th Computer Security Foundation Workshop, June 2002.
18. K. Julisch. Mining alarm clusters to improve alarm handling efficiency. In Proceedings of the
17th Annual Computer Security Applications Conference (ACSAC), pages 12–21, December
2001.
19. S. Kumar. Classification and Detection of Computer Intrusions. PhD thesis, Purdue University,
August 1995.
20. S. Kumar and E. H. Spafford. A pattern matching model for misuse intrusion detection. In
Proceedings of the 17th National Computer Security Conference, pages 11–21, October 1994.
21. J. Lin, X. S. Wang, and S. Jajodia. Abstraction-based misuse detection: High-level specifications and adaptable strategies. In Proceedings of the 11th Computer Security Foundations
Workshop, pages 190–201, Rockport, MA, June 1998.
22. S. Manganaris, M. Christensen, D. Zerkle, and K. Hermiz. A data mining analysis of RTID
alarms. Computer Networks, 34:571–577, 2000.
23. MIT Lincoln Lab. 2000 DARPA intrusion detection scenario specific datasets.
http://www.ll.mit.edu/IST/ideval/data/2000/2000 data index.html, 2000.
24. B. Morin, L. MKe, H. Debar, and M. DucassKe. M2D2: A formal data model for IDS alert correlation. In Proceedings of the 5th International Symposium on Recent Advances in Intrusion
Detection (RAID 2002), pages 115–137, 2002.
25. B. Mukherjee, L. T. Heberlein, and K. N. Levitt. Network intrusion detection. IEEE Network,
8(3):26–41, May 1994.
26. P. Ning, Y. Cui, and D. S Reeves. Analyzing intensive intrusion alerts via correlation. In Proceedings of the 5th International Symposium on Recent Advances in Intrusion Detection (RAID
2002), pages 74–94, Zurich, Switzerland, October 2002.
27. P. Ning, Y. Cui, and D. S Reeves. Constructing attack scenarios through correlation of intrusion
alerts. In Proceedings of the 9th ACM Conference on Computer and Communications Security,
pages 245–254, Washington, D.C., November 2002.
28. P. Ning and D. Xu. Adapting query optimization techniques for efficient intrusion alert correlation. In Proceedings of the 17th IFIP WG 11.3 Working Conference on Data and Application
Security (DAS ’03), August 2003.
29. P. Ning and D. Xu. Learning attack stratagies from intrusion alerts. In Proceedings of the 10th
ACM Conference on Computer and Communications Security, pages 200–209, October 2003.
30. Packet storm. http://packetstormsecurity.nl. Accessed on April 30, 2003.
31. P. A. Porras and P. G. Neumann. EMERALD: Event monitoring enabling response to anomalous live disturbances. In Proceedings of the 20th National Information Systems Security
Conference, National Institute of Standards and Technology, 1997.

Toward Automated Intrusion Alert Analysis

205

32. P. A. Porras, M. W. Fong, and A. Valdes. A mission-impact-based approach to INFOSEC
alarm correlation. In Proceedings of the 5th International Symposium on Recent Advances in
Intrusion Detection (RAID 2002), pages 95–114, 2002.
33. C. R. Ramakrishnan and R. Sekar. Model-based analysis of configuration vulnerabilities. Journal of Computer Security, 10(1/2):189–209, 2002.
34. L. Ricciulli and N. Shacham. Modeling correlated alarms in network management systems. In
In Western Simulation Multiconference, 1997.
35. O. Sheyner, J. Haines, S. Jha, R. Lippmann, and J. M. Wing. Automated generation and analysis
of attack graphs. In Proceedings of IEEE Symposium on Security and Privacy, May 2002.
36. S. Staniford, J. A. Hoagland, and J. M. McAlerney. Practical automated detection of stealthy
portscans. Journal of Computer Security, 10(1/2):105–136, 2002.
37. S. Templeton and K. Levitt. A requires/provides model for computer attacks. In Proceedings
of New Security Paradigms Workshop, pages 31 – 38. ACM Press, September 2000.
38. A. Valdes and K. Skinner. Probabilistic alert correlation. In Proceedings of the 4th International
Symposium on Recent Advances in Intrusion Detection (RAID 2001), pages 54–68, 2001.
39. G. Vigna and R. A. Kemmerer. NetSTAT: A network-based intrusion detection system. Journal
of Computer Security, 7(1):37–71, 1999.

