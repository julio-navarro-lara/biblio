Recognizing Malicious Intention in an Intrusion Detection Process     Ą ˘
ege & Salem Benferhat Fr´ ed´ eric Cuppens , Fabien Autrel , Alexandre Mi` 1: ONERA Toulouse, 2 Av. E. Belin, 31055 Toulouse Cedex, France, 2: ENST Paris, 46 rue Barrault, 75014 Paris CEDEX, France, 3: IRIT, 118 route Ł de Narbonne, 31062 Toulouse CEDEX, France email: cuppens,autrel,miege ¤ @cert.fr, benferhat@irit.fr
Abstract. Generally, the intruder must perform several actions, organized in an intrusion scenario, to achieve his or her malicious objective. We argue that intrusion scenarios can be modelled as a planning process and we suggest modelling a malicious objective as an attempt to violate a given security requirement. Our proposal is then to extend the definition of attack correlation presented in [CM02] to correlate attacks with intrusion objectives This notion is useful to decide if a sequence of correlated actions can lead to a security requirement violation. This approach provides the security administrator with a global view of what happens in the system. In particular, it controls unobserved actions through hypothesis generation, clusters repeated actions in a single scenario, recognizes intruders that are changing their intrusion objectives and is efficient to detect variations of an intrusion scenario. This approach can also be used to eliminate a category of false positives that correspond to false attacks, that is actions that are not further correlated to an intrusion objective.

1 Introduction The main objective of computer security is to design and develop computer systems that conform to the specification of a security policy. A security policy is a set of rules that specify the authorizations, prohibitions and obligations of agents (including both users and applications) that can access to the computer system. An intruder might be viewed as a malicious agent that tries to violate the security policy. Notice that sometimes the intruder might perform his intrusion by using a single action. However, more complex intrusions generally require several steps to be performed. For instance, there are two steps in the Mitnick attack. In the first step, the intruder floods a given host Ľ . Then the intruder sends spoofed SYN messages corresponding to Ľ address to establish a TCP connection with a given server Ś . When Ś sends a SYN-ACK message, Ľ would normally send a RESET message to close the connection. But this is not possible since Ľ is flooded. This enables the intruder to send an ACK message to illegally open a connection with Ś . Notice also that opening a TCP connection with Ś is probably not the intruder's final objective. It is likely that the intruder will then attempt to get an access on Ś for instance by performing a rlogin. This means that the Mitnick attack will actually represent preliminary steps of a more global intrusion. In the following, we shall call intrusion scenario the complete sequence of actions that enables the intruder to achieve his intrusion objective.

In this context, current intrusion detection technology only detects elementary attacks that correspond to the steps of a given intrusion scenario. They neither provide a global view of the intrusion scenarios in progress nor of the intrusion objectives the intruders attempt to achieve. Therefore, our goal in this paper is twofold. First, we suggest an approach to recognize various steps of an intrusion scenario. We shall call attack correlation this first functionality. It is actually an extension of the approach suggested in [CM02]. Second, when the attack correlation succeeds in gathering several actions, we want to decide whether the current observations actually correspond to malicious activities or not. We call malicious intention recognition this second functionality. Combining these two functionalities would enable the security administrator to have a global understanding of what happens in the system in order to prepare an adequate reaction. Notice that sometimes, this reaction might be launched before the intrusion scenario is completed, that is before the intrusion objective is actually achieved. The remainder of this paper is organized as follow. Section 2 introduces preliminary definitions to fix the vocabulary. Section 3 presents our approach to modelling the intrusion process. Derived from planning process models in Artificial Intelligence, this model includes a representation of both attacks and intrusion objectives. Section 4 then presents our approach for modelling the intrusion detection process. Based on these materials and following [CM02], we define the notion of attack and alert correlation and also correlation between an attack and an intrusion objective. Section 5 further refines our approach by introducing hypothesis generation in the correlation process. This is useful to complete detection of an intrusion scenario when some steps in this scenario are not detected (false negatives). This is also useful to anticipate over the intruder intentions when several actions that match an intrusion scenario have been correlated. Section 6 illustrates our approach on several examples of intrusion scenarios. Finally section 7 concludes the paper. 2 Preliminary definitions 2.1 Intrusion objective and intrusion scenario Intrusion objective (intrusion detection point of view) An intrusion objective is the final purpose of an intruder, which justifies all its actions. So, from its point of view, the intrusion objective is obvious. By contrast, from the intrusion detection point of view, it is more difficult to determine the possible intrusion objectives and to differentiate them from non malicious activities. As an intruder aims at committing a forbidden action, we suggest deriving the possible intrusion objectives from the security policy: any security policy violation is a potential intrusion objective. We give three examples corresponding to integrity, confidentiality, and availability violation: gaining a non authorized root access right (Objective 1), having a non authorised read access to a sensitive file (Objective 2), performing a denial of service attack on the DNS (Objective 3). Intrusion scenario As an intrusion objective will often needs several actions to be reached, the intruder needs to draw up an intrusion scenario. It is an organised set of correlated actions, which have to be executed following a certain order. Let us present three intrusion scenarios corresponding to the intrusion objectives described just before. 1. Illegal NFS mount: the intruder, say badguy, wants to obtain a root access on a target. badguy can perform the following actions: (1) rpcinfo to know if portmapper is running

on the target, (2) with the showmount command, badguy sees the target exportable partitions, (3) mount enables badguy to mount one of this partition, say the root partition, (4) by modifying the .rhost file of this partition, (5) badguy gets a root access on the target system, (6) rlogin is the final step to access the target system with root privileges. 2. DoS on the DNS: this intrusion scenario leads to a DoS attack on the DNS server. A possible scenario is: (1) nslookup to locate the DNS server, (2) ping to check whether the DNS server is active, (3) scan port 139 (NetBios) to get evidence that Windows is active on the DNS, (4) winnuke that performs a DOS attack on Windows machine. 3. Illegal file access: we shall consider the following intrusion scenario example where an unauthorised user bad guy tries to read secret-file [ZMB02]: (1) bad guy creates a file (touch file), (2) bad guy blocks the printer, by opening the paper trays, (3) lpr -s enables bad guy to print file, (4) bad guy deletes file, (5) bad guy creates a symbolic link from file to secret-file: ln -s file secret-file, (6) bad guy unblocks the printer and secret-file will be printed. 2.2 Malicious and suspicious actions Malicious action A malicious action enables the intruder to directly achieve an intrusion objective. For instance, thanks to the Winnuke attack, an intruder can do a denial of service on a Windows server. Action correlation (informal definition) §Š¨ may enable the intruder to then perform §Š¨ Ą .

 

is correlated with

§¨ Ą

if

§Š¨ !"  

Suspicious action A suspicious action is defined as an action that can be correlated to a malicious action or to another suspicious action. According to this definition, a suspicious action may be an inoffensive action, or may also be a way to execute a malicious action on a following step. For example, scanning port 139 (NetBios) is not a dangerous action. But, if port 139 is open, the intruder knows that Windows is running and can perform the Winnuke attack. Attack An attack is a malicious action or a suspicious action. This is quite a weak definition of "attack" since it also includes suspicious actions. However, we guess it is close to the intrusion detection terminology since many alerts actually correspond to only suspicious actions. 2.3 Fusion and correlation process Fusion process and fusion alert The simple alerts generated by different IDS detecting the same attack are merged into a single cluster. This is called fusion process. It determines first which are the merging criteria for each type of attack, and then, during the intrusion detection process, uses those criteria to constitute clusters. At last, it generates a fusion alert to inform all the security devices of the creation and the content of a new cluster. The fusion process is not the purpose of this paper; see [Cup01, VS01] for different proposals.

Correlation process and scenario alert The correlation process receives the fusion alerts and tries to correlate them one by one using correlation rules. When a complete or a partial intrusion scenario is detected, a scenario alert is generated. The purpose of this paper is to extend this correlation process suggested in [CM02]. 3 Modelling intrusion from the intruder point of view In our approach the intrusion process is modelled as a planning activity. We assume that the intruder wants to achieve intrusion objectives and, for this purpose, the intruder can use a set of attacks. The intruder's problem is to find a sequence of attacks that transforms a given initial state into a final state. The initial state corresponds to the system state when the intruder starts his intrusion. And the final state has the property that the intrusion objective is achieved in this state. We check this approach on several intrusion scenarios, including the three scenarios presented in section 2 but also other scenarios such as the Mitnick attack. Due to space limitation, we shall only illustrate scenario 3 "illegal file access" as a planning process. But before, we need to present our approach to model attacks and intrusion objectives. 3.1 Action representation In the planning context, actions are represented by their pre and post conditions. Pre conditions correspond to conditions the system's state must satisfy to perform the action. Post conditions correspond to effects of executing the action on the system's state. Note that in the modelling of intrusion process system's state is only partially known. In our model, an attack is similarly represented using three fields: its name, pre condition and post condition. Attack name is a functional expression that represents the name of the attack and its different parameters. Attack pre-condition specifies the minimal logical conditions to be satisfied for the attack to succeed and attack post-condition is a logical condition that specifies the minimal effect of the attack when this attack succeeds. The pre-condition and post-condition of an attack correspond to conditions over the system's state. For this purpose, we use a language, denoted #   , which is based on the logic of predicates. Predicates are used to describe properties of the system state relevant to the description of an attack. In this language, we assume that terms starting by an upper case letter correspond to variables and other terms are constants. The predicates are combined using the logical connectives "," (conjunction denoted by a comma) and "not" (negation). Currently, we do not allow using disjunction in the pre and post conditions of an attack. This means that negation only applies to predicates, not to conjunctive expressions. Taking into account disjunctions is left for future work. Figure 1 shows how various actions of the example illegal file access are represented in this (0) ¨01 model. )3254 -6 ,To 487@model 9 A 7 , this )  -6 scenario, (') we actually specify 8 actions. The 6 first actions $%¨'& , , and $B ¨'1 correspond to the various actions performed by the intruder in the illegal file access scenario as presented in section 2. 254 254 7 7 )7 Our model includes two additional actions % - ¨ 66 and C  - DE that usually do 2F4 2F4 7 4 7Q4R #ST1BU models what happens on not appear in this example. Action B - ¨ 6"6HGPI % I 4 B 7@4 when #ST1 is queued: a file is printed if I 4 % 7@4 )7 is not blocked.  ) 7 7  -DE This )X7 G§YC printed 7 % R V file )`7 U W V  C will be VW if there is a logical link between #SE1 and . Action 7  )X7 after it is printed. This corresponds to the physical action performed by §aC B to get )VW 7 7 last action actually enables §aC % to obtain a read access to VW .

Action Pre: Post: Action Pre:

b!cd8ePfhgpirqst"buvxwpys b!ds 8w3ys'gvw3ys PuctHs Qg3iqs t"bu!vw3ys 

ye8 -'g3iqs t"bu!xwt"b!s u!vw3ys  wt"b!sQgxwt"b!s Pu8w3ys'gvw3ys Pu Qdb!fcwf0s d8g3irqst"bus @d8uvxwpys Post: gd8sd8sd8gvxw3ys0uxwt"b!s Action yt - 0gpirqst"bum%wtHHu!vw3ys  Pre: not g8w3ys0gm%wtH"l Post: ywtHs dgm%wtHHu!vw3ys  wt"b -cePs 'gwt"b!s um%wtH" gds ds d8gm%wtHHuxwt"b!su ywtHs d8gm%wtHHuvxw3ysu not gycePs dgxwt"b!s` Post: wt"b!s dgxwt"b!suvxwpys Pu not ggd8s ds d8gm%wtHHuxwt"b!s l
Action Pre: Intrusion Objective State Condition:

ycePg3irqst"buxwt"b!s 8wt"b!s Qgwt"b!s Pu f80 weP'y @eePs 'g3irqst"buxwt"b!s Post: yceP"sd8gwt"b!s  Action shicj0s'g3iqs t"bu!vxwpys  Pre: cktHsQgpirqst"buvxwpys Post: not gwpys'gvxwpys l
Action Pre:

dtHXycePHgpirqs t"buxwt"b!s  8wt"b!s Qgwt"b!s PuyceP"sd8gwt"b!s Pu f80 weP'y @eePs 'g3irqst"buxwt"b!s Post: not gyceP"sd8gwt"b!s l Action qsXb - 8wpys0gpirqst"buvxwpys Pre: 8wt"b!s d8gxwt"b!s u!vw3ys Pu f80 weP'y @eePs 'g3irqst"buxwt"b!s Post: sQd QePePs 'g3iqs t"bu!vw3ys 
Action Pre:

Figure 1: Modelling the illegal file access scenario

wpy3ysXq'y ccb @eePs 'gnWcXb! ccb @eePs 'g3irqst"bunWcXb!Pu not g@db!f8cwf'sd8g3iqs t"bu!ccbunWcXb!l Intrusion Objective wpy3ysXq'y wpys QePes 0gvxwpys State Condition: sQd QePePs 'g3iqs t"bu!vxwpys Pu not g@db!f8cwf'sd8g3iqs t"bu!s Qd8u!vxwpys l Intrusion Objective oYpxq ct oYrWqEgnWcXb! State Condition: d@tH  sj'sQgnWcb!u!dQc'gnWcXb!
Figure 2: Examples of intrusion objectives

3.2 Modelling intrusion objective An intrusion objective is modelled by a system state condition that corresponds to a violation of the security policy. An intrusion objective contains two fields : its name and a set of conditions denoted by State condition. Figure 2 provides three examples of intrusion objectives that respectively correspond to violation of the three requirements specified in the previl ) X ) 7 ) X ) 7 7 )7 ous security policy example. For instance, intrusion objective  CFs DT sh¨'¨ 6"6HGPVW U is 7 X ) 7 achieved if §aC B has a read access to the file VW but he is not authorized to read it. 3.3 Domain rules Domain rules are used to represent general properties of system's state through possible relations between predicates. For convenience matters, these domain rules are also represented using a pre and post condition. However, the pre and post conditions of a domain rule are evaluated on the same system state: if the pre condition of a domain rule is true in a given state, then the post condition is also true in the same state.

cktHs wtqfbgvxwpys  cktHsQgpirqst"buvxwpys QdQb!f8cwf'sd8gpirqs t"busQd8u!vw3ys PuQdQb!f8cwf0s dgpirqst"buwtb!s0uvxwpys  Domain rule s hucj's wvqfQbgvxw3ys Pre: not 8w3ys'gvw3ys  Post: not gctHs Qg3iqs t"bu!vxwpys lu not gQdQb!f8cwf0s dgpirqst"busQd8uvxw3ys`Pu not gQdQb!f8cwf0s dgpirqst"buwtb!s0uvxwpys l
Domain rule Pre: Post: Figure 3: Examples of domain rules

Figure 3 provides two examples of domain rule. Rule wi xCF&y0GPVW U says that the 7 X ) 7 §aC B owner a given Vz is automatically authorized to have read and write access to this 4{7@9 of file. Rule A 7 4 |CF&50GVz )7 U says that if VW )X7 does)no longer exist, then there is no7 longer 7 an owner for this file and read and write access to VW are also removed to every §aC B . 3.4 Planning intrusion scenario Using the three previous sections, we can now show how the intrusion scenario illegal file access as a planning process. For this purpose, let us consider an intruder, say ( s~} CF$%is, modelled ( 7 8 4 7  ) 7  . 7 Let and a file containing sensitive data, assume that sh} CF$% )l)X7 CFs say ) DE 6 )X7 ¨ sh¨'¨ 7 DE 487  us )X7 U . This   6  6 ! G 6 ¨ E D  wants to achieve the intrusion objective that ( s~} CF$% wants to achieve a final system state such that the following condition is means satisfied:

7Q4 4

)7

Now, the planning problem consists in finding a sequence of actions that transforms the initial state into the final state. Figure 4 presents a possible solution to this problem. It is )l)X7 ) )7 7 7 487 )7 easy to check that objective  CFs DE sh¨'¨ 6"6HG!6 ¨  DE U is achieved in the state resulting from these 8 steps. Notice that there is another solution that corresponds to starting by )X7 blocking the printer and then creating CF$B DT using the  $%¨0& command, the other steps being identical to the other solution. 7 )7 ( R 7 487 )7 According to our definitions presented in section 2, only C  - DT G sh} CF$% 6 ¨  DT U corresponding to step 8 is a malicious action since it enables the intruder to achieve the intrusion objective. Steps 1 to 7 are only suspicious actions in the sense that they enable the intruder to then perform step 8. 4 Attack and alert correlation Our approach for intrusion scenario detection uses the same materials as the ones introduced in section 3. Based on these materials, we shall extend the definition of attack correlation suggested in [CM02] by defining the notion of objective correlation.

47h  8 s } s~¨0¨ 7 66HG ( sh} CF$% R 6 7 ¨ 487  DE )7 U R not G!s~$5&% 4  7 }5G ( sh} CF$% R4{7 sh} R 6 7 ¨ 487  DT )X7 UU ( Let us also assume that s~} CF$% starts in the following initial state:  DE )7 G6 7 ¨ 487  DT )7 U R not G 487 sh} sh¨0¨ 7 66HG ( s~} CF$% R 6 7 ¨ 487  DT )X7 UU R 254 % 7@4 G 22 U R!2 &%~6¨0s ) sh¨0¨ 7 66HG ( s~} CF$% R282 U 7 ¨ 4{7  DT )X7 exists but ( s~} CF$B has not a read access to this file 6 That is, in the initial state, 282 ( and there is a printer  and s~} CF$% has a physical access to this printer.

Step 1: Step 2: Step 3: Step 4: Step 5: Step 6: Step 7: Step 8:

b!cd8ePf~gPQd qd"uxqd 8w3ys ycePHg@d qd"u'Qb! ye8 -'g@d qd"u'Qbu|qd8 8w3ys  s hucj's0gPQd qd8u|qd8 wpys  yt -'gPQd qd8u|qd8 wpys'u! sesb 8w3ys  d8tHycePgPQd qd"u'Qb! 8wt"b -cePs  0g0Qbu|qd8 wpys  qsb -wpys'gPQd qd8us ePsXb 8w3ys irqs t"bPirqst"b!'u vxwpysTvw3ys  vxwpysTmBwtHQ irqs t"bPirqst"b!'u xwt"b!s  wt"b!s   vxwpys  m%wtH  u xwt"b!s  wt"b!s   m%wtHTm%wtHQ0u xwt"b!sTwt"b!s  xwt"b!sTwt"b!s  vxwpysTvxwpys 0u xwt"b!sTwt"b!s 
Unifier

Figure 4: Planning the illegal file access scenario Attack  i b!cdefhgpirqs t"bPu!vxwpys! s hucj's0gpirqst"b!"u!vxwpys P shicj0s'g3irqst"bPQu!vw3ys! yt -0gpirqst"b!Qum%wtH@u!vxwpys  ycePHg3iqs t"bP0u!wt"b!s l d8tHyceHg3iqs t"b!0uxwt"b!s P ye -'g3irqst"b  uxwt"b!s  uvxwpys     wt"b -cePs 'gwt"b!s   um%wtH   yt -'g3irqst"bP0um%wtH"u!vw3ys!   wt"b -cePs 'gwt"b!s 'um%wtHQP dtHycePHg3iqs t"bPuxwt"b!s!   wt"b -cePs 'gwt"b!s 'um%wtHQP 8wt"b -cePs  0gxwt"b!s um%wtH qsXb -8w3ys0gpirqs t"b!uvxwpys  Attack

Figure 5: Direct attack correlation in the illegal file access scenario

4.1 Correlation definitions

Let  and V be two logical expressions having the form:  , @ 7 H  5 2 0 4  Q 7 H  F 2 ' 4 8    0 R Q 7 H  F 2 ' 4 Q    Q R       0 R Q 7 H  F 2 ' 4    and V Each and V is either a predicate or a negation 4 $ 7 .), 7@Hin 254   must  of predicate (not equivalent to namely have one of the following forms: 7@H254   25487 } , or 7QH2F4   not G 2F4{7 }~U . Definition 1: Correlation say that logical expressions  and V are correlated if there R9  and  in 3 R We   such that 7@H254 5 and 7@H254 0 are unifiable through a most exist  in p general unifier (mgu)   . For instance, the post condition of )X action $%¨'&rG!§aC 7 B R VW )X7 U is correlated with the pre 8 4 Q 7 9 7 7 R 7 condition of action A 7@4 G!§aC 7 B R Vz )7 U . This is because these two logical expressions have @ 7 4 7 in common predicate wu G§aC % VW U . After renaming the variables of "wu G§YC % R VW )7 that appear in the post condition of action "R $%¨0& )X7 and the pre condition of action 487@9 respectively 7 @ 7 4 7 R X ) 7 @ 7 4 7     that these A into wu G§aC % VW U and "wu G§YC %7  Ą Vz Ą U , 7 we can conclude X ) 7   Ą   expressions are unifiable through mgu   such that §aC B Ą§aC B and Vz ˘VW )7 Ą .

7@H254'%R'7@H2540~@RQR'7@H254'F

U

Definition 2: Direct attack correlation We say that attacks § and Ł are directly correlated 487 GPŁĽU are correlated. if expressions I6Q'G!§¤U and I Intuitively, correlation between attacks § and Ł means that § enables the intruder to then perform attack Ł . Figure 5 shows attacks that are directly correlated in the illegal file access scenario.

touch

lpr -s

Illegal remove ln -s print-process get-file file access

block

unblock

Figure 6: Illegal file access scenario

Definition 3: Indirect attack correlation We say that attacks § and Ł are indirectly corRQR ŚY§ if: (1) I60G!§¤U is correlated with I 487 GŚ   U through related through domain rules Ś   R  4{7 GPŚŽŹPŻ   U through a a mgu  u¨ , and (2) For each  in 3 ŞŠŤ , I"6Q0GŚŹ'U is correlated with I 487 GPŁĽU through a mgu  u§ . mgu  aŹ , and (3) I6Q'GPŚY§HU is correlated with attack I 7 R )7 For instance, it is easy to verify that attack $%¨'&rG§YC % VW U is indirectly correlated 3 ) 5 2 4 7 R 4 @ 7 " 4 R ` ) 7 with attack - 6HG§YC % I !B Vz U through the domain rule wu 7@4 4 |CF&50GVz )X7 U . Definition 4: Direct objective correlation We say that attack § is directly correlated to 7 intrusion objective ° if expressions I60G!§¤U and ŚsH ¨'T}H`kG°WU are correlated. Definition 5: Indirect objective correlation Same definition as definition 5 by replacing Śs 7 ¨0E}H`G°WU for I 487 GŁĽU . Intuitively, correlation between attack § and intrusion objective7 ° means that attack §  ) 7 7 R ` ) 7 C )7  -DE G§aC % VW U is enables the intruder to achieve objective ° . )`For )7 instance, ) )7 attack 7 directly correlated with intrusion objective  CFs DE s~¨0¨ 66HGVz U . Figure 6 shows the result of applying the correlation definitions to the illegal file access scenario. 4.2 Generating correlation rules In [CM02], we show how to automatically generate correlation rules. Due to space limitation, we shall simply give the intuition here. An attack correlation rule enables the correlation process to correlate two alerts corre4{7@9 A 7 G!§aC 7 B   R VW )7   U is correlated to sponding to correlated attacks. For instance, attack ) 7 R R )7 when Vz )X7   ą#˛!E1 Ą . In this case, the associated correattack  - 6G!§aC B Ą #SE1 Ą VW Ą U )7@ 4    corresponding to detection of attack 487@9 "A 7 can be § lation rule will say that an alert )7Q4  Ą corresponding to detection of attack )  -6 if the target file as§ correlated with )X an alert 7@4    is equal to the target link associated with § )7@4  Ą . Of course, an implicit sociated with § )7@4    with § )7Q4  Ą is that the attack associated with § )7Q4    occurred condition to correlate § )7@4  Ą . before the attack associated with § We similarly generate objective correlation rules to correlate an alert with an intrusion objective. When the correlation process receives an alert and there is a correlation rule that applies to correlate this alert to an intrusion objective, the correlation process will check if 7 is correlated this objective is achieved or not. For instance, attack u w   E  T  % $ 1 objective ł °¤Ś " łľ´ Ś . If an alert corresponding to attack wiTE$%1 7 on a given Ľświth 6 is received,

rpcinfo

showmount

mount

.rhost modification

illegal rlogin root access

Figure 7: Illegal root access scenario

then the correlation process will check if Ľˇ6Q corresponds to a DNS server. Notice that this data is generally not provided in the alert. Therefore, we need to combine "classical" IDS with other tools that collect additional information about the monitored system such as its topology and configuration. This problem is briefly discussed in the conclusion. 5 Hypothesis generation in the correlation process In the correlation process, hypothesis generation (HG) is used in two different situations: 1. When all the steps of a given intrusion scenario are detected, the correlation process will succeed in tracking the intruder by reconstituting his intrusion scenario. However, it may happen that some steps in an intrusion scenario are not detected by any of the IDS. In this case, HG will try to generate minimal hypotheses corresponding to undetected attacks in order to complete the intrusion scenario detection. We suggest raising a virtual alert for each hypothesis successfully generated. 2. When the correlation process succeeds in correlating several attacks but no intrusion objective is achieved yet, HG is used to generate an intrusion objective consistent with these attacks. This is used by the correlation process to anticipate over the intruder's intention in order to prepare the most adequate reaction. 5.1 Virtual alerts The correlation process will attempt to create virtual alerts when it is plausible that some attacks are not detected. That is, when two alerts cannot be correlated, we try to insert one or several virtual alerts between them. Let us describe the two main steps of the virtual alert  ) @ 7 4  ) Q 7 4   creation function. Let us assume that §  and §  Ą are not correlated.



Let §iPs~¨01   and §iPsh¨'1 Ą be the attacks respectively associated with §    and §  Ą . The correlation process will then attempt to find a path of attacks to connect §ush¨'1   with §iPs~¨01 Ą . Of course, this path must be formed by attacks that might be not detected by any IDS that provides alerts to the correlation process.

)7Q4

)X7@4

For example, let us assume that, in the illegal root access scenario1 (see figure 7), the modification of the .rhost file is not detected. In this case, the correlation process receives the rlogin alert without being able to correlate it with the mount alert. However, the correlation process knows that attack mount can be correlated with attack rlogin through attack .rhost.
Due to space limitation, we do not give a complete specification of various actions and intrusion objective included in this scenario (see [CM02] for a more complete discussion of this scenario).
1



The second step of the function replaces the path of attacks by a path of virtual alerts by instantiating each attack. From the first attack we create a first virtual alert. This virtual )X7@4    . We do the same for the next attacks of the path until § )7@4  Ą alert is correlated with § is achieved. At this point, the correlation process verifies whether it is possible to correlate )7@4  Ą . the last virtual alert with §

In the last example, we had a single attack in our path corresponding to the &%6Q modification. We create a virtual alert associated with this attack. According to the correlation rules between mount alert and .rhost modification alert, the target IP addresses must be the same. Consequently, the virtual alert is initialised with the target IP address of the mount alert. We then check correlation between the virtual alert .rhost and the rlogin alert. This test could fail if the target IP addresses of these two alerts are not equal. 5.2 Derivation of intrusion objective When the correlation process has detected the beginning of a scenario, it tries to find out what will be the next steps that might enable the intruder to achieve an intrusion objective. For this purpose, the correlation process applies an approach similar to the first step used to raise virtual alerts. It analyses the possible correlations between attacks and between an attack and an intrusion objective to find a path of attacks between the last detected alert of the scenario and an intrusion objective. When this alert can be connected to different intrusion objectives through different paths, our strategy is simply to select an intrusion objective that corresponds to the shortest path. 6 Discussions and examples of scenario detection In the intrusion detection context, the intruder whose plans are being inferred is not cooperative and observations are gleaned through IDS alerts. This point and the computer security context bring to light several issues to take in consideration. The objective of this section is to show, through the intrusion scenarios introduced in section 2, how our approach addresses these issues:

v4





Unobserved actions: There are multiple reasons that can make an attack unobservable. Signature based IDS are not able to recognize unknown exploits and even variations of known exploits can make them undetectable. Furthermore there can be holes in the IDS network coverage that make impossible detection of some malicious attacks. Our approach to solve the problem that some steps in an intrusion scenario are not detected is based on hypothesis generation as shown in section 5. Optional actions: Figure 8 shows detection of intrusion scenario 7 °WŚ  Ś when the ) T 2  R 2 R R 2 intruder performs the sequence E6 "1F$ !yC 6¨0s~ wi!EE$%1 . Actually, 7 actions yC and 6"¨0sh are optional since the intruder may directly attempt the wuET$B1 attack without 2 checking that the server is active (with the yC command) and Windows is installed (with a 6¨'sh of port 139). Representing intrusion scenario that includes optional actions 2 is immediate in our approach. If the intruder does not execute !yC or 6¨'sh , we shall simply detect a simpler scenario that does not include these actions.

ł

łŞ´

nslookup

DOS on DNS ping winnuke

scan port 139

Figure 8: DOS on DNS scenario





Representation of intrusion scenario variations: As an intruder executes his plan, his actions may lead him to draw some conclusions i.e. gain some knowledge about the network or some host for example. This may lead in small variations in the execution of the intruder's plan. We have to be able to represent these variations to take them in conł łŞ´ Ś scenario, the intruder may prefer using sideration. For instance, in the °¤Ś " 4 Q 7 4 7 2  sh¨ $5 instead of a 5C to know which machines are active in the network he wants to attack. Representing intrusion scenario variations is straightforward our approach. 4 sh¨ 7Q4 in 7 and  5 $  the corWe have simply to specify the pre and post conditions of4 attack 2 Q 7 4 7 relation process will automatically derive that replacing  sh¨ $5 by yC also enables ł łŞ´ Ś objective. the intruder to achieve the °WŚ  Management of repeated observations: an intruder that will repeat several times the steps of an intrusion scenario will potentially activate the plan recognition several times. This may lead to an explosion of the number 7 of alerts as in [GG01a].2 For instance, if one specifies an intrusion scenario ¸˘TE$%1 §i2 Ps~¨01 by the sequence 5C , 6¨'sh port 139, wi!EE$%1 7 and if the intruder executes 100 yCF6 and 100 6¨0s~T67 and then 1 wiTE$%1 7 , this may lead to @š8šşť@š8šź@š8š8šš detections of the ¸˘TE$%1 sHsh¨'1 . Our approach will generate only one alert for such a case, even if this alert corresponds to a complex scenario.

7 Conclusion Based on the observation that an intrusion scenario might be represented as a planning activity, we suggest a model to recognize intrusion scenarios and malicious intentions. This model does not follow previous proposals that require to explicitly specify a library of intrusion scenarios. Instead, our approach is based on specification of elementary attacks and intrusion objectives. We then show how to derive correlation relations between two attacks or between an attack and an intrusion objective. Detection of complex intrusion scenario is obtained by combining these binary correlation relations. Our approach is efficient to cluster repeated actions in a single scenario. We also suggest using hypothesis generation to recognize intrusion scenarios when some steps in these scenarios are not detected. We have implemented in Prolog the functions that perform attack and objective correlations in the CRIM prototype [Cup01, CM02]. Attacks are actually specified in Lambda [CO00], which is fully compatible with the attack model suggested in this paper and alerts are represented in the IDMEF format [CD01]. There are several issues to this work. When the intruder did not achieved his intrusion ob-

jective yet but there are several possible intrusion objectives consistent with a given sequence of correlated attacks, our current strategy is simply to select the objective that requires the shortest path of attacks to be achieved. Our course, it would be useful to significantly enhance this strategy. We are studying approaches based on Bayesian Networks to infer the best intrusion objectives that explain all the observations. As suggested in [GG01b], our solution should also able to consider situations where the intruder has multiple goals. Another point is that to decide if a given intrusion scenario is achieved or not, it is often necessary to combine information provided by "classical" IDS with other information about the system monitored by the IDS: its topology, configuration and other data about the type and version of the operating systems and installed applications. For instance, to decide if the ł ľ ł ´ objective °WŚ  Ś is achieved it is necessary to know on which system is installed the DNS server. This is not provided by classical IDS but other tools exist that may be used to collect it. Since current IDS also provide alerts that do not allow us to distinguish between successful or failing attacks, these additional data would be also useful for that purpose. This problem is currently investigated in the ongoing project DICO (see also [MMDD02]). 8 Acknowledgements This work was partially funded by the DGA/CELAR/CASSI as a part of the Mirador project and then by the French Ministry of Research as part of the DICO project. The authors would like to thank all the members of these projects, especially the members of the sub-project "Correlation": Herv´ e Debar, Ludovic M´ e and Benjamin Morin. References
[CD01] D. Curry and H. Debar. Intrusion detection message exchange format data model and extensible markup language (xml) document type definition. draft-itetf-idwg-idmef-xml-06.txt, December 2001. F. Cuppens and A. Mi` ege. Alert Correlation in a Cooperative Intrusion Detection Framework. In IEEE Symposium on Security and Privacy, Oakland, USA, 2002. F. Cuppens and R. Ortalo. Lambda: A language to model a database for detection of attacks. In Third International Workshop on the Recent Advances in Intrusion Detection (RAID'2000), Toulouse, France, October 2000. F. Cuppens. Managing Alerts in a Multi-Intrusion Detection Environment. In 17th Annual Computer Security Applications Conference New-Orleans, New-Orleans, USA, December 2001. C. Geib and R. Goldman. Plan Recognition in Intrusion Detection Systems. In DARPA Information Survivability Conference and Exposition (DISCEX), June 2001. C. Geib and R. Goldman. Probabilistic Plan Recognition for Hostile Agents. In Florida AI Research Symposium (FLAIR), Key-West, USA, 2001.

[CM02] [CO00]

[Cup01] [GG01a] [GG01b]

[MMDD02] Benjamin Morin, Ludovic M´ e, Herv´ e Debar, and Mireille Ducass´ e. M2D2: A Formal Data Model for IDS Alert Correlation. In Fifth International Workshop on the Recent Advances in Intrusion Detection (RAID'2002), Zurich, October 2002. [VS01] [ZMB02] A. Valdes and K. Skinner. Probabilistic Alert Correlation. In Fourth International Workshop on the Recent Advances in Intrusion Detection (RAID'2001), Davis, USA, October 2001. Jacob Zimmermann, Ludovic M´ e, and Christophe Bidan. Introducing reference flow control for intrusion detection at the OS level. In Fifth International Workshop on the Recent Advances in Intrusion Detection (RAID'2002), Zurich, October 2002.

