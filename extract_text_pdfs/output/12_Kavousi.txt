6'th International Symposium on Telecommunications (IST'2012)

Automatic Learning of Attack Behavior Patterns Using Bayesian Networks
Fatemeh Kavousi and Behzad Akbari
Faculty of Electrical and Computer Engineering Tarbiat Modares University Tehran, Iran {fatemeh.kavousi, b.akbari}@modares.ac.ir
Abstract--A tremendous number of low-level alerts reported by information security systems makes it challenging for security administrators to do an effective analysis and initiate a timely response. Alert correlation techniques have been proposed to reduce the number of alerts and provide a succinct and high-level view of attacks. Most of the existing approaches rely on a priori and hard-coded domain knowledge that leads to their difficult implementation and limited capabilities of detecting new attack strategies. To address the drawbacks of these approaches, the recent trend of research in this area has gone towards extracting attack strategies through automatic analysis of intrusion alerts. In this paper, we present new algorithms to mine attack behavior patterns from a large number of intrusion alerts without specific prior knowledge about attacks. Unlike expert knowledge-based methods, our proposed scheme automatically generates correlation rules from the previously observed alerts using a Bayesian causality mechanism. The attack activity patterns learned by this way can help us to correlate alerts, reconstruct attack scenarios and predict possible forthcoming attacks in a real-time system. Our experimental results clearly show efficiency of the proposed method in learning new attack strategies. Keywords- Alert Correlation; Network Security; Intrusion Detection; Bayesian Network;

I.

INTRODUCTION

With the immense popularity of Internet and network-based applications, the number and sophistication of network attacks have also increased drastically. So, security management has become one of the main challenges for network administrators. To promote security of the networks, many technologies and security mechanisms have been developed, such as firewalls, authentication and access control services and intrusion detection systems (IDSs). Deploying such information security systems can provide in-depth protection for IT infrastructure. However, a huge number of low-level alerts generated by these systems makes it challenging for security administrators to perform an effective analysis and initiate a timely response. Thus, it is important to develop an advanced alert correlation system to reduce alert redundancy, intelligently correlate alerts, discover attack strategies and predict forthcoming attacks. Up to now, a variety of alert correlation methods have been suggested that can be classified as similarity-based [1, 2, 3] scenario-based [ 4 , 5 , 6 ], pre/post-condition based [ 7 , 8 ], statistical causality analysis [9, 10] or hybrid approaches [11].

The majority of the existing approaches rely on complex correlation rule definition or other forms of hard-coded domain expert knowledge that leads to their difficult implementation and limited capabilities of detecting new attack strategies. To overcome the drawbacks of these approaches, the most recent researches in alert correlation have gone towards extracting attack strategies through automatic analysis of intrusion alerts. The main challenge that arises in this context is to extract the necessary constraints and alert relationships that define a multistage attack in order to accurately and quickly characterize the instances of that attack in the future. In line with the recent researches, in this paper, we present a new technique to automatically mine attack behavior patterns from the previously observed alerts. In the current study, we are interested in Bayesian networks [12], since it requires no expert knowledge. Moreover, using of Bayesian networks provides an opportunity to incorporate prior knowledge about attacks with attack behavior patterns learned from history alerts. Also, new attack strategies can be learned automatically by updating alert Bayesian network based on the new observations. Our alert correlation engine has two components. (1) An offline component that periodically learns multi-step attack behavior patterns from historical alerts using a Bayesian causality analysis. (2) An online component that correlate alerts in real time using a hierarchical method and based on the attack behavior patterns extracted by the offline component. In this paper, we will only focus on the offline component. The rest of this paper is structured as follows: In section II we introduce the overall architecture of our proposed alert correlation model. In section III, we explain the first part of our model and describe how the offline attack pattern recognition component extract attack transition patterns from observations history. Section IV reports experimental results and finally section V concludes the paper and outlines some future works. II.
PROPOSED BAYESIAN-BASED CORRELATION ENGINE

Fig. 1 shows the general architecture of the proposed model for alert correlation, which consists of two main components: an offline attack pattern recognition component and an online alert correlation component. The aim of the offline component is to mine multi-step attack activity patterns to be later used in the online alert correlation. For this purpose, it first aggregates alerts related to the same attack step and refer to attacks launched by a single attacker against the same target. It then automatically infers the

978-1-4673-2073-3/12/$31.00 Å 2012 IEEE

999

causal relations between different alert types from aggregated alerts using a Bayesian network-based approach. The extracted information by this component is stored in a data structure called correlation knowledge base which holds information necessary to identify causally related alerts. The online alert correlation component correlates alerts in real-time using a hierarchical method and based on the information provided by the offline component. It first fuses repetitive alerts from same or different sensors to reduce alerts redundancy (alert fusion). Based on the results of alert fusion, it then aggregates alerts belonging to the same attack step into hyper alerts to provide more synthetic information for the following module (attack thread reconstruction). This can speed-up the correlation process and make the output more intelligible. Finally, the attack scenario reconstruction module correlates causally related hyper alerts and reconstructs attack scenarios based on the relationships defined in the correlation knowledge base. III. OFFLINE ATTACK PATTERN RECOGNITION

New Alert

Alerts database

Correlation Base

Alert preprocessing

Alert fusion Attack thread reconstruction

Attack scenario

Alerts relevance analysis Attack pattern recognition component

Attack scenario reconstruction Alert correlation component

A. Alert preprocessing The motivation in this step is to decrease redundancy of information embodied in low-level alerts. For this aim, the alert preprocessing module follows a simple strategy to aggregate alerts that are triggered by an attacker who runs the same exploit against a single target multiple times to estimate the right values of some parameters. The temporal difference between such alerts usually doesnt exceed a specific threshold. Here, a time window parameter is defined in this paper which is known as threading time window. The preprocessing module keeps a sliding window of alerts stored in a timeordered queue. When a new alert arrives, it is compared with alerts in the queue. If the protocol, the alert type, the source IP, and the target IP of the two alerts are all matched, the two alerts are merged into a single meta-alert and the search ends. The timestamp of the new meta-alert is set to the timestamp of the earlier alert. Other attributes of the meta-alert are assigned the union of the values of the corresponding alert attributes. B. Relevance Analysis After preprocessing raw alerts, we infer the causal relations between alert types from the history aggregated alerts. During this step, we also extract equality constraints that significantly contribute to the degree of relevance of two alert types. An equality constraint defines the relationships among the attribute values of two alerts when one of them prepares for later one. There may be several equality constraints for a pair of alert types. In this case, if a type alert prepares for a type alert , then and must satisfy at least one of the equality constraints. Thus, given a stream of aggregated alerts, we first derive all possible causal relations between alert types together with the corresponding equality constraints, then we encode the extracted information in a data structure called alert type graph. Definition 1. Given a set of alert types , an alert type graph ATG over T is a quadruple where,  is a Bayesian network over T,  , if and only if there is a causal relation from to .  C is a mapping that maps each edge to a set of equality constraints corresponded to .

Figure 1. Overview of the alert correlation system

Our proposed method for finding alert type graph includes three main steps: learning a super-structure, transaction data formulation, and Bayesian network learning. In the following we explain each of these steps in details. 1) Learning a super-structure We first approximate a structural constraint for alert type graph by estimating the correlation probability between alert types. The structural constraint called super-structure can speed-up the Bayesian network learning process, since it restricts the search to networks that are a subgraph of the learned super-structure. The problem of learning a super-structure includes two subtasks: (1) finding the possible causal relationships between alert types, and (2) extracting the corresponding set of equality constraints for each alert type pair. To examine the existence of causal relation from to , and to determine its corresponding set of equality constraints , in the first step, we should evaluate the influence of each first-order equality constraint ec on the relation between and (list of all first-order equality constraints used in this paper are shown in Table I). This requires the calculation of . Let ECS be a set of equality constraints for , then is computed by (1). ( | ) (1)

Where, is the number of alerts of type , and indicates the number of times that a type alert followed by a type alert, such that they are in a same predefined time window and satisfy at least one of the equality constraints in ECS. Based on the values of ( | ) and , we can distinguish three kinds of equality constraints:  If ( ) ( ) then ec is irrelevant and doesnt influence the incidence probability of type alerts after type alerts.

1000

TABLE I.

LIST OF FIRST-ORDER EQUALITY CONSTRAINTS

Equality Constraints Equality of source IP addresses (SrcIP = SrcIP) Equality of destination IP addresses (DestIP = DestIP) Equality of source port numbers (SrcPort = SrcPort) Equality of destination port numbers (DestPort = DestPort) Alerts IP chain (DestIP = SrcIP) Reverse IP chain (SrcIP = DestIP)

In which is the probability of kth correlation between and where a type alert a followed by a type alert b, such that they are in the same time window and satisfy at least one of the equality constraints in ECS. In this case, to estimate the correlation probability between alerts a and b, a similarity vector is created for them based on the features shown in Table II. Then, the correlation probability between alerts a and b is computed by (3).   (3)

If ( ) ( ) then considering equality constraint ec reduces the incidence probability of type alerts after type alerts (ec is a relevant equality constraint with negative influence).  If ( ) ( ) then considering equality constraint ec increases the occurrence probability of type alerts after type alerts (ec is a relevant equality constraint with positive influence). At the end of this step, all relevant equality constraints with positive influence are selected and enter the next step. In step 2, the set of higher-order equality constraints are constructed by conjunction of the selected first-order equality constraints and their influence on the relation between and are evaluated. In this step, we only consider conjunctions that contain "DestIP = DestIP" or "DestIP = SrcIP" as a constraint. It is based on the fact that for attacks that are part of a same multi-step attack, they usually have the same destination IPs or the destination IP of the previous one is equal to the source IP of the next attack. After investigating all possible equality constraints, the set of relevant equality constraints with positive influence are chosen as candidate equality constraints C. Then, for each , we calculate a factor called "minimum conditional correlativity" for and , which specifies the minimum correlativity between alerts of type with alerts of type with respect to ec (the details of computation of this factor will be explained later). If the calculated minimum conditional correlativity for ec doesnt satisfy a predefined threshold t, ec is removed from C. So, at the end of this step, C will be the set of all relevant equality constraints with positive influence that satisfy threshold t. In the last step, C is divided into two partitions and , where and . Then, from each subset, an equality constraint that maximizes the minimum conditional correlativity factor is selected and added into . To build super-structure S, the algorithm starts with an empty graph. It determines for each alert type pair using the procedure described above. Then, it adds edge to the graph, if is not null. Minimum conditional correlativity factor If and be two alert types and ECS be a set of equality constraints for , the minimum conditional correlativity between and with respect to ECS is calculated using (2). ( | ) (2)



and represent the value and the weight of kth feature, respectively. Table III gives the weight vector. The weight values are set empirically and can be tuned in practice. 2) Transaction data formulation After finding a super-structure , we need to preprocess observed data to convert it to a structured format that can be readily used in the Bayesian network learning process. During this step, for each alert type , we formulate a transaction data which will be used to investigate the causal relationships of other alert types to . Pseudocode of the transaction data formulation procedure for alert type is illustrated in algorithm 1 (Fig. 2). As see, we first define the candidate parent set of as: {(
TABLE II. No.

)(

)

(

)} (4)

FEATURES INVOLVED IN CORRELATIVITY CALCULATION Description

Feature Source IPs similarity { Destination IPs similarity Alerts IP chain Reverse IP chain Source ports similarity Destination ports similarity Time similarity Alerts type chain

1

[1]

2 3 4 5 6 7 8

It is computed as Feature 1. { { { { { ( )

TABLE III. Feature No. Weight 1 0.15 2 0.2

THE WEIGHT VALUES FOR FEATURES 3 0.15 4 0.1 5 0.08 6 0.02 7 0.05 8 0.25

1001

Now, let and GSeq be the sequence of time-ordered alerts whose types belong to the set . We split GSeq into subsequences according to . In the case that a target alert (an instance of ) is observed inside a window, we shift the window to left until it ends on the target alert (see Fig. 3). This is done to ensure that all the alerts that prepare for the target alert are present in a single window. So, some alerts may fall into two windows simultaneously. Then, each window is mapped to a Boolean vector which actually encodes the occurrence or non-occurrence of each candidate parent and target alert within it. Each vector is also tagged by the ID of the observed target alert. When no target alert has been observed, the label 0 is assigned. Table IV shows an example of the transaction data for alert type .
Algorithm 1: Transaction Data Formulation() Input: : target alert type Observ: history aggregated alerts : size of time window : super-structure Output: : set of training data for alert type Method: 1. 2. { 3. 4. for each target 5. ; }; in the do ; ; ;

TABLE IV.

EXAMPLE OF TRANSACTION DATA FOR ALERT TYPE ... 0 0 .... 1 0 1 ... 0 ... ... ... ... 1 0 ... 1 1 0 ... 1

...

(initially empty)

3) Bayesian network learning Finally, the alert type graph is constructed from transaction data D, by considering the super-structure S learned in the first step. As shown in algorithm 2 (Fig. 4), each alert type is allowed to have parents only from a predetermined candidate . It means that for each alert type , we will parent set denotes the parent set of . , where have Our Bayesian network learning algorithm inspired from [13], infers the causal relationships between alert types using some conditional independence tests. Let be a , the algorithm candidate parent for , and , that returns true if invokes a function to test is conditionally independent from cp given Z. Function measures the strength of association of and given Z, as estimated by a statistical test on . To implement this function, we applied mutual information which measures the statistical dependency among random variables. Definition 2. The conditional mutual information between two variables X, Y, with respect to the set of evidence variables (conditioning-set) Z is defined as [14]:  (5)

6. Sort chronologically and split it into windows, according to 7. if an instance of is observed inside a window then 8. Move this window to left until it ends on the target alert; 9. end if 10. for each time window do 11. Create a Boolean vector of size | ; | 12. if ends with a target alert b then [ ] 13. and Label with ; 14. for each do 15. If  alert a of type within s.t. a and b satisfy ECS then 16. [ ] ; 17. else [ ] ; 18. end for 19. else [ ] 20. and Label with 0; 21. for each do 22. If  alert a of type within then [ ] ; 23. else [ ] ; 24. end for 25. end if 26. Add into ; 27. end for 28. end for 29. if  s.t. then ; 30. return ; Figure 2. Algorithm1 (Transaction data formulation)

Given the actual probability distributions of variables, it would be claimed that X and Y are conditionally independent given Z, iff . But, in practice, in the Bayesian network learning process, we dont have the real distributions and instead use the empirical distributions estimated from available data. A normal practice is usually to use , which approximates from data D and claim that X and Y are independent given Z when ( is a small threshold and should be set up suitably). To implement function , we estimate the conditional mutual information between cp and given Z based on , we then apply relations (6) and (7) to calculate the value of this function.
{

(6)


W1 1 2 1 W2 3 W3 4 W4 3 1 2 2 4 1 Host 1 172.16.112.10 Host 2 172.16.112.50

(7)

Target Alerts 1 3 1 4 1 4 2 1 1

Figure 3. Data observation preprocessing

is a small value that is determined experimentally. We assume that . Our Bayesian network learning algorithm (Fig. 4) starts with an empty graph and builds the causal network model using a two-phase scheme. In the forward phase, candidate

1002

edges are added sequentially to the graph using a heuristic called "Max-Min". Based on this heuristic, in each iteration, the graph is augmented by an edge like where: ( ) (8)



Function ( ) represents the minimum association of k and y relative to and is defined as: ( ) ( ) (9)



The idea behind this heuristic is to select an edge that its corresponding nodes remain very associated together despite our best efforts to make them independent. Phase I continues until the maximum minimum association reaches zero. In the backward phase, the algorithm tries to eliminate the false positives of the first phase. This is achieved by testing . for each and each subset We used some optimizations to improve the computational performance of the algorithm.
Algorithm 2: Bayesian Network Learning() Input: : set of all alert types : super-structure : the full set of training data Output: //alert type graph (initially empty) Method: //Phase I: Forward 1. for each do 2. {( )( ) 3. end for 4. repeat 5. for each do 6. for each do 7. if (   8. 9. 10. 11. If and ! 12. 13. 14. end if 15. ; 16. until //Phase II: Backward 17. for each do 18. for each do 19. if  , s.t. 20. ; 21. ; 22. end if 23. end for 24. end for 25. return ;

Once a variable reaches a minimum association of zero with , it is crossed out from and is not considered in next iterations of the algorithm. Also, in computing the MinAssoc function in Line 8, when a is found such that conditioning-set , there is no need to keep trying other subsets. Similarly, in Line 19. Caching the results of the subsequent calls to the MinAssoc function which reduces the number of independence tests and accordingly the running time drastically. Assume that in iteration n variable P is added to , so we will have . In iteration (n+1), the minimum association for any with X relative to can be written as the minimum achieved with all subsets that do not include the new element P, i.e. , and the minimum achieved with all subsets that include P. The first part which is calculated in iteration n, can be cached to be used in the next iteration. By this way, we only need to update by testing only the newly created subsets of for further minimizing the association. IV. EXPERIMENTAL RESULTS

};

;

)

then Delete ( (

from ); ) then

;

then

Figure 4. Algorithm 2 (Bayesian network learning)

To evaluate the proposed method, we used DARPA 2000 dataset [15]. There are two attack scenarios in DARPA 2000: LLDOS1.0 and LLDOS2.0.2. In the both scenarios, a novice attacker tries to run a Distributed Denial of Service (DDOS) attack at a US government site using a scripted attack. The main difference between these two scenarios is that in 2.0.2 the attacker probes for host operating system by doing DNS HINFO queries, rather than sweeping IPs and rpc ports, and that he/she breaks into one host first, and then fans out from there, rather than attacking each host individually. We tested our method on both of the scenarios. Alert log files [ 16 ] generated by RealSecure IDS, were used in our experiments. Table V gives the parameter settings in our experiments. Fig. 5 also shows the alert type graph generated for the first scenario. RealSecure doesnt report any alert for the ICMP probing activity and thus it is not included in this graph. A few ,,Sadmind_Ping and ,,Admind alerts are generated for step 2, when the attacker tries to identify vulnerable hosts. The timestamps of these alerts and the values of their attributes reveal that RealSecure reports two different alerts for a single attack. In the next step, attacker runs remote buffer-overflow attack to penetrate into the vulnerable machines. Again, IDS reports two different alerts ,,Sadmind_Amslverify_Overflow and ,,Admind for a single attack. The fourth step, logging into compromised machines and installing "mstream" software, triggers five types of alerts: ,,Rsh, ,,Mstream_Zombie, ,,TelnetXDisplay, ,,TelnetEnvAll and ,,TelnetTerminalType. Unfortunately, the telnet alerts are not included in this alert type graph. Instead, ,,TelnetXdisplay and ,,TelnetEnvAll alerts are correlated in a separated graph. However, to the best of our knowledge, excepting [3, 11] (which both use a similar approach), in none of the approaches proposed for alert correlation, the telnet alerts are not correctly correlated with the attack scenario. The last stage of the attack which leads to

1003

a ,,Stream_DOS alert has not been inserted in the graph because of using spoofed IP addresses by the attacker. Fig. 6 displays the alert type graph for LLDOS2.0.2. It correctly shows the major steps of the attack. Like LLDOS1.0, Realsecure doesnt raise any alert for the first step of the attack and thus, it is not included in the corresponding alert type graph. Step 5 is also missing in Fig. 6 since the attacker again used spoofed IP addresses. IDS identifies other steps of the attack by raising the following alerts: ,,Admind, ,,Sadmind_Amslverify_Overflow, ,,Ftp_Put, ,,Ftp_User, ,,Ftp_Pass, ,,Mstream_Zombie, ,,TelnetTerminalType, ,,TelnetXDisplay, ,,TelnetEnvAll alert. V. CONCLUSION AND FUTURE WORK In this paper, we proposed a new alert correlation method which aims at solving the problems of detecting new attack strategies and difficulty of complex correlation rule definition and maintenance.
TABLE V. Threading window ( 5 Min ) 60 Min VARIABLES USED IN OUR EXPERIMENTS Correlation threshold (t) 0.4  0.15

Our method requires no expert knowledge. It concerns history of observations and automatically extracts the attack transition patterns using a new Bayesian network learning algorithm. The results of our experiments on DARPA 2000 showed that our method has the great potential to learn new attack strategies. As a future work, we plan to revise the method in such a way that it can learn new attack strategies dynamically by adapting the alert Bayesian network based on the new observations. ACKNOWLEDGMENT This work has been supported in part by the Iran Telecommunication Research Center (ITRC) under contract number T-500-18130. REFERENCES
[1] S. Lee, B. Chung, H. Kim, Y. Lee, C. Park, and H. Yoon, "Real-time analysis of intrusion detection alerts via correlation," Computers & Security, vol. 25, no. 3, pp. 169-183, 2006. [2] B. Zhu, and A.A. Ghorbani, "Alert correlation for extracting attack strategies," International journal of network security, vol. 3, no. 3, pp. 244Â­258, 2006. [3] S.H. Ahmadinejad, and S. Jalili, "Alert correlation using correlation probability estimation and time windows," In: International conference on computer technology and development , vol. 2, pp. 170Â­175, 2009. [4] F. Cuppens, and R. Ortalo, "LAMBDA: A language to model a database for detection of attacks," In: Recent Advances in Intrusion Detection (RAID), LNCS, vol. 1907, pp. 197Â­216, 2000. [5] L. Wang, A. Liu, and S. Jajodia, "Using attack graphs for correlating, hypothesizing and predicting intrusion alerts," C omputer Communications, vol. 29, no. 15, pp. 2917Â­2933, 2006. [6] Z. Li, A. Zhang, J. Lei, and L. Wang, "Real-time correlation of network security alerts," in: Proceedings of the 4th IEEE International Conference on e-Business Engineering (ICEBE), pp. 73-80, 2007. [7] S.J. Templeton and K. Levitt, "A requires/provides model for computer attacks," In: Proceedings of the 3rd ACM workshop on new security paradigms, pp. 31-38, 2000. [8] F. Cuppens, and A. Miege, "Alert correlation in a cooperative intrusion detection framework," In: Proceedings of the 2002 IEEE Symposium on Security and Privacy, pp. 202Â­215, 2002. [9] X. Qin, and W. Lee: "Statistical causality analysis of INFOSEC alert data," In: Recent Advances in Intrusion Detection (RAID), LNCS, vol. 2820, pp. 73-93, 2003. [10] H. Ren, N. Stakhanova, and A.A. Ghorbani, "An online adaptive approach to alert correlation," In: Proceedings of the 17 th international conference on Detection of intrusions and malware, and vulnerability assessment, LNCS, vol. 6201, pp. 153Â­172, 2010. [11] S. H. Ahmadinejad, S. Jalili, and M. Abadi, "A hybrid model for correlating alerts of known and unknown attack scenarios and updating attack graphs," Computer Networks, vol. 55, pp. 2221-2240, 2011. [12] P. Spirtes, C. Glymour, and R. Scheines, "Causation, prediction, and search," Springer/Verlag, First edition, 1993. [13] I. Tsamardinos, L.E. Brown, and C.F. Aliferis, "The max-min hillclimbing Bayesian network structure learning algorithm," Machine Learning, vol. 65, no. 1, pp. 31-78, 2006. [14] J. Cheng, R. Greiner, J. Kelly, D. Bell, and W. Liu, "Learning Bayesian networks from data: An information-theory based approach," Artificial Intelligence, vol. 137, pp. 43-90, 2002. [15] MIT Lincoln Lab., 2000 DARPA Intrusion detection evaluation datasets, http://www.ll.mit.edu/mission/communications/ist/corpora/ideval/data/ 2000data.html [ 16 ] North Carolina State University Cyber Defense Laboratory, TIAA, http://discovery.csc.ncsu.edu/software/correlator/ver1.0

n1: Sadmind_ping {n1.SrcIP = n3.SrcIP  n1.DestIP = n3.DestIP  n1.DestPort = n3.DestPort} {n1.SrcIP = n2.SrcIP  n1.SrcPort = n2.S cPo t  n1.DestIP = n2.DestIP  n1.DestPort = n2.DestPort} {n3.SrcIP = n2.SrcIP  n3.SrcPort = n2.S cPo t  n3.DestIP = n2.DestIP  n3.DestPort = n2.DestPort}

n3: Sadmind_Amslverify_Overflow {n3.SrcIP = n4.SrcIP  n3.DestIP = n4.DestIP}, {n3.DestIP = n4.S cIP  n3.SrcIP = n4.DestIP} n4: Rsh

n2: Admind

{n3.DestIP = n5.SrcIP}

n5: Mstream_Zombie

Figure 5. Alert type graph for LLDOS1.0
n1: Admind {n1.SrcIP = n2.SrcIP  n1.SrcPort = n2.S cPo t  n1.DestIP = n2.DestIP  n1.DestPort = n2.DestPort} n2: Sadmind_Amslverify_Overflow {n2.SrcIP = n3.SrcIP  2.DestIP = n3.DestIP} {n3.SrcIP = n4.SrcIP  n3.SrcPort = n4.S cPo t  n3.DestIP = n4.DestIP  n3.DestPort = n4.DestPort} n3: Ftp_Put {n3.SrcIP = n8.SrcIP  n3.DestIP = n8.DestIP} {n3.SrcIP = n7.SrcIP  n3.DestIP = n7.DestIP}, {n3.DestIP = n7.SrcIP} n8:TelnetXDisplay n7: Mstream_Zombie {n8.SrcIP = n9.SrcIP  n8.SrcPort = n9.S cPo t  n8.DestIP = n9.DestIP  n8.DestPort = n9.DestPort}

n4: Ftp_User {n4.SrcIP = n5.SrcIP  n4.SrcPort = n5.S cPo t  n4.DestIP = n5.DestIP  n4.DestPort = n5.DestPort} n5: Ftp_Pass {n5.SrcIP = n6.SrcIP  n5.SrcPort = n6.S cPo t  n5.DestIP = n6.DestIP  n5.DestPort = n6.DestPort} n6: Ftp_Syst

n9:TelnetEnvAll

Figure 6. Alert type graph for LLDOS2.0.2

1004

